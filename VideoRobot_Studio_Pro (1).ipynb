{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"VideoRobot_Studio_Pro.ipynb\n",
        "\n",
        "Automatically generated by Colab.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1zDTsiqfJzp_wdnlfXadMA9lwC6GfDUXO\n",
        "\"\"\"\n",
        "\n",
        "# @title 1) Install (pip + apt) — Self-contained, Idempotent (with Inter font fetch)\n",
        "# نصب پیش‌نیازها + دانلود مطمئن فونت‌های Inter (static TTF) با چند مسیر fallback\n",
        "\n",
        "from __future__ import annotations\n",
        "import os, sys, shutil, tempfile, subprocess as sp\n",
        "from pathlib import Path\n",
        "from shutil import which\n",
        "\n",
        "# -----------------------------\n",
        "# Helpers\n",
        "# -----------------------------\n",
        "def _env():\n",
        "    e = os.environ.copy()\n",
        "    e.setdefault(\"PIP_DISABLE_PIP_VERSION_CHECK\", \"1\")\n",
        "    e.setdefault(\"DEBIAN_FRONTEND\", \"noninteractive\")\n",
        "    e.setdefault(\"PYTHONWARNINGS\", \"ignore\")\n",
        "    e.setdefault(\"LC_ALL\", \"C\")\n",
        "    e.setdefault(\"LANG\", \"C\")\n",
        "    return e\n",
        "\n",
        "def _run(cmd, timeout=None):\n",
        "    p = sp.run(cmd, stdout=sp.PIPE, stderr=sp.PIPE, text=True, timeout=timeout, env=_env())\n",
        "    return p.returncode, (p.stdout or \"\").strip(), (p.stderr or \"\").strip()\n",
        "\n",
        "def _ok(msg): print(f\"✅ {msg}\")\n",
        "def _warn(msg): print(f\"⚠️  {msg}\")\n",
        "def _err(msg): print(f\"❌ {msg}\")\n",
        "\n",
        "def _apt_install(pkgs):\n",
        "    if not pkgs: return\n",
        "    if which(\"apt-get\") is None:\n",
        "        _warn(\"apt-get unavailable; skipping APT installs\")\n",
        "        return\n",
        "    _run([\"apt-get\",\"update\",\"-qq\"], timeout=60)\n",
        "    _run([\"apt-get\",\"install\",\"-y\",\"-qq\",*pkgs], timeout=600)\n",
        "\n",
        "def _pip_install(specs):\n",
        "    if not specs: return\n",
        "    py = sys.executable\n",
        "    _run([py,\"-m\",\"pip\",\"install\",\"--upgrade\",\"--no-input\",\"--no-cache-dir\",*specs], timeout=1200)\n",
        "\n",
        "# -----------------------------\n",
        "# APT tools\n",
        "# -----------------------------\n",
        "needed_apt = []\n",
        "if which(\"ffmpeg\") is None or which(\"ffprobe\") is None:\n",
        "    needed_apt.append(\"ffmpeg\")\n",
        "for req in (\"fontconfig\",\"unzip\"):\n",
        "    needed_apt.append(req)\n",
        "# یک فونت سیستم پایه هم برای fallback\n",
        "needed_apt.append(\"fonts-dejavu-core\")\n",
        "# unique\n",
        "needed_apt = list(dict.fromkeys(needed_apt))\n",
        "_apt_install(needed_apt)\n",
        "\n",
        "for tool in (\"ffmpeg\",\"ffprobe\",\"fc-match\"):\n",
        "    if which(tool): _ok(f\"{tool} present\")\n",
        "    else: _err(f\"{tool} missing (install via apt-get)\")\n",
        "\n",
        "# -----------------------------\n",
        "# Python deps (حداقل‌های ضروری)\n",
        "# -----------------------------\n",
        "pip_specs = [\n",
        "    \"gradio>=5.49.0\",\n",
        "    \"Pillow>=11.3.0\",\n",
        "    \"fonttools>=4.60.0\",\n",
        "    \"ctranslate2>=4.5.0\",\n",
        "    \"faster-whisper>=1.0.3\",\n",
        "]\n",
        "_pip_install(pip_specs)\n",
        "\n",
        "def _try_import(name, attr=\"__version__\"):\n",
        "    try:\n",
        "        m = __import__(name)\n",
        "        ver = getattr(m, attr, None)\n",
        "        _ok(f\"{name} {ver if ver else ''} OK\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        _warn(f\"{name} import failed: {e}\")\n",
        "        return False\n",
        "\n",
        "_ = _try_import(\"PIL\")\n",
        "_ = _try_import(\"fontTools\")\n",
        "_ = _try_import(\"gradio\")\n",
        "_ = _try_import(\"ctranslate2\")\n",
        "_ = _try_import(\"faster_whisper\")\n",
        "\n",
        "# -----------------------------\n",
        "# Smoke tests (x264 / libass / NVENC)\n",
        "# -----------------------------\n",
        "def _probe_x264():\n",
        "    fps = 30\n",
        "    rc, _, err = _run([\n",
        "        \"ffmpeg\",\"-hide_banner\",\"-loglevel\",\"error\",\n",
        "        \"-f\",\"lavfi\",\"-t\",\"0.1\",\"-i\",f\"testsrc2=size=16x16:rate={fps}\",\n",
        "        \"-c:v\",\"libx264\",\"-preset\",\"fast\",\"-crf\",\"21\",\n",
        "        \"-pix_fmt\",\"yuv420p\",\"-profile:v\",\"high\",\"-bf\",\"2\",\"-g\",str(2*fps),\n",
        "        \"-colorspace\",\"bt709\",\"-color_primaries\",\"bt709\",\"-color_trc\",\"bt709\",\"-color_range\",\"tv\",\n",
        "        \"-f\",\"null\",\"-\"\n",
        "    ], timeout=6)\n",
        "    if rc==0: _ok(\"FFmpeg: libx264 OK\")\n",
        "    else: _err(f\"FFmpeg: libx264 probe failed: {err[:2000]}\")\n",
        "\n",
        "def _probe_ass():\n",
        "    ass_path = Path(tempfile.gettempdir())/\"ass_probe.ass\"\n",
        "    txt = (\n",
        "        \"[Script Info]\\nPlayResX:64\\nPlayResY:64\\nWrapStyle:2\\nScaledBorderAndShadow:yes\\nYCbCr Matrix: TV.709\\n\\n\"\n",
        "        \"[V4+ Styles]\\n\"\n",
        "        \"Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, \"\n",
        "        \"Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, \"\n",
        "        \"Alignment, MarginL, MarginR, MarginV, Encoding\\n\"\n",
        "        \"Style: Default,DejaVu Sans,18,&H00FFFFFF,&H00FFFFFF,&H00000000,&H00000000,0,0,0,0,100,100,0,0,1,1,0,7,10,10,10,0\\n\\n\"\n",
        "        \"[Events]\\nFormat: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text\\n\"\n",
        "        \"Dialogue: 0,0:00:00.00,0:00:00.20,Default,,0,0,0,,Hello\\\\NWorld\\n\"\n",
        "    )\n",
        "    ass_path.write_text(txt, encoding=\"utf-8\")\n",
        "    rc, _, err = _run([\n",
        "        \"ffmpeg\",\"-hide_banner\",\"-loglevel\",\"error\",\n",
        "        \"-f\",\"lavfi\",\"-t\",\"0.1\",\"-i\",\"color=size=16x16:rate=30:color=black\",\n",
        "        \"-vf\", f\"subtitles={ass_path}:charenc=UTF-8\",\n",
        "        \"-f\",\"null\",\"-\"\n",
        "    ], timeout=6)\n",
        "    if rc==0: _ok(\"FFmpeg: libass (subtitles) OK\")\n",
        "    else: _err(f\"FFmpeg: libass probe failed: {err[:2000]}\")\n",
        "\n",
        "def _probe_nvenc():\n",
        "    fps = 30\n",
        "    rc, _, _ = _run([\n",
        "        \"ffmpeg\",\"-hide_banner\",\"-loglevel\",\"error\",\n",
        "        \"-f\",\"lavfi\",\"-t\",\"0.1\",\"-i\",f\"testsrc2=size=16x16:rate={fps}\",\n",
        "        \"-c:v\",\"h264_nvenc\",\"-f\",\"null\",\"-\"\n",
        "    ], timeout=6)\n",
        "    print(f\"NVENC_AVAILABLE (detected): {rc==0}\")\n",
        "\n",
        "_probe_x264()\n",
        "_probe_ass()\n",
        "_probe_nvenc()\n",
        "\n",
        "# -----------------------------\n",
        "# Font install: Inter (static TTFs)\n",
        "# -----------------------------\n",
        "HOME = Path.home()\n",
        "FONTS_A = HOME/\".local/share/fonts/Inter\"\n",
        "FONTS_B = HOME/\".fonts/Inter\"  # بعضی بیلدها فقط این مسیر را اسکن می‌کنند\n",
        "for d in (FONTS_A, FONTS_B):\n",
        "    d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# لیست وزن‌های استاندارد که برای رندر کپشن کافی و شیک‌اند\n",
        "weights = [\"Regular\",\"Medium\",\"SemiBold\",\"Bold\",\"ExtraBold\",\"Black\"]\n",
        "static_names = [f\"Inter-{w}.ttf\" for w in weights]\n",
        "\n",
        "def _download(url: str, dst: Path) -> bool:\n",
        "    if dst.exists() and dst.stat().st_size > 1_000:\n",
        "        return True\n",
        "    rc, _, err = _run([\"curl\",\"-L\",\"-f\",\"-sS\",\"-o\",str(dst), url], timeout=60)\n",
        "    return rc == 0 and dst.exists() and dst.stat().st_size > 1_000\n",
        "\n",
        "def _copy_to_both(src: Path):\n",
        "    try:\n",
        "        shutil.copy2(src, FONTS_A/src.name)\n",
        "    except Exception: pass\n",
        "    try:\n",
        "        shutil.copy2(src, FONTS_B/src.name)\n",
        "    except Exception: pass\n",
        "\n",
        "def install_inter_static() -> bool:\n",
        "    ok_count = 0\n",
        "    # Source A: Google Fonts repo (raw static TTFs)\n",
        "    baseA = \"https://raw.githubusercontent.com/google/fonts/main/ofl/inter/static/\"\n",
        "    for name in static_names:\n",
        "        for target_dir in (FONTS_A, FONTS_B):\n",
        "            dst = target_dir/name\n",
        "            if dst.exists() and dst.stat().st_size > 1_000:\n",
        "                ok_count += 1\n",
        "                continue\n",
        "            url = baseA + name\n",
        "            if _download(url, dst):\n",
        "                ok_count += 1\n",
        "    if ok_count >= 4:\n",
        "        return True\n",
        "\n",
        "    # Source B: gh mirror path (alternative raw endpoint)\n",
        "    baseB = \"https://github.com/google/fonts/raw/main/ofl/inter/static/\"\n",
        "    for name in static_names:\n",
        "        for target_dir in (FONTS_A, FONTS_B):\n",
        "            dst = target_dir/name\n",
        "            if dst.exists() and dst.stat().st_size > 1_000:\n",
        "                continue\n",
        "            url = baseB + name\n",
        "            if _download(url, dst):\n",
        "                ok_count += 1\n",
        "    if ok_count >= 4:\n",
        "        return True\n",
        "\n",
        "    # Source C: Official rsms release zip (v4.1), extract TTFs\n",
        "    zip_url = \"https://github.com/rsms/inter/releases/download/v4.1/Inter-4.1.zip\"\n",
        "    tmpdir = Path(tempfile.mkdtemp(prefix=\"inter_dl_\"))\n",
        "    zpath = tmpdir/\"Inter-4.1.zip\"\n",
        "    if _download(zip_url, zpath):\n",
        "        rc, _, err = _run([\"unzip\",\"-o\",\"-qq\",str(zpath),\"-d\",str(tmpdir)], timeout=120)\n",
        "        if rc == 0:\n",
        "            for ttf in tmpdir.rglob(\"*.ttf\"):\n",
        "                # فقط Inter_* را کپی کن\n",
        "                if \"Inter\" in ttf.name:\n",
        "                    _copy_to_both(ttf)\n",
        "    # شمارش نهایی\n",
        "    have = [p for p in (FONTS_A.glob(\"Inter-*.ttf\")) if p.stat().st_size>1_000]\n",
        "    have += [p for p in (FONTS_B.glob(\"Inter-*.ttf\")) if p.stat().st_size>1_000]\n",
        "    return len({p.name for p in have}) >= 4\n",
        "\n",
        "inter_ok = install_inter_static()\n",
        "if inter_ok:\n",
        "    _ok(\"Inter static TTFs installed\")\n",
        "else:\n",
        "    _warn(\"Inter font download failed (variable + static). Using system fallbacks only.\")\n",
        "\n",
        "# Refresh fontconfig cache\n",
        "_run([\"fc-cache\",\"-f\",\"-v\"], timeout=60)\n",
        "\n",
        "# Verify default font availability\n",
        "rc, out, err = _run([\"fc-match\",\"-f\",\"%{family}\\n\",\"Inter,DejaVu Sans,Arial,Helvetica,sans\"], timeout=5)\n",
        "if rc==0 and out.strip():\n",
        "    fam = out.splitlines()[0]\n",
        "    _ok(f\"Font available: {fam}\")\n",
        "else:\n",
        "    _warn(f\"fontconfig could not resolve a font: {err[:2000]}\")\n",
        "\n",
        "print(\"\\nPreflight complete. This cell installed and verified runtime prerequisites.\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "PHUo90AFxwgu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "627c0e73-99e0-439c-e3f7-4e9db8a3d1c2"
      },
      "id": "PHUo90AFxwgu",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ ffmpeg present\n",
            "✅ ffprobe present\n",
            "✅ fc-match present\n",
            "✅ PIL 11.3.0 OK\n",
            "✅ fontTools 4.60.1 OK\n",
            "✅ gradio 5.49.1 OK\n",
            "✅ ctranslate2 4.6.0 OK\n",
            "✅ faster_whisper 1.2.1 OK\n",
            "✅ FFmpeg: libx264 OK\n",
            "✅ FFmpeg: libass (subtitles) OK\n",
            "NVENC_AVAILABLE (detected): False\n",
            "✅ Inter static TTFs installed\n",
            "✅ Font available: Inter\n",
            "\n",
            "Preflight complete. This cell installed and verified runtime prerequisites.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 2) Roots & Cache — Refactored, Deterministic, Colab-aware\n",
        "# Define Drive/Work roots, JSON cache, and ensure folders.\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import json\n",
        "import os\n",
        "from pathlib import Path\n",
        "from typing import Any, Dict, List, Tuple\n",
        "\n",
        "# --------------------------------------------------------------------------------------\n",
        "# Changelog (kept for provenance; not used at runtime)\n",
        "# --------------------------------------------------------------------------------------\n",
        "CHANGELOG: List[str] = [\n",
        "    \"vFINAL: Hidden cells + short titles\",\n",
        "    \"Cache-safe ASS burn + moving pill highlight\",\n",
        "    \"NVENC with clean x264 fallback\",\n",
        "    \"Strict assets root: MyDrive/VideoRobot/Assets\",\n",
        "    \"UI-first; heavy steps on demand\",\n",
        "]\n",
        "\n",
        "# --------------------------------------------------------------------------------------\n",
        "# Runtime / environment detection\n",
        "# --------------------------------------------------------------------------------------\n",
        "\n",
        "def _in_colab() -> bool:\n",
        "    \"\"\"\n",
        "    Cheap Colab detection that tolerates non-notebook environments.\n",
        "    Signals: COLAB_RELEASE_TAG, COLAB_GPU, PATH containing 'COLAB'.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        env = os.environ.copy()\n",
        "        if \"COLAB_RELEASE_TAG\" in env or \"COLAB_GPU\" in env:\n",
        "            return True\n",
        "        return \"COLAB\" in env.get(\"PATH\", \"\")\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "\n",
        "def _mount_drive(force: bool = False) -> None:\n",
        "    \"\"\"\n",
        "    Mount Google Drive inside Colab. No-op elsewhere.\n",
        "    Failures are intentionally silent to avoid breaking local runs.\n",
        "    \"\"\"\n",
        "    if not _in_colab():\n",
        "        return\n",
        "    try:\n",
        "        from google.colab import drive  # type: ignore\n",
        "        drive.mount(\"/content/drive\", force_remount=bool(force))\n",
        "    except Exception:\n",
        "        pass  # degrade gracefully to local paths\n",
        "\n",
        "# --------------------------------------------------------------------------------------\n",
        "# Path selection helpers\n",
        "# --------------------------------------------------------------------------------------\n",
        "\n",
        "def _first_existing(paths: List[Path]) -> Tuple[bool, Path]:\n",
        "    \"\"\"\n",
        "    Return (found, path) for the first existing candidate; if none, (False, last candidate or '.').\n",
        "    \"\"\"\n",
        "    last = paths[-1] if paths else Path(\".\")\n",
        "    for p in paths:\n",
        "        try:\n",
        "            if p.exists():\n",
        "                return True, p\n",
        "        except Exception:\n",
        "            continue\n",
        "        last = p\n",
        "    return False, last\n",
        "\n",
        "\n",
        "def _pick_drive_root() -> Path:\n",
        "    \"\"\"\n",
        "    Resolve the Drive root:\n",
        "      • Colab: prefer /content/drive/MyDrive/VideoRobot or 'My Drive' variant.\n",
        "      • Local: $VR_DRIVE_ROOT or ~/VideoRobot.\n",
        "    Ensures the returned directory exists (creates for local).\n",
        "    \"\"\"\n",
        "    if _in_colab():\n",
        "        _mount_drive(False)\n",
        "        candidates = [\n",
        "            Path(\"/content/drive/MyDrive/VideoRobot\"),\n",
        "            Path(\"/content/drive/My Drive/VideoRobot\"),\n",
        "        ]\n",
        "        found, p = _first_existing(candidates)\n",
        "        if not found:\n",
        "            _mount_drive(True)  # one retry with forced remount\n",
        "            found, p = _first_existing(candidates)\n",
        "        if not found:\n",
        "            raise RuntimeError(\"Drive not mounted or '/content/drive/.../VideoRobot' missing in Colab.\")\n",
        "        return p\n",
        "\n",
        "    env_root = os.environ.copy().get(\"VR_DRIVE_ROOT\")\n",
        "    root = Path(env_root).expanduser().absolute() if env_root else (Path.home() / \"VideoRobot\")\n",
        "    root.mkdir(parents=True, exist_ok=True)\n",
        "    return root\n",
        "\n",
        "\n",
        "def _pick_work_root() -> Path:\n",
        "    \"\"\"\n",
        "    Resolve the work/cache root:\n",
        "      • Colab: /content/_studio_cache\n",
        "      • Local: $VR_WORK_ROOT or ~/.videorobot_cache\n",
        "    Ensures the returned directory exists.\n",
        "    \"\"\"\n",
        "    if _in_colab():\n",
        "        wr = Path(\"/content/_studio_cache\").absolute()\n",
        "        wr.mkdir(parents=True, exist_ok=True)\n",
        "        return wr\n",
        "\n",
        "    env_wr = os.environ.copy().get(\"VR_WORK_ROOT\")\n",
        "    wr = Path(env_wr).expanduser().absolute() if env_wr else (Path.home() / \".videorobot_cache\")\n",
        "    wr.mkdir(parents=True, exist_ok=True)\n",
        "    return wr\n",
        "\n",
        "# --------------------------------------------------------------------------------------\n",
        "# Drive/Work tree (materialize eagerly for downstream cells)\n",
        "# --------------------------------------------------------------------------------------\n",
        "\n",
        "DRIVE_ROOT: Path = _pick_drive_root().absolute()\n",
        "ASSETS_ROOT: Path = (DRIVE_ROOT / \"Assets\"); ASSETS_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "OUTPUT_ROOT: Path = (DRIVE_ROOT / \"Output\"); OUTPUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "WORK_ROOT: Path = _pick_work_root()\n",
        "WORK_CACHE: Path = WORK_ROOT / \"cache\";  WORK_CACHE.mkdir(parents=True, exist_ok=True)\n",
        "WORK_ASSETS: Path = WORK_ROOT / \"assets\"; WORK_ASSETS.mkdir(parents=True, exist_ok=True)\n",
        "WORK_META: Path = WORK_ROOT / \"meta.json\"\n",
        "\n",
        "# --------------------------------------------------------------------------------------\n",
        "# JSON cache helpers\n",
        "# --------------------------------------------------------------------------------------\n",
        "\n",
        "def _json_dump(path: Path, obj: Any) -> None:\n",
        "    \"\"\"\n",
        "    Atomic JSON write: write to <path>.tmp then replace.\n",
        "    Errors are swallowed to keep telemetry non-fatal.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        path.parent.mkdir(parents=True, exist_ok=True)\n",
        "        tmp = path.with_suffix(path.suffix + \".tmp\")\n",
        "        tmp.write_text(json.dumps(obj, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
        "        tmp.replace(path)\n",
        "    except Exception:\n",
        "        pass  # best-effort cache\n",
        "\n",
        "\n",
        "def _json_load(path: Path, default: Any) -> Any:\n",
        "    \"\"\"\n",
        "    Safe JSON load:\n",
        "      • Returns 'default' for any error (missing, parse, permissions).\n",
        "      • Leaves corrupt file untouched (non-destructive).\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if not path.exists():\n",
        "            return default\n",
        "        return json.loads(path.read_text(encoding=\"utf-8\"))\n",
        "    except Exception:\n",
        "        return default\n",
        "\n",
        "# Global metadata cache (shared across cells)\n",
        "META: Dict[str, Any] = _json_load(WORK_META, {})\n",
        "\n",
        "# --------------------------------------------------------------------------------------\n",
        "# Asset roots hook and tree ensure\n",
        "# --------------------------------------------------------------------------------------\n",
        "\n",
        "def DRIVE_ASSETS_FOLDERS() -> List[Path]:\n",
        "    \"\"\"\n",
        "    Returns Drive asset roots to be scanned by staging layers.\n",
        "    Extendable without changing callers.\n",
        "    \"\"\"\n",
        "    return [ASSETS_ROOT]\n",
        "\n",
        "\n",
        "def ensure_drive_tree(root: Path) -> None:\n",
        "    \"\"\"\n",
        "    Ensure a standard folder layout under 'root' (idempotent).\n",
        "    Creates: Assets, Output, _tmp, Music, Figures.\n",
        "    \"\"\"\n",
        "    for sub in (\"Assets\", \"Output\", \"_tmp\", \"Music\", \"Figures\"):\n",
        "        try:\n",
        "            (root / sub).mkdir(parents=True, exist_ok=True)\n",
        "        except Exception:\n",
        "            pass  # directory creation should never kill the session\n",
        "\n",
        "# Ensure the expected subfolders under DRIVE_ROOT\n",
        "ensure_drive_tree(DRIVE_ROOT)\n",
        "\n",
        "print(f\"ASSETS ROOT = {ASSETS_ROOT}\")\n",
        "print(f\"WORK ROOT   = {WORK_ROOT}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "syqxfbi3xy50",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "493f8b7a-0a60-4f64-93e2-411f491353b3"
      },
      "id": "syqxfbi3xy50",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "ASSETS ROOT = /content/drive/MyDrive/VideoRobot/Assets\n",
            "WORK ROOT   = /content/_studio_cache\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "b03c1602",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b03c1602",
        "outputId": "bed2353f-6e14-4e61-b8c3-9349f2aebb78",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVENC_AVAILABLE: False\n"
          ]
        }
      ],
      "source": [
        "# @title 3) Core Utils + NVENC Detect — Refactored, Clean, Deterministic\n",
        "# Process helpers, escaping, hashing, probe, and NVENC detection.\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import hashlib\n",
        "import os\n",
        "import re\n",
        "import shlex\n",
        "import subprocess as sp\n",
        "from dataclasses import dataclass\n",
        "from functools import lru_cache\n",
        "from pathlib import Path\n",
        "from typing import Dict, Iterable, Optional, Tuple, Union\n",
        "\n",
        "__all__ = [\n",
        "    \"_RunResult\", \"_env\", \"_run\",\n",
        "    \"ffesc\", \"sha1_file\",\n",
        "    \"bgr_hex\", \"ass_timestamp\",\n",
        "    \"probe_image_wh\",\n",
        "    \"detect_nvenc\", \"NVENC_AVAILABLE\",\n",
        "]\n",
        "\n",
        "# ============================================================\n",
        "# Subprocess runner\n",
        "# ============================================================\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class _RunResult:\n",
        "    \"\"\"Minimal, predictable result container for subprocess calls.\"\"\"\n",
        "    returncode: int\n",
        "    stdout: str\n",
        "    stderr: str\n",
        "\n",
        "\n",
        "def _env(extra: Optional[Dict[str, str]] = None) -> Dict[str, str]:\n",
        "    \"\"\"\n",
        "    Return a copy of the current environment with optional overrides.\n",
        "    Never mutates os.environ.\n",
        "    \"\"\"\n",
        "    e = os.environ.copy()\n",
        "    if extra:\n",
        "        e.update(extra)\n",
        "    return e\n",
        "\n",
        "\n",
        "def _run(\n",
        "    cmd: Union[str, Iterable[Union[str, Path]]],\n",
        "    check: bool = True,\n",
        "    capture: bool = True,\n",
        "    env: Optional[Dict[str, str]] = None,\n",
        "    cwd: Optional[Path] = None,\n",
        "    timeout: Optional[float] = None,\n",
        ") -> _RunResult:\n",
        "    \"\"\"\n",
        "    Safe subprocess runner with sane defaults:\n",
        "      - cmd may be a string (shell-split) or an iterable of args/Paths.\n",
        "      - capture toggles stdout/stderr pipes.\n",
        "      - raises RuntimeError on non-zero exit when check=True.\n",
        "      - provides clear timeout and not-found errors.\n",
        "    \"\"\"\n",
        "    args = shlex.split(cmd) if isinstance(cmd, str) else [str(a) for a in cmd]\n",
        "    try:\n",
        "        p = sp.run(\n",
        "            args,\n",
        "            stdout=(sp.PIPE if capture else None),\n",
        "            stderr=(sp.PIPE if capture else None),\n",
        "            text=True,\n",
        "            env=(env or _env()),\n",
        "            cwd=(str(cwd) if cwd else None),\n",
        "            timeout=timeout,\n",
        "        )\n",
        "    except sp.TimeoutExpired as te:\n",
        "        raise RuntimeError(f\"Command timeout: {' '.join(args)}\") from te\n",
        "    except FileNotFoundError as fe:\n",
        "        missing = args[0] if args else \"<empty>\"\n",
        "        raise RuntimeError(f\"Command not found: {missing}\") from fe\n",
        "\n",
        "    rr = _RunResult(p.returncode, p.stdout or \"\", p.stderr or \"\")\n",
        "    if check and rr.returncode != 0:\n",
        "        tail = (rr.stderr or rr.stdout or \"\").strip()\n",
        "        raise RuntimeError(tail or f\"Command failed: {' '.join(args)}\")\n",
        "    return rr\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# FFmpeg escaping\n",
        "# ============================================================\n",
        "\n",
        "def ffesc(s: str) -> str:\n",
        "    r\"\"\"\n",
        "    Escape string for ffmpeg filter/option contexts.\n",
        "    Escapes: \\  :  '  ,  [ ]  ;  %  ( )  =\n",
        "    \"\"\"\n",
        "    r_ = str(s).replace(\"\\\\\", \"\\\\\\\\\")\n",
        "    for ch in (\":\", \"'\", \",\", \"[\", \"]\", \";\", \"%\", \"(\", \")\", \"=\"):\n",
        "        r_ = r_.replace(ch, \"\\\\\" + ch)\n",
        "    return r_\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Hashing\n",
        "# ============================================================\n",
        "\n",
        "def sha1_file(p: Path, chunk: int = 1 << 20) -> str:\n",
        "    \"\"\"\n",
        "    SHA1 over file content + mtime_ns + size.\n",
        "    This keeps cache keys stable per artifact while invalidating on edits.\n",
        "    \"\"\"\n",
        "    pp = Path(p)\n",
        "    if not pp.is_file():\n",
        "        raise FileNotFoundError(f\"sha1_file: missing file: {pp}\")\n",
        "    h = hashlib.sha1()\n",
        "    with pp.open(\"rb\") as f:\n",
        "        for b in iter(lambda: f.read(chunk), b\"\"):\n",
        "            h.update(b)\n",
        "    st = pp.stat()\n",
        "    h.update(str(st.st_mtime_ns).encode(\"utf-8\"))\n",
        "    h.update(str(st.st_size).encode(\"utf-8\"))\n",
        "    return h.hexdigest()\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Color helpers\n",
        "# ============================================================\n",
        "\n",
        "_HEX_DIGITS = set(\"0123456789abcdefABCDEF\")\n",
        "\n",
        "def _normalize_rgb_hex(rgb_hex: str) -> str:\n",
        "    \"\"\"\n",
        "    Normalize '#RGB' or '#RRGGBB' (or bare) to 6-hex uppercase 'RRGGBB'.\n",
        "    Returns 'FFFFFF' on invalid input.\n",
        "    \"\"\"\n",
        "    hx = (rgb_hex or \"\").strip().lstrip(\"#\")\n",
        "    if len(hx) == 3 and all(c in _HEX_DIGITS for c in hx):\n",
        "        hx = \"\".join(c * 2 for c in hx)\n",
        "    if len(hx) != 6 or any(c not in _HEX_DIGITS for c in hx):\n",
        "        return \"FFFFFF\"\n",
        "    return hx.upper()\n",
        "\n",
        "\n",
        "def bgr_hex(rgb_hex: str) -> str:\n",
        "    \"\"\"\n",
        "    Convert CSS-like hex to ASS BGR (without &H and alpha).\n",
        "    Example: '#A1B2C3' -> 'C3B2A1'\n",
        "    \"\"\"\n",
        "    hx = _normalize_rgb_hex(rgb_hex)\n",
        "    return f\"{hx[4:6]}{hx[2:4]}{hx[0:2]}\"\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# ASS helpers\n",
        "# ============================================================\n",
        "\n",
        "def ass_timestamp(seconds: float) -> str:\n",
        "    \"\"\"\n",
        "    Format seconds -> h:mm:ss.cc (centiseconds) per ASS spec.\n",
        "    \"\"\"\n",
        "    cs_total = int(round(max(0.0, float(seconds)) * 100.0))\n",
        "    h, rem = divmod(cs_total, 360000)\n",
        "    m, rem = divmod(rem, 6000)\n",
        "    s, cs = divmod(rem, 100)\n",
        "    return f\"{int(h)}:{int(m):02d}:{int(s):02d}.{int(cs):02d}\"\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Probing helpers\n",
        "# ============================================================\n",
        "\n",
        "def _probe_wh_with_ffprobe(p: Path) -> Tuple[int, int]:\n",
        "    \"\"\"\n",
        "    Try to probe width/height using ffprobe for videos and images.\n",
        "    Returns (w, h) or (0, 0) on failure.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        r = _run(\n",
        "            [\n",
        "                \"ffprobe\",\n",
        "                \"-v\", \"error\",\n",
        "                \"-select_streams\", \"v:0\",\n",
        "                \"-show_entries\", \"stream=width,height\",\n",
        "                \"-of\", \"csv=s=x:p=0\",\n",
        "                str(p),\n",
        "            ],\n",
        "            check=False,\n",
        "            timeout=5.0,\n",
        "        ).stdout.strip()\n",
        "        if \"x\" in r:\n",
        "            w, h = r.split(\"x\", 1)\n",
        "            return int(w), int(h)\n",
        "    except Exception:\n",
        "        pass\n",
        "    return 0, 0\n",
        "\n",
        "\n",
        "def _probe_wh_with_pil(p: Path) -> Tuple[int, int]:\n",
        "    \"\"\"\n",
        "    Fallback probing via PIL for image files.\n",
        "    Returns (w, h) or (0, 0) on failure.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        from PIL import Image  # type: ignore\n",
        "        with Image.open(str(p)) as im:\n",
        "            w, h = im.size\n",
        "            return int(w), int(h)\n",
        "    except Exception:\n",
        "        return 0, 0\n",
        "\n",
        "\n",
        "def probe_image_wh(p: Path) -> Tuple[int, int]:\n",
        "    \"\"\"\n",
        "    Probe width/height via ffprobe (video or image) with PIL fallback.\n",
        "    Returns (0, 0) on failure or invalid input.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if not p or not Path(p).exists():\n",
        "            return 0, 0\n",
        "    except Exception:\n",
        "        return 0, 0\n",
        "    w, h = _probe_wh_with_ffprobe(Path(p))\n",
        "    if w > 0 and h > 0:\n",
        "        return w, h\n",
        "    return _probe_wh_with_pil(Path(p))\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# NVENC detection (cached for speed)\n",
        "# ============================================================\n",
        "\n",
        "def _preflight_tools() -> None:\n",
        "    \"\"\"Assert ffmpeg and ffprobe availability with actionable errors.\"\"\"\n",
        "    missing = []\n",
        "    for exe in (\"ffmpeg\", \"ffprobe\"):\n",
        "        try:\n",
        "            _run([exe, \"-version\"], check=False, timeout=3.0)\n",
        "        except Exception:\n",
        "            missing.append(exe)\n",
        "    if missing:\n",
        "        raise RuntimeError(\n",
        "            \"WHAT: PATH tools check\\n\"\n",
        "            f\"WHY: Missing required executable(s): {', '.join(missing)}\\n\"\n",
        "            \"HOW_TO_FIX: Install the missing tools and ensure they are on PATH, then re-run this cell.\"\n",
        "        )\n",
        "\n",
        "@lru_cache(maxsize=1)\n",
        "def _ffmpeg_encoders_text() -> str:\n",
        "    \"\"\"Cached raw encoder listing from ffmpeg.\"\"\"\n",
        "    try:\n",
        "        return _run([\"ffmpeg\", \"-hide_banner\", \"-encoders\"], check=False, timeout=5.0).stdout or \"\"\n",
        "    except Exception:\n",
        "        return \"\"\n",
        "\n",
        "\n",
        "@lru_cache(maxsize=1)\n",
        "def _ffmpeg_hwaccels_text() -> str:\n",
        "    \"\"\"Cached raw hwaccel listing from ffmpeg.\"\"\"\n",
        "    try:\n",
        "        return _run([\"ffmpeg\", \"-hide_banner\", \"-hwaccels\"], check=False, timeout=5.0).stdout or \"\"\n",
        "    except Exception:\n",
        "        return \"\"\n",
        "\n",
        "\n",
        "def _ffmpeg_has_encoder(name: str) -> bool:\n",
        "    \"\"\"Check if ffmpeg lists a given encoder by name token.\"\"\"\n",
        "    out = _ffmpeg_encoders_text()\n",
        "    return bool(re.search(rf\"(?m)^\\s*[A-Z\\.]{{6}}\\s+{re.escape(name)}\\b\", out))\n",
        "\n",
        "\n",
        "def _has_nvidia_smi() -> bool:\n",
        "    \"\"\"Quick CUDA sanity check via nvidia-smi.\"\"\"\n",
        "    try:\n",
        "        r = _run([\"nvidia-smi\"], check=False, timeout=2.0)\n",
        "        return r.returncode == 0\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "\n",
        "def _ffmpeg_has_hwaccel(tag: str) -> bool:\n",
        "    \"\"\"See whether ffmpeg reports a given hwaccel (e.g., 'cuda').\"\"\"\n",
        "    out = _ffmpeg_hwaccels_text()\n",
        "    return tag.lower() in out.lower()\n",
        "\n",
        "\n",
        "@lru_cache(maxsize=1)\n",
        "def _nvenc_smoke_test() -> bool:\n",
        "    \"\"\"\n",
        "    Try a tiny encode with h264_nvenc; True only if ffmpeg succeeds with zero errors.\n",
        "    Enforces SCA: bt709 tags, yuv420p, profile=high, bf∈{2,3}, gop=2*fps.\n",
        "    \"\"\"\n",
        "    fps = 30  # normalized integer fps\n",
        "    gop = int(round(2 * fps))\n",
        "    args = [\n",
        "        \"ffmpeg\", \"-hide_banner\", \"-loglevel\", \"error\", \"-nostdin\",\n",
        "        \"-f\", \"lavfi\", \"-t\", \"0.1\", \"-i\", f\"color=size=16x16:rate={fps}:color=black\",\n",
        "        \"-c:v\", \"h264_nvenc\",\n",
        "        \"-pix_fmt\", \"yuv420p\",\n",
        "        \"-profile:v\", \"high\",\n",
        "        \"-bf\", \"2\",\n",
        "        \"-g\", str(gop),\n",
        "        \"-colorspace\", \"bt709\", \"-color_primaries\", \"bt709\", \"-color_trc\", \"bt709\", \"-color_range\", \"tv\",\n",
        "        \"-f\", \"null\", \"-\"\n",
        "    ]\n",
        "    rr = _run(args, check=False, timeout=3.0)\n",
        "    return rr.returncode == 0 and (rr.stderr.strip() == \"\")\n",
        "\n",
        "\n",
        "def _nvenc_available() -> bool:\n",
        "    \"\"\"\n",
        "    Encoder is listed, CUDA stack is visible, AND a real encode succeeds.\n",
        "    Eliminates false positives like 'Cannot load libcuda.so.1'.\n",
        "    \"\"\"\n",
        "    if not _ffmpeg_has_encoder(\"h264_nvenc\"):\n",
        "        return False\n",
        "    if not (_has_nvidia_smi() or _ffmpeg_has_hwaccel(\"cuda\")):\n",
        "        return False\n",
        "    return _nvenc_smoke_test()\n",
        "\n",
        "\n",
        "def detect_nvenc() -> bool:\n",
        "    \"\"\"Public entry point for NVENC capability check.\"\"\"\n",
        "    return _nvenc_available()\n",
        "\n",
        "\n",
        "# Preflight before evaluation to provide deterministic, actionable errors.\n",
        "_preflight_tools()\n",
        "\n",
        "NVENC_AVAILABLE: bool = detect_nvenc()\n",
        "print(\"NVENC_AVAILABLE:\", NVENC_AVAILABLE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "3d58f251",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3d58f251",
        "outputId": "b18d8d53-bb4c-4a8e-b219-e430f12e420d",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Font manager ready.\n"
          ]
        }
      ],
      "source": [
        "# @title 4) Font Manager — Refactored, TTC-aware, ASS-friendly\n",
        "# Resolve fonts from Assets to ~/.fonts and cache PIL fonts with robust fallbacks.\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import hashlib\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import subprocess\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "from typing import Dict, Iterable, List, Optional, Tuple\n",
        "\n",
        "# Hard fail with remediation if dependencies are missing (no installs here).\n",
        "try:\n",
        "    from PIL import ImageFont  # type: ignore\n",
        "except Exception as e:\n",
        "    raise RuntimeError(\"Missing dependency: Pillow (PIL). Install with: pip install Pillow>=11.3.0\") from e\n",
        "\n",
        "try:\n",
        "    from fontTools.ttLib import TTCollection, TTFont  # type: ignore\n",
        "except Exception as e:\n",
        "    raise RuntimeError(\"Missing dependency: fonttools. Install with: pip install fonttools>=4.54.1\") from e\n",
        "\n",
        "# Use shared sha1_file from Core Utils; do not re-declare hashing here.\n",
        "try:\n",
        "    _HASH_FUNC = sha1_file  # type: ignore[name-defined]\n",
        "except Exception as e:\n",
        "    raise RuntimeError(\"Dependency missing: sha1_file not found. Execute the Core Utils cell before Font Manager.\") from e\n",
        "\n",
        "__all__ = [\n",
        "    \"FontInfo\", \"PREFERRED_FAMILIES\",\n",
        "    \"FontManager\", \"FONTM\",\n",
        "]\n",
        "\n",
        "# --------------------------------------------------------------------------------------\n",
        "# Public data model\n",
        "# --------------------------------------------------------------------------------------\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class FontInfo:\n",
        "    \"\"\"Resolved font choice for both ASS and PIL.\"\"\"\n",
        "    family: str\n",
        "    subfam: str\n",
        "    path: Optional[Path]\n",
        "\n",
        "\n",
        "# --------------------------------------------------------------------------------------\n",
        "# Utility helpers (pure functions)\n",
        "# --------------------------------------------------------------------------------------\n",
        "\n",
        "_ASS_ENV_KEY = \"ASS_FONT_DIR\"\n",
        "_USER_FONTS_DIR = Path(\"~/.fonts\").expanduser()\n",
        "_ASS_FONT_DIR_COMPUTED: Optional[str] = None  # computed for callers that wish to pass via env\n",
        "\n",
        "# Professional fallback chain (order matters)\n",
        "PREFERRED_FAMILIES: List[str] = [\n",
        "    \"Inter\",\n",
        "    \"Source Sans 3\",\n",
        "    \"IBM Plex Sans\",\n",
        "    \"Roboto\",\n",
        "    \"Noto Sans\",\n",
        "    \"DejaVu Sans\",\n",
        "]\n",
        "\n",
        "\n",
        "def _which(cmd: str) -> bool:\n",
        "    \"\"\"Return True if command exists on PATH.\"\"\"\n",
        "    try:\n",
        "        from shutil import which\n",
        "        return which(cmd) is not None\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "\n",
        "def _run_cmd(args: List[str], *, capture: bool = True) -> subprocess.CompletedProcess:\n",
        "    \"\"\"\n",
        "    Run a command safely. If a project-provided `_run` exists, prefer it.\n",
        "    Falls back to `subprocess.run`. Never raises; caller inspects returncode.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        return _run(args, check=False, capture=capture)  # type: ignore[name-defined]\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    stdout = subprocess.PIPE if capture else None\n",
        "    stderr = subprocess.PIPE if capture else None\n",
        "    try:\n",
        "        return subprocess.run(args, check=False, text=True, stdout=stdout, stderr=stderr)\n",
        "    except Exception as e:\n",
        "        cp = subprocess.CompletedProcess(args=args, returncode=1)\n",
        "        cp.stdout = \"\"  # type: ignore[attr-defined]\n",
        "        cp.stderr = str(e)  # type: ignore[attr-defined]\n",
        "        return cp\n",
        "\n",
        "\n",
        "def _atomic_copy(src: Path, dst: Path) -> None:\n",
        "    \"\"\"Atomic copy to dst via a temporary sibling file.\"\"\"\n",
        "    dst = Path(dst)\n",
        "    src = Path(src)\n",
        "    dst.parent.mkdir(parents=True, exist_ok=True)\n",
        "    tmp = dst.with_suffix(dst.suffix + \".tmpcopy\")\n",
        "    try:\n",
        "        if tmp.exists():\n",
        "            try:\n",
        "                tmp.unlink()\n",
        "            except Exception:\n",
        "                pass\n",
        "        shutil.copy2(src, tmp)\n",
        "        tmp.replace(dst)\n",
        "    finally:\n",
        "        try:\n",
        "            if tmp.exists():\n",
        "                tmp.unlink()\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "\n",
        "def _dedup_existing(paths: Iterable[Path]) -> List[Path]:\n",
        "    \"\"\"Resolve, filter to existing unique paths; preserve order.\"\"\"\n",
        "    out: List[Path] = []\n",
        "    seen: set[Path] = set()\n",
        "    for p in paths:\n",
        "        try:\n",
        "            rp = Path(p).resolve()\n",
        "        except Exception:\n",
        "            continue\n",
        "        if rp.exists() and rp not in seen:\n",
        "            out.append(rp)\n",
        "            seen.add(rp)\n",
        "    return out\n",
        "\n",
        "\n",
        "def _normalize_subfamily(name: str) -> str:\n",
        "    \"\"\"Normalize subfamily tags to a small, predictable set.\"\"\"\n",
        "    s = (name or \"\").strip().lower()\n",
        "    mapping = {\n",
        "        \"regular\": \"regular\",\n",
        "        \"book\": \"regular\",\n",
        "        \"roman\": \"regular\",\n",
        "        \"normal\": \"regular\",\n",
        "        \"plain\": \"regular\",\n",
        "        \"bold\": \"bold\",\n",
        "        \"italic\": \"italic\",\n",
        "        \"oblique\": \"italic\",\n",
        "        \"bold italic\": \"bold italic\",\n",
        "        \"italic bold\": \"bold italic\",\n",
        "        \"black\": \"black\",\n",
        "        \"heavy\": \"black\",\n",
        "        \"light\": \"light\",\n",
        "        \"thin\": \"thin\",\n",
        "        \"medium\": \"medium\",\n",
        "        \"semibold\": \"semibold\",\n",
        "        \"semi bold\": \"semibold\",\n",
        "        \"extra bold\": \"extrabold\",\n",
        "        \"extrabold\": \"extrabold\",\n",
        "    }\n",
        "    return mapping.get(s, s)\n",
        "\n",
        "\n",
        "def _read_name_table(tt: TTFont) -> Tuple[str, str, str]:\n",
        "    \"\"\"\n",
        "    Extract family, subfamily, and PostScript name from a TTFont.\n",
        "    Prefers typographic family/subfamily (nameID 16/17) when present.\n",
        "    Returns ('', '', '') on failure.\n",
        "    \"\"\"\n",
        "    fam = sub = ps = \"\"\n",
        "    try:\n",
        "        n = tt[\"name\"]\n",
        "        f16 = next((r for r in n.names if r.nameID == 16), None)\n",
        "        f1 = next((r for r in n.names if r.nameID == 1), None)\n",
        "        f17 = next((r for r in n.names if r.nameID == 17), None)\n",
        "        f2 = next((r for r in n.names if r.nameID == 2), None)\n",
        "        f6 = next((r for r in n.names if r.nameID == 6), None)\n",
        "        fam = (f16 or f1).toUnicode() if (f16 or f1) else \"\"\n",
        "        sub = (f17 or f2).toUnicode() if (f17 or f2) else \"\"\n",
        "        ps = f6.toUnicode() if f6 else \"\"\n",
        "    except Exception:\n",
        "        pass\n",
        "    return (fam or \"\").strip(), (sub or \"\").strip(), (ps or \"\").strip()\n",
        "\n",
        "\n",
        "def _read_font_meta(path: Path) -> Tuple[str, str]:\n",
        "    \"\"\"\n",
        "    Extract (family, subfamily) from a font file.\n",
        "    TTC/OTC collections: favor Regular/Book face when available.\n",
        "    \"\"\"\n",
        "    fam, sub = Path(path).stem, \"\"\n",
        "    try:\n",
        "        if Path(path).suffix.lower() in (\".ttc\", \".otc\"):\n",
        "            coll = TTCollection(str(path), lazy=True)\n",
        "            best: Optional[Tuple[str, str]] = None\n",
        "            for face in coll.fonts:\n",
        "                try:\n",
        "                    f, s, _ = _read_name_table(face)\n",
        "                    if not best:\n",
        "                        best = (f or Path(path).stem, s)\n",
        "                    if _normalize_subfamily(s) in (\"regular\", \"book\"):\n",
        "                        best = (f or Path(path).stem, s)\n",
        "                        break\n",
        "                except Exception:\n",
        "                    continue\n",
        "            if best:\n",
        "                fam, sub = best\n",
        "            try:\n",
        "                coll.close()\n",
        "            except Exception:\n",
        "                pass\n",
        "        else:\n",
        "            tt = TTFont(str(path), lazy=True)\n",
        "            f, s, _ = _read_name_table(tt)\n",
        "            fam, sub = (f or Path(path).stem), s\n",
        "            try:\n",
        "                tt.close()\n",
        "            except Exception:\n",
        "                pass\n",
        "    except Exception:\n",
        "        pass\n",
        "    return (fam or Path(path).stem).strip(), _normalize_subfamily(sub)\n",
        "\n",
        "\n",
        "def _fc_match_family_path(family: str) -> Optional[Path]:\n",
        "    \"\"\"\n",
        "    Resolve a family to a concrete font file using fontconfig (`fc-match -v`).\n",
        "    Returns a Path or None. Parsing is deliberately loose to survive distro quirks.\n",
        "    \"\"\"\n",
        "    if not family or not _which(\"fc-match\"):\n",
        "        return None\n",
        "    cp = _run_cmd([\"fc-match\", \"-v\", family], capture=True)\n",
        "    text = (getattr(cp, \"stdout\", None) or \"\") + (getattr(cp, \"stderr\", None) or \"\")\n",
        "    m = re.search(r'file:\\s*\"([^\"]+)\"', text)\n",
        "    if not m:\n",
        "        return None\n",
        "    p = Path(m.group(1))\n",
        "    return p if p.exists() else None\n",
        "\n",
        "\n",
        "def _collect_asset_roots() -> List[Path]:\n",
        "    \"\"\"\n",
        "    Return potential asset root directories in order of likelihood.\n",
        "    Uses external globals if available, but degrades gracefully.\n",
        "    \"\"\"\n",
        "    roots: List[Path] = []\n",
        "    try:\n",
        "        wa = WORK_ASSETS  # type: ignore[name-defined]\n",
        "        roots.append(wa if isinstance(wa, Path) else Path(wa))\n",
        "    except Exception:\n",
        "        pass\n",
        "    try:\n",
        "        ar = ASSETS_ROOT if isinstance(ASSETS_ROOT, Path) else Path(ASSETS_ROOT)  # type: ignore[name-defined]\n",
        "        roots.append(ar)\n",
        "    except Exception:\n",
        "        pass\n",
        "    try:\n",
        "        for p in DRIVE_ASSETS_FOLDERS():  # type: ignore[name-defined]\n",
        "            roots.append(p)\n",
        "    except Exception:\n",
        "        pass\n",
        "    return _dedup_existing(roots)\n",
        "\n",
        "\n",
        "def _find_font_file_by_name(file_name: str) -> Optional[Path]:\n",
        "    \"\"\"\n",
        "    Search known asset roots for an exact filename match (non-recursive).\n",
        "    Returns the first match or None.\n",
        "    \"\"\"\n",
        "    if not file_name:\n",
        "        return None\n",
        "    name = Path(file_name).name\n",
        "    for base in _collect_asset_roots():\n",
        "        candidate = Path(base) / name\n",
        "        try:\n",
        "            if candidate.exists() and candidate.is_file():\n",
        "                return candidate\n",
        "        except Exception:\n",
        "            continue\n",
        "    return None\n",
        "\n",
        "\n",
        "def _ensure_user_fonts_dir() -> Path:\n",
        "    \"\"\"Create ~/.fonts if missing and return its path.\"\"\"\n",
        "    _USER_FONTS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    return _USER_FONTS_DIR\n",
        "\n",
        "\n",
        "def _needs_copy(src: Path, dst: Path) -> bool:\n",
        "    \"\"\"Return True if dst is missing or content hash differs (uses shared hash helper).\"\"\"\n",
        "    if not Path(dst).exists():\n",
        "        return True\n",
        "    try:\n",
        "        return _HASH_FUNC(Path(dst)) != _HASH_FUNC(Path(src))\n",
        "    except Exception:\n",
        "        return True\n",
        "\n",
        "\n",
        "def _install_into_user_fonts(src: Path) -> Path:\n",
        "    \"\"\"\n",
        "    Copy a font file into ~/.fonts atomically if content differs.\n",
        "    Trigger `fc-cache -f` when available. Return destination path.\n",
        "    \"\"\"\n",
        "    fonts_dir = _ensure_user_fonts_dir()\n",
        "    dst = fonts_dir / Path(src).name\n",
        "    try:\n",
        "        if _needs_copy(Path(src), dst):\n",
        "            _atomic_copy(Path(src), dst)\n",
        "            if _which(\"fc-cache\"):\n",
        "                _run_cmd([\"fc-cache\", \"-f\"], capture=False)\n",
        "    except Exception:\n",
        "        try:\n",
        "            shutil.copy2(src, dst)\n",
        "        except Exception:\n",
        "            pass\n",
        "    return dst\n",
        "\n",
        "\n",
        "def _set_ass_fonts_dir(extra_dirs: Iterable[Path]) -> None:\n",
        "    \"\"\"\n",
        "    Compute a value for ASS_FONT_DIR including ~/.fonts and provided extras.\n",
        "    libass accepts '|' separated list. Keep deterministic and de-duped.\n",
        "    Do not mutate global environment per SCA; callers may pass via _run(env=...).\n",
        "    \"\"\"\n",
        "    global _ASS_FONT_DIR_COMPUTED\n",
        "    dirs = [_USER_FONTS_DIR, *extra_dirs]\n",
        "    entries = [str(Path(p).resolve()) for p in _dedup_existing(dirs)]\n",
        "    if not entries:\n",
        "        entries = [str(_ensure_user_fonts_dir().resolve())]\n",
        "    _ASS_FONT_DIR_COMPUTED = \"|\".join(entries)\n",
        "\n",
        "\n",
        "# --------------------------------------------------------------------------------------\n",
        "# FontManager: caches + public API\n",
        "# --------------------------------------------------------------------------------------\n",
        "\n",
        "class FontManager:\n",
        "    \"\"\"\n",
        "    Responsibilities:\n",
        "      • Resolve a usable font file (explicit file, family via fontconfig, or fallbacks).\n",
        "      • Install asset fonts into ~/.fonts atomically and refresh fontconfig.\n",
        "      • Expose computed ASS_FONT_DIR via _ASS_FONT_DIR_COMPUTED for ffmpeg calls.\n",
        "      • Cache fontconfig lookups, PIL font instances, and (family, subfamily) metadata.\n",
        "      • Handle TTC/OTC collections and ambiguous subfamilies.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        self._fc_cache: Dict[str, Optional[Path]] = {}\n",
        "        self._pil_cache: Dict[Tuple[Optional[Path], int], Optional[ImageFont.FreeTypeFont]] = {}\n",
        "        self._meta_cache: Dict[Path, Tuple[str, str]] = {}\n",
        "\n",
        "    # -----------------------\n",
        "    # Internal cached helpers\n",
        "    # -----------------------\n",
        "\n",
        "    def _fc_cached(self, family: str) -> Optional[Path]:\n",
        "        if not family:\n",
        "            return None\n",
        "        key = family.strip()\n",
        "        if key in self._fc_cache:\n",
        "            return self._fc_cache[key]\n",
        "        p = _fc_match_family_path(key)\n",
        "        self._fc_cache[key] = p\n",
        "        return p\n",
        "\n",
        "    def _meta_cached(self, path: Path) -> Tuple[str, str]:\n",
        "        if Path(path) in self._meta_cache:\n",
        "            return self._meta_cache[Path(path)]\n",
        "        fam, sub = _read_font_meta(Path(path))\n",
        "        self._meta_cache[Path(path)] = (fam, sub)\n",
        "        return fam, sub\n",
        "\n",
        "    def _resolve_by_family_chain(self, families: Iterable[str]) -> Optional[FontInfo]:\n",
        "        \"\"\"Try a list of family names via fontconfig; return first success.\"\"\"\n",
        "        for fam in families:\n",
        "            p = self._fc_cached(fam)\n",
        "            if p and Path(p).exists():\n",
        "                f, s = self._meta_cached(Path(p))\n",
        "                _set_ass_fonts_dir([Path(p).parent])\n",
        "                return FontInfo(family=f, subfam=s or \"regular\", path=Path(p))\n",
        "        return None\n",
        "\n",
        "    # -----------------------\n",
        "    # Public API\n",
        "    # -----------------------\n",
        "\n",
        "    def resolve_font_selection(self, font_file_name: Optional[str]) -> FontInfo:\n",
        "        \"\"\"\n",
        "        Resolution order:\n",
        "          1) Explicit file in Assets → install to ~/.fonts → use it.\n",
        "          2) Treat provided string as a family name via fontconfig.\n",
        "          3) Professional fallback chain via fontconfig.\n",
        "          4) DejaVu Sans via fontconfig.\n",
        "          5) Last resort: report DejaVu Sans with no concrete file (PIL default).\n",
        "        Side effect: computes ASS font dir value to include ~/.fonts and any chosen directory.\n",
        "        \"\"\"\n",
        "        # 1) Explicit asset file\n",
        "        if font_file_name and str(font_file_name).strip().lower() != \"none\":\n",
        "            asset = _find_font_file_by_name(str(font_file_name))\n",
        "            if asset and Path(asset).exists():\n",
        "                dst = _install_into_user_fonts(Path(asset))\n",
        "                fam, sub = self._meta_cached(Path(dst))\n",
        "                _set_ass_fonts_dir([Path(dst).parent])\n",
        "                return FontInfo(family=fam, subfam=sub or \"regular\", path=Path(dst))\n",
        "\n",
        "        # 2) Interpret as a family name\n",
        "        if font_file_name:\n",
        "            p = self._fc_cached(str(font_file_name).strip())\n",
        "            if p and Path(p).exists():\n",
        "                fam, sub = self._meta_cached(Path(p))\n",
        "                _set_ass_fonts_dir([Path(p).parent])\n",
        "                return FontInfo(family=fam, subfam=sub or \"regular\", path=Path(p))\n",
        "\n",
        "        # 3) Preferred professional families\n",
        "        pick = self._resolve_by_family_chain(PREFERRED_FAMILIES)\n",
        "        if pick:\n",
        "            return pick\n",
        "\n",
        "        # 4) DejaVu Sans via fontconfig\n",
        "        p5 = self._fc_cached(\"DejaVu Sans\")\n",
        "        if p5 and Path(p5).exists():\n",
        "            fam, sub = self._meta_cached(Path(p5))\n",
        "            _set_ass_fonts_dir([Path(p5).parent])\n",
        "            return FontInfo(family=fam, subfam=sub or \"regular\", path=Path(p5))\n",
        "\n",
        "        # 5) Last resort\n",
        "        _set_ass_fonts_dir([_USER_FONTS_DIR])\n",
        "        return FontInfo(family=\"DejaVu Sans\", subfam=\"regular\", path=None)\n",
        "\n",
        "    def load_pil_font(self, file_path: Optional[Path], px: int) -> Optional[ImageFont.FreeTypeFont]:\n",
        "        \"\"\"\n",
        "        Cached PIL load with graceful fallbacks:\n",
        "          1) Provided file path.\n",
        "          2) Preferred families via fontconfig.\n",
        "          3) DejaVu Sans via fontconfig.\n",
        "          4) PIL default bitmap font.\n",
        "        \"\"\"\n",
        "        key = (Path(file_path) if file_path else None, int(px))\n",
        "        if key in self._pil_cache:\n",
        "            return self._pil_cache[key]\n",
        "\n",
        "        font: Optional[ImageFont.FreeTypeFont] = None\n",
        "\n",
        "        # 1) Explicit file\n",
        "        try:\n",
        "            if file_path and Path(file_path).exists():\n",
        "                font = ImageFont.truetype(str(Path(file_path)), int(px))\n",
        "        except Exception:\n",
        "            font = None\n",
        "\n",
        "        # 2) Family chain\n",
        "        if font is None:\n",
        "            for fam in PREFERRED_FAMILIES:\n",
        "                try:\n",
        "                    p = self._fc_cached(fam)\n",
        "                    if p and Path(p).exists():\n",
        "                        font = ImageFont.truetype(str(Path(p)), int(px))\n",
        "                        if font:\n",
        "                            break\n",
        "                except Exception:\n",
        "                    continue\n",
        "\n",
        "        # 3) DejaVu Sans\n",
        "        if font is None:\n",
        "            try:\n",
        "                p = self._fc_cached(\"DejaVu Sans\")\n",
        "                if p and Path(p).exists():\n",
        "                    font = ImageFont.truetype(str(Path(p)), int(px))\n",
        "            except Exception:\n",
        "                font = None\n",
        "\n",
        "        # 4) PIL default\n",
        "        if font is None:\n",
        "            try:\n",
        "                font = ImageFont.load_default()\n",
        "            except Exception:\n",
        "                font = None\n",
        "\n",
        "        self._pil_cache[key] = font\n",
        "        return font\n",
        "\n",
        "    def clear_caches(self) -> None:\n",
        "        \"\"\"Drop all caches. Use when fonts are updated on disk.\"\"\"\n",
        "        self._fc_cache.clear()\n",
        "        self._pil_cache.clear()\n",
        "        self._meta_cache.clear()\n",
        "\n",
        "\n",
        "# Singleton instance used by other modules\n",
        "FONTM = FontManager()\n",
        "print(\"Font manager ready.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "bfc53eb6",
      "metadata": {
        "id": "bfc53eb6",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title 5) ASR + Text Utils — Hidden\n",
        "# @markdown Faster-Whisper cached transcription (EN-only), LTR normalization/segmentation, precise sizing helpers.\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import hashlib\n",
        "import json\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import subprocess as sp\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "from typing import Any, Dict, List, Optional, Tuple\n",
        "\n",
        "# ---------------------------\n",
        "# Imports with fail-fast hints\n",
        "# ---------------------------\n",
        "try:\n",
        "    from PIL import Image, ImageFont  # type: ignore\n",
        "except Exception as e:\n",
        "    raise RuntimeError(\"Pillow is required. Remediation: `pip install Pillow>=11.3.0` and re-run prior install cell.\") from e\n",
        "\n",
        "try:\n",
        "    from faster_whisper import WhisperModel  # type: ignore\n",
        "except Exception as e:\n",
        "    raise RuntimeError(\"faster-whisper is required. Remediation: `pip install faster-whisper>=1.0.3`.\") from e\n",
        "\n",
        "# Optional CUDA probe (tolerate missing ctranslate2)\n",
        "try:\n",
        "    import ctranslate2  # type: ignore\n",
        "    _ct2_cuda_count = getattr(ctranslate2, \"get_cuda_device_count\", lambda: 0)\n",
        "except Exception:\n",
        "    ctranslate2 = None  # type: ignore\n",
        "    _ct2_cuda_count = lambda: 0  # type: ignore\n",
        "\n",
        "__all__ = [\n",
        "    \"Word\",\n",
        "    \"SENTENCE_GAP_SEC\", \"MIN_WORD_DUR\", \"END_PUNCT\", \"PUNCT\",\n",
        "    \"normalize_words\", \"sentenceize\",\n",
        "    \"ui_size_to_ass\", \"measure_text_px\",\n",
        "    \"effective_render_size\", \"effective_render_size_pipeline\",\n",
        "    \"detect_silences\", \"snap_to_voice_onset\",\n",
        "    \"extract_speech_stats\", \"smart_decide\",\n",
        "    \"transcribe_cached\",\n",
        "]\n",
        "\n",
        "# ============================================================\n",
        "# Data model\n",
        "# ============================================================\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class Word:\n",
        "    start: float\n",
        "    end: float\n",
        "    text: str\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Constants (EN/LTR only)\n",
        "# ============================================================\n",
        "\n",
        "SENTENCE_GAP_SEC: float = 0.60\n",
        "MIN_WORD_DUR: float = 0.06  # hard floor enforced by generators\n",
        "\n",
        "# English/LTR punctuation\n",
        "END_PUNCT = set(\".?!…\")\n",
        "PUNCT = set(\".,?!:;…—–-\\\"'()[]{}\")\n",
        "\n",
        "# ============================================================\n",
        "# Compiled regex\n",
        "# ============================================================\n",
        "\n",
        "_WS_RE = re.compile(r\"\\s+\")\n",
        "_SIL_START_RE = re.compile(r\"silence_start:\\s*([0-9]*\\.?[0-9]+)\")\n",
        "_SIL_END_RE = re.compile(r\"silence_end:\\s*([0-9]*\\.?[0-9]+)\")\n",
        "_DOTS_TO_ELLIP = re.compile(r\"(?<!\\.)\\.\\.\\.(?!\\.)\")  # normalize \"...\" → \"…\"\n",
        "\n",
        "# ============================================================\n",
        "# Env & misc helpers\n",
        "# ============================================================\n",
        "\n",
        "def _safe_env() -> Dict[str, str]:\n",
        "    \"\"\"Best-effort to obtain the runtime env mapping (copy only).\"\"\"\n",
        "    try:\n",
        "        return _env()  # type: ignore[name-defined]\n",
        "    except Exception:\n",
        "        return dict(os.environ)\n",
        "\n",
        "def _collapse_ws(s: str) -> str:\n",
        "    \"\"\"Collapse internal whitespace to single spaces and strip ends.\"\"\"\n",
        "    return _WS_RE.sub(\" \", s).strip()\n",
        "\n",
        "def is_punct_token(token: str) -> bool:\n",
        "    \"\"\"True if token is non-empty and every char is in the punctuation set.\"\"\"\n",
        "    t = (token or \"\").strip()\n",
        "    return bool(t) and all(ch in PUNCT for ch in t)\n",
        "\n",
        "def _clean_token_text(token: str) -> str:\n",
        "    \"\"\"Normalize whitespace and convert ASCII '...' to a single ellipsis.\"\"\"\n",
        "    if not token:\n",
        "        return \"\"\n",
        "    token = token.replace(\"\\n\", \" \").replace(\"\\t\", \" \")\n",
        "    token = _DOTS_TO_ELLIP.sub(\"…\", token)\n",
        "    return _collapse_ws(token)\n",
        "\n",
        "def _clamp_duration(start: float, end: float, floor: float = MIN_WORD_DUR) -> Tuple[float, float]:\n",
        "    \"\"\"Ensure end ≥ start and duration ≥ floor.\"\"\"\n",
        "    st = float(start)\n",
        "    en = float(end)\n",
        "    if en < st:\n",
        "        en = st\n",
        "    if en - st < floor:\n",
        "        en = st + floor\n",
        "    return st, en\n",
        "\n",
        "# ============================================================\n",
        "# Normalize & sentence split\n",
        "# ============================================================\n",
        "\n",
        "def normalize_words(words: List[Dict[str, Any]]) -> List[Word]:\n",
        "    \"\"\"\n",
        "    EN/LTR normalization:\n",
        "      - Sort tokens by start then end time.\n",
        "      - Merge pure punctuation into the previous token without spaces.\n",
        "      - Keep timings monotonic; enforce min word duration.\n",
        "    \"\"\"\n",
        "    out: List[Word] = []\n",
        "    seq = sorted(\n",
        "        (w for w in (words or []) if (w.get(\"text\") or \"\").strip()),\n",
        "        key=lambda x: (float(x.get(\"start\", 0.0)), float(x.get(\"end\", 0.0))),\n",
        "    )\n",
        "    for w in seq:\n",
        "        raw = str(w.get(\"text\", \"\")).strip()\n",
        "        if not raw:\n",
        "            continue\n",
        "        st, en = _clamp_duration(w.get(\"start\", 0.0), w.get(\"end\", 0.0), floor=MIN_WORD_DUR)\n",
        "        if is_punct_token(raw) and out:\n",
        "            last = out[-1]\n",
        "            out[-1] = Word(start=last.start, end=max(last.end, en), text=last.text + raw)\n",
        "            continue\n",
        "        cleaned = _clean_token_text(raw)\n",
        "        if cleaned:\n",
        "            out.append(Word(start=st, end=en, text=cleaned))\n",
        "    return out\n",
        "\n",
        "def sentenceize(words: List[Word]) -> List[List[Word]]:\n",
        "    \"\"\"\n",
        "    Split into sentences by:\n",
        "      - terminal punctuation in END_PUNCT\n",
        "      - or a time gap between tokens ≥ SENTENCE_GAP_SEC\n",
        "    \"\"\"\n",
        "    sentences: List[List[Word]] = []\n",
        "    current: List[Word] = []\n",
        "    prev_end: Optional[float] = None\n",
        "    for w in words or []:\n",
        "        gap = (float(w.start) - float(prev_end)) if prev_end is not None else 0.0\n",
        "        current.append(w)\n",
        "        if (w.text and w.text[-1] in END_PUNCT) or (gap >= SENTENCE_GAP_SEC):\n",
        "            sentences.append(current)\n",
        "            current = []\n",
        "        prev_end = float(w.end)\n",
        "    if current:\n",
        "        sentences.append(current)\n",
        "    return sentences\n",
        "\n",
        "# ============================================================\n",
        "# Font sizing & render geometry\n",
        "# ============================================================\n",
        "\n",
        "def ui_size_to_ass(value: int) -> int:\n",
        "    \"\"\"\n",
        "    Map UI slider range (10..100) to ASS px via a smooth S-curve,\n",
        "    which preserves perceptual steps at small sizes.\n",
        "    \"\"\"\n",
        "    v = max(10, min(100, int(value)))\n",
        "    px_lo, px_hi = 28, 220\n",
        "    t = (v - 10) / 90.0\n",
        "    eased = t * t * (3 - 2 * t)  # smoothstep\n",
        "    return int(round(px_lo + (px_hi - px_lo) * eased))\n",
        "\n",
        "def measure_text_px(file_path: Optional[Path], px: int, text: str) -> float:\n",
        "    \"\"\"\n",
        "    Measure text width in pixels:\n",
        "      - Prefer PIL FreeType getlength, then getbbox fallback.\n",
        "      - Fall back to a conservative linear estimate if metrics are unavailable.\n",
        "    \"\"\"\n",
        "    txt = _clean_token_text(text or \"\")\n",
        "    if not txt:\n",
        "        return 0.0\n",
        "    # Require upstream FONTM singleton from Font Manager cell\n",
        "    if \"FONTM\" not in globals():\n",
        "        raise RuntimeError(\"FONTM is missing. Remediation: run the Font Manager cell before calling `measure_text_px`.\")\n",
        "    fnt = FONTM.load_pil_font(file_path, int(px))  # type: ignore[name-defined]\n",
        "    if fnt is not None:\n",
        "        try:\n",
        "            return float(fnt.getlength(txt))  # type: ignore[attr-defined]\n",
        "        except Exception:\n",
        "            try:\n",
        "                box = fnt.getbbox(txt)\n",
        "                if box:\n",
        "                    return float(max(0, box[2] - box[0]))\n",
        "            except Exception:\n",
        "                pass\n",
        "    per_char = max(1.0, 0.56 * max(14, int(px)))  # conservative\n",
        "    return per_char * len(txt)\n",
        "\n",
        "def effective_render_size(final_w: int, final_h: int, subscale: float) -> Tuple[int, int, bool]:\n",
        "    \"\"\"\n",
        "    Compute effective render size (for subscale burn-in).\n",
        "    Returns (width, height, do_subscale).\n",
        "    \"\"\"\n",
        "    if subscale >= 1.0:\n",
        "        return int(final_w), int(final_h), False\n",
        "    sw = int(round(final_w * float(subscale)))\n",
        "    sh = int(round(final_h * float(subscale)))\n",
        "    if sw <= 0 or sh <= 0:\n",
        "        return int(final_w), int(final_h), False\n",
        "    return sw, sh, True\n",
        "\n",
        "def effective_render_size_pipeline(subscale: float) -> Tuple[int, int, bool]:\n",
        "    \"\"\"Convenience wrapper for a 1920x1080 pipeline target.\"\"\"\n",
        "    return effective_render_size(1920, 1080, float(subscale))\n",
        "\n",
        "# ============================================================\n",
        "# Audio: silence detection & snapping\n",
        "# ============================================================\n",
        "\n",
        "def detect_silences(audio_path: Path, noise_db: int = -35, min_silence: float = 0.35) -> List[Tuple[float, float]]:\n",
        "    \"\"\"\n",
        "    Detect silences via ffmpeg silencedetect.\n",
        "    Robust parsing, cached via META. Returns list of (start, end) pairs.\n",
        "    \"\"\"\n",
        "    if not audio_path or not audio_path.exists():\n",
        "        return []\n",
        "    # Require global cache facilities from Roots & Cache cell\n",
        "    if \"META\" not in globals() or \"WORK_META\" not in globals() or \"_json_dump\" not in globals():\n",
        "        raise RuntimeError(\n",
        "            \"WHAT: Cache globals missing\\n\"\n",
        "            \"WHY: Required objects META/WORK_META/_json_dump are not defined\\n\"\n",
        "            \"HOW_TO_FIX: Run the Roots & Cache cell before calling `detect_silences`.\"\n",
        "        )\n",
        "    try:\n",
        "        st = audio_path.stat()\n",
        "        key = f\"sil::{audio_path}::{int(st.st_mtime)}::{st.st_size}::{noise_db}::{min_silence}\"\n",
        "        if key in META:  # type: ignore[name-defined]\n",
        "            return META[key]  # type: ignore[index]\n",
        "    except Exception:\n",
        "        key = \"\"  # cache disabled on error\n",
        "    cmd = [\n",
        "        \"ffmpeg\", \"-hide_banner\", \"-nostdin\", \"-vn\", \"-nostats\",\n",
        "        \"-i\", str(audio_path),\n",
        "        \"-af\", f\"silencedetect=noise={int(noise_db)}dB:d={float(min_silence)}\",\n",
        "        \"-f\", \"null\", \"-\",\n",
        "    ]\n",
        "    proc = sp.run(cmd, capture_output=True, text=True, env=_safe_env())\n",
        "    log = proc.stderr or \"\"\n",
        "    silences: List[Tuple[float, float]] = []\n",
        "    pending_start: Optional[float] = None\n",
        "    for line in log.splitlines():\n",
        "        m1 = _SIL_START_RE.search(line)\n",
        "        if m1:\n",
        "            try:\n",
        "                pending_start = float(m1.group(1))\n",
        "            except Exception:\n",
        "                pending_start = None\n",
        "            continue\n",
        "        m2 = _SIL_END_RE.search(line)\n",
        "        if m2 and pending_start is not None:\n",
        "            try:\n",
        "                s_en = float(m2.group(1))\n",
        "                silences.append((pending_start, s_en))\n",
        "            except Exception:\n",
        "                pass\n",
        "            pending_start = None\n",
        "    silences.sort(key=lambda x: (x[0], x[1]))\n",
        "    if key:\n",
        "        try:\n",
        "            META[key] = silences  # type: ignore[name-defined]\n",
        "            _json_dump(WORK_META, META)  # type: ignore[name-defined]\n",
        "        except Exception:\n",
        "            pass\n",
        "    return silences\n",
        "\n",
        "def snap_to_voice_onset(t: float, silences: List[Tuple[float, float]], window: float = 0.18) -> float:\n",
        "    \"\"\"\n",
        "    Snap a time 't' to the end of a nearby or containing silence:\n",
        "      - If t is within ±window of a silence end, snap to that end.\n",
        "      - If t is inside a silence interval, snap to the interval end.\n",
        "    Useful for making captions feel aligned to speech onsets.\n",
        "    \"\"\"\n",
        "    tt = float(t)\n",
        "    w = max(0.0, float(window))\n",
        "    if not silences:\n",
        "        return tt\n",
        "    for s_st, s_en in silences:\n",
        "        s_st_f = float(s_st)\n",
        "        s_en_f = float(s_en)\n",
        "        if (s_en_f - w) <= tt <= (s_en_f + w):\n",
        "            return s_en_f\n",
        "        if s_st_f <= tt <= s_en_f:\n",
        "            return s_en_f\n",
        "    return tt\n",
        "\n",
        "# ============================================================\n",
        "# Speech stats & heuristics (language-agnostic)\n",
        "# ============================================================\n",
        "\n",
        "def extract_speech_stats(words: List[Word]) -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Compute basic pacing metrics:\n",
        "      - wpm: words per minute across the full span\n",
        "      - median_gap: median inter-word gap\n",
        "      - avg_wdur: mean token duration (floored at 10ms to avoid zeros)\n",
        "      - wps: average words per sentence (sentence ~ gap ≥ SENTENCE_GAP_SEC)\n",
        "    \"\"\"\n",
        "    if not words:\n",
        "        return {\"wpm\": 0.0, \"median_gap\": 0.0, \"avg_wdur\": 0.0, \"wps\": 0.0}\n",
        "    ws = sorted(words, key=lambda x: (float(x.start), float(x.end)))\n",
        "    starts = [float(w.start) for w in ws]\n",
        "    ends = [float(w.end) for w in ws]\n",
        "    total_span = max(0.001, max(ends) - min(starts))\n",
        "    gaps = [max(0.0, float(ws[i].start) - float(ws[i - 1].end)) for i in range(1, len(ws))]\n",
        "    if gaps:\n",
        "        gs = sorted(gaps)\n",
        "        n = len(gs)\n",
        "        median_gap = gs[n // 2] if n % 2 else (gs[n // 2 - 1] + gs[n // 2]) / 2.0\n",
        "    else:\n",
        "        median_gap = 0.0\n",
        "    avg_wdur = sum(max(0.01, float(w.end) - float(w.start)) for w in ws) / len(ws)\n",
        "    wpm = (len(ws) / total_span) * 60.0\n",
        "    sentence_count = 0\n",
        "    prev_end: Optional[float] = None\n",
        "    for w in ws:\n",
        "        if prev_end is None or (float(w.start) - float(prev_end)) >= SENTENCE_GAP_SEC:\n",
        "            sentence_count += 1\n",
        "        prev_end = float(w.end)\n",
        "    wps = len(ws) / max(1, sentence_count)\n",
        "    return {\"wpm\": float(wpm), \"median_gap\": float(median_gap), \"avg_wdur\": float(avg_wdur), \"wps\": float(wps)}\n",
        "\n",
        "def smart_decide(words: List[Word], bg_path: Path) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Heuristic UI defaults based on background luma and speech pace.\n",
        "    Returns margins, highlight mode, karaoke offset, fps, subscale, encoder mode.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with Image.open(str(bg_path)) as im:\n",
        "            resample = getattr(getattr(Image, \"Resampling\", Image), \"BILINEAR\")\n",
        "            small = im.convert(\"L\").resize((64, 36), resample)\n",
        "            buf = small.tobytes()\n",
        "            luma = (sum(buf) / (255.0 * len(buf))) if buf else 0.5\n",
        "    except Exception:\n",
        "        luma = 0.5\n",
        "    stats = extract_speech_stats(words)\n",
        "    wpm = float(stats[\"wpm\"])\n",
        "    median_gap = float(stats[\"median_gap\"])\n",
        "    avg_wdur = float(stats[\"avg_wdur\"])\n",
        "    hmargin = 154\n",
        "    vbase = 97\n",
        "    if luma > 0.65:\n",
        "        vmargin = min(140, int(vbase + 10 + (luma - 0.65) * 120))\n",
        "    elif luma < 0.35:\n",
        "        vmargin = max(70, int(vbase - 10 - (0.35 - luma) * 80))\n",
        "    else:\n",
        "        vmargin = vbase\n",
        "    if wpm >= 165.0 or avg_wdur <= 0.21:\n",
        "        hl_mode, koffset = \"word_pill\", 40\n",
        "    elif wpm <= 120.0 or median_gap >= 0.35:\n",
        "        hl_mode, koffset = \"word_pill\", 60\n",
        "    else:\n",
        "        hl_mode, koffset = \"word_pill\", 50\n",
        "    return {\n",
        "        \"hmargin\": hmargin,\n",
        "        \"vmargin\": vmargin,\n",
        "        \"highlight_mode\": hl_mode,\n",
        "        \"karaoke_offset_ms\": koffset,\n",
        "        \"fps\": 24,\n",
        "        \"subscale\": 0.80,\n",
        "        \"enc_mode\": \"studio\" if wpm <= 160.0 else \"race\",\n",
        "    }\n",
        "\n",
        "# ============================================================\n",
        "# Transcription (cached)\n",
        "# ============================================================\n",
        "\n",
        "_whisper_models: Dict[str, WhisperModel] = {}\n",
        "\n",
        "def _read_transcript_cache(path: Path) -> Optional[List[Word]]:\n",
        "    \"\"\"Load words from a JSON cache if it exists and is valid.\"\"\"\n",
        "    try:\n",
        "        data = json.loads(Path(path).read_text(encoding=\"utf-8\"))\n",
        "        records = data.get(\"words\", [])\n",
        "        out: List[Word] = []\n",
        "        for rec in records:\n",
        "            if {\"start\", \"end\", \"text\"} <= set(rec.keys()):\n",
        "                out.append(Word(float(rec[\"start\"]), float(rec[\"end\"]), str(rec[\"text\"])))\n",
        "        return out or None\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def _load_whisper_model(model_name: str, device: str) -> WhisperModel:\n",
        "    \"\"\"\n",
        "    Lazy model loader with compute_type fallbacks.\n",
        "    CUDA prefers half-precision/int8 hybrids; CPU favors int8.\n",
        "    \"\"\"\n",
        "    if model_name in _whisper_models:\n",
        "        return _whisper_models[model_name]\n",
        "    last_error: Optional[Exception] = None\n",
        "    candidates = [\"float16\", \"int8_float16\", \"int8\"] if device == \"cuda\" else [\"int8\", \"int8_float32\"]\n",
        "    for compute_type in candidates:\n",
        "        try:\n",
        "            model = WhisperModel(\n",
        "                model_name,\n",
        "                device=device,\n",
        "                compute_type=compute_type,\n",
        "                download_root=str(WORK_CACHE),  # type: ignore[name-defined]\n",
        "                cpu_threads=max(2, (os.cpu_count() or 2)),\n",
        "                num_workers=1,\n",
        "            )\n",
        "            _whisper_models[model_name] = model\n",
        "            return model\n",
        "        except Exception as e:\n",
        "            last_error = e\n",
        "    raise last_error or RuntimeError(f\"Failed to load Whisper model: {model_name}\")\n",
        "\n",
        "def transcribe_cached(audio_path: Path, model_name: str, lang: str = \"en\") -> List[Word]:\n",
        "    \"\"\"\n",
        "    Faster-Whisper transcription with VAD and on-disk caching.\n",
        "    Cache key is independent of compute_type; per-device for stability.\n",
        "    \"\"\"\n",
        "    if not audio_path or not Path(audio_path).exists():\n",
        "        raise FileNotFoundError(f\"Audio not found: {audio_path}\")\n",
        "    # Require upstream cache/work roots\n",
        "    if \"WORK_CACHE\" not in globals():\n",
        "        raise RuntimeError(\n",
        "            \"WHAT: WORK_CACHE missing\\n\"\n",
        "            \"WHY: Required cache directory not defined or created\\n\"\n",
        "            \"HOW_TO_FIX: Run the Roots & Cache cell before transcription.\"\n",
        "        )\n",
        "    try:\n",
        "        has_cuda = bool(_ct2_cuda_count() > 0)\n",
        "    except Exception:\n",
        "        has_cuda = False\n",
        "    device = \"cuda\" if has_cuda else \"cpu\"\n",
        "    try:\n",
        "        ah = sha1_file(audio_path)  # type: ignore[name-defined]\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(\n",
        "            \"WHAT: sha1 helper unavailable\\n\"\n",
        "            \"WHY: sha1_file not found from Core Utils\\n\"\n",
        "            \"HOW_TO_FIX: Run the Core Utils cell before transcription.\"\n",
        "        ) from e\n",
        "    key = {\"v\": 8, \"audio\": str(audio_path), \"sha1\": ah, \"model\": model_name, \"lang\": lang, \"device\": device}\n",
        "    cache_path = Path(WORK_CACHE) / f\"tr_{hashlib.sha1(json.dumps(key, sort_keys=True).encode()).hexdigest()}.json\"  # type: ignore[name-defined]\n",
        "    cached = _read_transcript_cache(cache_path) if Path(cache_path).exists() else None\n",
        "    if cached is not None:\n",
        "        return cached\n",
        "    model = _load_whisper_model(model_name, device)\n",
        "    try:\n",
        "        segments, _info = model.transcribe(\n",
        "            str(audio_path),\n",
        "            language=lang,\n",
        "            vad_filter=True,\n",
        "            vad_parameters=dict(threshold=0.55, min_speech_duration_ms=250),\n",
        "            word_timestamps=True,\n",
        "            beam_size=1,\n",
        "            best_of=1,\n",
        "        )\n",
        "    except Exception:\n",
        "        segments, _info = model.transcribe(\n",
        "            str(audio_path),\n",
        "            language=lang,\n",
        "            vad_filter=False,\n",
        "            word_timestamps=True,\n",
        "            beam_size=1,\n",
        "            best_of=1,\n",
        "        )\n",
        "    raw_words: List[Dict[str, Any]] = []\n",
        "    for seg in segments:\n",
        "        words_attr = getattr(seg, \"words\", None)\n",
        "        if not words_attr:\n",
        "            continue\n",
        "        for w in words_attr:\n",
        "            token = (getattr(w, \"word\", \"\") or \"\").strip()\n",
        "            if token:\n",
        "                raw_words.append(\n",
        "                    {\n",
        "                        \"start\": float(getattr(w, \"start\", 0.0)),\n",
        "                        \"end\": float(getattr(w, \"end\", 0.0)),\n",
        "                        \"text\": token,\n",
        "                    }\n",
        "                )\n",
        "    words = normalize_words(raw_words)\n",
        "    try:\n",
        "        if \"_json_dump\" not in globals():\n",
        "            raise RuntimeError(\"Missing _json_dump for cache write. Remediation: run Roots & Cache cell.\")\n",
        "        _json_dump(cache_path, {\"words\": [{\"start\": w.start, \"end\": w.end, \"text\": w.text} for w in words]})  # type: ignore[name-defined]\n",
        "    except Exception:\n",
        "        pass\n",
        "    return words\n",
        "\n",
        "# ============================================================\n",
        "# Preemptive preflight (no side-effects beyond bounded probes)\n",
        "# ============================================================\n",
        "\n",
        "def _have_exe(name: str) -> bool:\n",
        "    try:\n",
        "        return shutil.which(name) is not None\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "def _ffmpeg_audio_smoke() -> None:\n",
        "    \"\"\"\n",
        "    Minimal audio pipeline probe to prevent runtime surprise:\n",
        "    anullsrc (48 kHz stereo) → 0.1s → null mux. Raises on failure.\n",
        "    \"\"\"\n",
        "    if not _have_exe(\"ffmpeg\"):\n",
        "        raise RuntimeError(\n",
        "            \"WHAT: ffmpeg tool check\\n\"\n",
        "            \"WHY: ffmpeg not found on PATH\\n\"\n",
        "            \"HOW_TO_FIX: Install ffmpeg and ensure it is on PATH, then re-run the install/setup cell.\"\n",
        "        )\n",
        "    cmd = [\n",
        "        \"ffmpeg\", \"-hide_banner\", \"-loglevel\", \"error\", \"-nostdin\",\n",
        "        \"-f\", \"lavfi\", \"-i\", \"anullsrc=r=48000:cl=stereo\",\n",
        "        \"-t\", \"0.1\", \"-ac\", \"2\", \"-ar\", \"48000\",\n",
        "        \"-f\", \"null\", \"-\"\n",
        "    ]\n",
        "    p = sp.run(cmd, stdout=sp.PIPE, stderr=sp.PIPE, text=True, env=_safe_env())\n",
        "    if p.returncode != 0:\n",
        "        err = (p.stderr or \"\").strip()\n",
        "        raise RuntimeError(\n",
        "            \"WHAT: FFmpeg audio smoke test\\n\"\n",
        "            f\"WHY: pipeline failed with error: {err or 'unknown'}\\n\"\n",
        "            \"HOW_TO_FIX: Ensure ffmpeg has libavfilter enabled and audio filters available.\"\n",
        "        )\n",
        "\n",
        "def _preflight_asr_utils() -> None:\n",
        "    # Tools presence\n",
        "    if not _have_exe(\"ffmpeg\"):\n",
        "        raise RuntimeError(\n",
        "            \"WHAT: Required tools check\\n\"\n",
        "            \"WHY: ffmpeg is missing\\n\"\n",
        "            \"HOW_TO_FIX: Install ffmpeg and ensure it’s on PATH.\"\n",
        "        )\n",
        "    if not _have_exe(\"ffprobe\"):\n",
        "        raise RuntimeError(\n",
        "            \"WHAT: Required tools check\\n\"\n",
        "            \"WHY: ffprobe is missing\\n\"\n",
        "            \"HOW_TO_FIX: Install ffmpeg (includes ffprobe) and ensure PATH is set.\"\n",
        "        )\n",
        "    # Cache/work roots\n",
        "    if \"WORK_CACHE\" not in globals() or not Path(WORK_CACHE).exists():  # type: ignore[name-defined]\n",
        "        raise RuntimeError(\n",
        "            \"WHAT: WORK_CACHE directory missing\\n\"\n",
        "            \"WHY: Roots & Cache cell was not executed or path is invalid\\n\"\n",
        "            \"HOW_TO_FIX: Run the Roots & Cache cell to create WORK_CACHE.\"\n",
        "        )\n",
        "    if not os.access(str(WORK_CACHE), os.W_OK):  # type: ignore[name-defined]\n",
        "        raise RuntimeError(\n",
        "            \"WHAT: Cache path not writable\\n\"\n",
        "            \"WHY: Insufficient permissions for WORK_CACHE\\n\"\n",
        "            \"HOW_TO_FIX: Fix permissions or configure a writable cache root.\"\n",
        "        )\n",
        "    # Shared helpers\n",
        "    if \"sha1_file\" not in globals():\n",
        "        raise RuntimeError(\n",
        "            \"WHAT: Helper dependency missing\\n\"\n",
        "            \"WHY: sha1_file is undefined\\n\"\n",
        "            \"HOW_TO_FIX: Run the Core Utils cell before this one.\"\n",
        "        )\n",
        "    # Audio smoke\n",
        "    _ffmpeg_audio_smoke()\n",
        "\n",
        "# Execute preflight now (bounded, deterministic)\n",
        "__pref_ok = True\n",
        "try:\n",
        "    _preflight_asr_utils()\n",
        "except Exception:\n",
        "    __pref_ok = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "50c7f503",
      "metadata": {
        "id": "50c7f503",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title 6) Caption Layout + ASS (Static Word Box) — Final (SCA v3)\n",
        "# Pixel-accurate English LTR captions with adaptive alignment, safe areas, and standards-correct ASS escaping.\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import hashlib\n",
        "import json\n",
        "import math\n",
        "import os\n",
        "import re\n",
        "from functools import lru_cache\n",
        "from pathlib import Path\n",
        "from shutil import which\n",
        "from typing import List, Optional, Tuple\n",
        "\n",
        "# ---------- Tunables ----------\n",
        "BASE_MIN_WORD_DUR: float = 0.06\n",
        "BASE_MIN_CAP_DUR: float = 0.25\n",
        "BASE_LINE_SPACE: float = 0.20\n",
        "BOX_ALPHA: str = \"55\"\n",
        "BOX_PAD_X: float = 0.08\n",
        "BOX_PAD_Y: float = 0.15\n",
        "GUARD_PX: int = 2\n",
        "CACHE_VER: int = 202\n",
        "\n",
        "# Width calibration to match ASS renderer\n",
        "WIDTH_CAL_MAP: dict[str, float] = {\n",
        "    \"Inter 18pt ExtraBold\": 0.972,\n",
        "    \"Arial\": 0.965,\n",
        "    \"DejaVu Sans\": 0.982,\n",
        "}\n",
        "WIDTH_CAL_DEFAULT: float = 0.969\n",
        "\n",
        "# ---------- Precompiled regex ----------\n",
        "_RE_WS_MULTI  = re.compile(r\"\\s+\")\n",
        "_RE_WS_PUNCT1 = re.compile(r\"\\s+([,.:;!?])\")\n",
        "_RE_WS_PUNCT2 = re.compile(r\"([(\\[{\\\"])\\s+\")\n",
        "_RE_WS_PUNCT3 = re.compile(r\"\\s+([)\\]\\\"])\")\n",
        "\n",
        "# ---------- Small constants ----------\n",
        "_END_PUNCT = (\".\", \"?\", \"!\", \"…\")\n",
        "_MID_PUNCT = (\",\", \";\", \":\")\n",
        "\n",
        "# ---------------- helpers: text ----------------\n",
        "def _sanitize_tokens(tokens: List[\"Word\"], sentence_head: bool = False) -> List[\"Word\"]:\n",
        "    \"\"\"Merge/pad whitespace around punctuation and preserve timing alignment.\"\"\"\n",
        "    if not tokens:\n",
        "        return tokens\n",
        "    raw = \" \".join(t.text for t in tokens)\n",
        "    raw = _RE_WS_MULTI.sub(\" \", raw).strip()\n",
        "    raw = _RE_WS_PUNCT1.sub(r\"\\1\", raw)\n",
        "    raw = _RE_WS_PUNCT2.sub(r\"\\1\", raw)\n",
        "    raw = _RE_WS_PUNCT3.sub(r\"\\1\", raw)\n",
        "    if sentence_head and raw and raw[0].isalpha():\n",
        "        raw = raw[0].upper() + raw[1:]\n",
        "    parts = raw.split(\" \")\n",
        "    out: List[\"Word\"] = []\n",
        "    i = 0\n",
        "    for p in parts:\n",
        "        if i < len(tokens):\n",
        "            t = tokens[i]\n",
        "            out.append(Word(float(t.start), float(t.end), p))\n",
        "            i += 1\n",
        "        else:\n",
        "            last = out[-1]\n",
        "            out[-1] = Word(float(last.start), float(last.end), f\"{last.text} {p}\")\n",
        "    while i < len(tokens):\n",
        "        out.append(tokens[i])\n",
        "        i += 1\n",
        "    return out\n",
        "\n",
        "\n",
        "def _ass_escape(text: str) -> str:\n",
        "    \"\"\"ASS v4+ escaping: ONLY backslash, braces, and newline→\\\\N (standards-correct).\"\"\"\n",
        "    t = (text or \"\")\n",
        "    t = t.replace(\"\\\\\", \"\\\\\\\\\").replace(\"{\", \"\\\\{\").replace(\"}\", \"\\\\}\")\n",
        "    return t.replace(\"\\n\", r\"\\N\")\n",
        "\n",
        "\n",
        "# ---------------- helpers: measure/geometry (cached) ----------------\n",
        "@lru_cache(maxsize=65536)\n",
        "def _measured_px_cached(fp_str: str, px: int, text: str, fam: str) -> int:\n",
        "    \"\"\"Cached text width with renderer calibration.\"\"\"\n",
        "    raw = float(measure_text_px(Path(fp_str) if fp_str else None, int(px), text))  # type: ignore[name-defined]\n",
        "    cal = float(WIDTH_CAL_MAP.get(fam, WIDTH_CAL_DEFAULT))\n",
        "    return max(0, int(round(raw * cal)))\n",
        "\n",
        "\n",
        "@lru_cache(maxsize=512)\n",
        "def _space_w_cached(fp_str: str, px: int, fam: str) -> int:\n",
        "    return max(1, _measured_px_cached(fp_str, int(px), \" \", fam))\n",
        "\n",
        "\n",
        "def _measure_tok_w_cached(file_path: Optional[Path], px: int, text: str, fam: str) -> int:\n",
        "    return _measured_px_cached(str(file_path) if file_path else \"\", int(px), text, fam)\n",
        "\n",
        "\n",
        "def _space_w(file_path: Optional[Path], px: int, fam: str) -> int:\n",
        "    return _space_w_cached(str(file_path) if file_path else \"\", int(px), fam)\n",
        "\n",
        "\n",
        "def _font_metrics(px: int, file_path: Optional[Path]) -> Tuple[int, int, int]:\n",
        "    \"\"\"Return (ascent, descent, line_height) with robust fallbacks.\"\"\"\n",
        "    f = FONTM.load_pil_font(file_path, int(px))  # type: ignore[name-defined]\n",
        "    if f:\n",
        "        try:\n",
        "            asc, desc = f.getmetrics()\n",
        "            lh = max(1, int(round((asc + desc) * 1.05)))\n",
        "            return int(asc), int(desc), int(lh)\n",
        "        except Exception:\n",
        "            pass\n",
        "    lh = max(1, int(math.ceil(int(px) * 1.7)))\n",
        "    asc = int(round(lh * 0.8))\n",
        "    desc = max(1, lh - asc)\n",
        "    return int(asc), int(desc), int(lh)\n",
        "\n",
        "\n",
        "def _ensure_interval(st: float, et: float, mind: float) -> Tuple[float, float]:\n",
        "    \"\"\"Clamp interval to minimum duration with stable ordering.\"\"\"\n",
        "    st = float(st); et = float(et); mind = float(mind)\n",
        "    if et - st < mind:\n",
        "        if st >= et:\n",
        "            st = max(0.0, et - mind)\n",
        "        else:\n",
        "            et = st + mind\n",
        "    return float(st), float(et)\n",
        "\n",
        "\n",
        "# ---------------- prefix sums & spans ----------------\n",
        "def _prefix_adv(widths: List[int], sp_w: int) -> List[int]:\n",
        "    \"\"\"Prefix-advance for tokens with a fixed inter-word spacing.\"\"\"\n",
        "    run = 0\n",
        "    out: List[int] = []\n",
        "    for i, w in enumerate(widths):\n",
        "        run += w\n",
        "        if i > 0:\n",
        "            run += sp_w\n",
        "        out.append(run)\n",
        "    return out\n",
        "\n",
        "\n",
        "def _build_word_spans_from_adv(\n",
        "    adv: List[int],\n",
        "    rw: int,\n",
        "    margin_h: int,\n",
        "    align_mode: str,\n",
        "    sp_w: int\n",
        ") -> Tuple[List[Tuple[int, int]], int, int]:\n",
        "    \"\"\"\n",
        "    Build inclusive [L, R) spans for each token in line space.\n",
        "    Returns (spans, line_width, x_origin).\n",
        "    \"\"\"\n",
        "    if not adv:\n",
        "        return [], 0, max(0, int(margin_h))\n",
        "    usable_line_w = min(adv[-1], max(80, int(rw) - 2 * max(0, int(margin_h))))\n",
        "\n",
        "    al = (align_mode or \"left\").strip().lower()\n",
        "    if al == \"center\":\n",
        "        x0 = int(round(max(margin_h, (rw - usable_line_w) / 2)))\n",
        "        x0 = min(x0, max(margin_h, rw - margin_h - usable_line_w))\n",
        "    elif al == \"right\":\n",
        "        x0 = int(round(max(margin_h, rw - margin_h - usable_line_w)))\n",
        "    else:\n",
        "        x0 = int(max(0, margin_h))\n",
        "\n",
        "    spans: List[Tuple[int, int]] = []\n",
        "    left_edge = 0\n",
        "    for i, a in enumerate(adv):\n",
        "        right_edge = a\n",
        "        if i + 1 < len(adv):\n",
        "            right_edge = min(right_edge, max(adv[i + 1] - sp_w // 2, a))\n",
        "        L = max(0, min(rw, int(round(x0 + left_edge))))\n",
        "        R = max(L + 1, min(rw, int(round(x0 + right_edge))))\n",
        "        spans.append((L, R))\n",
        "        left_edge = a + sp_w\n",
        "\n",
        "    return spans, int(round(usable_line_w)), int(x0)\n",
        "\n",
        "\n",
        "# ---------------- line breaking (1–2 lines, greedy but width-aware) -----------\n",
        "def _fit_line_with_adv(usable: int, max_words: int, adv: List[int], i0: int) -> int:\n",
        "    \"\"\"\n",
        "    Decide how many tokens from adv[i0:] go into the current line.\n",
        "    Uses O(1) prefix width queries with a gentle rag penalty.\n",
        "    \"\"\"\n",
        "    n = min(len(adv) - i0, max(1, int(max_words)))\n",
        "    best = 1\n",
        "    best_pen = 1e9\n",
        "\n",
        "    def prefix(j: int) -> int:\n",
        "        return adv[i0 + j - 1] - (adv[i0 - 1] if i0 > 0 else 0)\n",
        "\n",
        "    for j in range(1, n + 1):\n",
        "        lw = prefix(j)\n",
        "        if lw > usable and j > 1:\n",
        "            continue\n",
        "        if lw > usable and j == 1:\n",
        "            return 1\n",
        "        rag = (usable - lw) / float(usable)\n",
        "        pen = (rag * rag) * 0.25\n",
        "        if (pen < best_pen) or (abs(pen - best_pen) < 1e-9 and j > best):\n",
        "            best_pen, best = pen, j\n",
        "    return int(best or 1)\n",
        "\n",
        "\n",
        "def _words_to_lines(\n",
        "    tokens: List[\"Word\"],\n",
        "    file_path: Optional[Path],\n",
        "    px: int,\n",
        "    vw: int,\n",
        "    h_margin: int,\n",
        "    max_wpl: int,\n",
        "    line_count: int,\n",
        "    fam: str,\n",
        ") -> Tuple[List[List[\"Word\"]], List[\"Word\"]]:\n",
        "    \"\"\"Greedy line-fit for 1–2 lines with cached measurements.\"\"\"\n",
        "    usable = max(80, int(vw) - 2 * max(0, int(h_margin)))\n",
        "    max_words = max(1, int(max_wpl))\n",
        "    sp_w = _space_w(file_path, int(px), fam)\n",
        "\n",
        "    buf = list(tokens)\n",
        "    if not buf:\n",
        "        return [], []\n",
        "\n",
        "    widths = [_measure_tok_w_cached(file_path, int(px), w.text, fam) for w in buf]\n",
        "    adv = _prefix_adv(widths, sp_w)\n",
        "\n",
        "    lines: List[List[\"Word\"]] = []\n",
        "    i0 = 0\n",
        "    for _ in range(max(1, min(2, int(line_count)))):  # 1–2 lines\n",
        "        if i0 >= len(buf):\n",
        "            break\n",
        "        cut = _fit_line_with_adv(usable, max_words, adv, i0)\n",
        "        line = buf[i0 : i0 + cut]\n",
        "        lines.append(line)\n",
        "        i0 += cut\n",
        "        if i0 >= len(buf):\n",
        "            break\n",
        "    rest = buf[i0:] if i0 < len(buf) else []\n",
        "    return lines, rest\n",
        "\n",
        "\n",
        "def _split_sentence_to_captions(\n",
        "    sent: List[\"Word\"],\n",
        "    file_path: Optional[Path],\n",
        "    px: int,\n",
        "    vw: int,\n",
        "    h_margin: int,\n",
        "    max_wpl: int,\n",
        "    max_wpc: int,\n",
        "    line_count: int,\n",
        "    fam: str,\n",
        ") -> List[List[List[\"Word\"]]]:\n",
        "    \"\"\"Split one sentence into caption chunks with widow/orphan control.\"\"\"\n",
        "    toks = _sanitize_tokens(sent, sentence_head=True)\n",
        "    out: List[List[List[\"Word\"]]] = []\n",
        "    i = 0\n",
        "    n = len(toks)\n",
        "    cap_max = max(1, int(max_wpc))\n",
        "    while i < n:\n",
        "        end = min(n, i + cap_max)\n",
        "        chunk = toks[i:end]\n",
        "        lines, _ = _words_to_lines(\n",
        "            chunk, file_path, int(px), int(vw), int(h_margin), int(max_wpl), int(line_count), fam\n",
        "        )\n",
        "        if not lines:\n",
        "            i += 1\n",
        "            continue\n",
        "        lines = [_sanitize_tokens(ln, sentence_head=(len(out) == 0)) for ln in lines if ln]\n",
        "        out.append(lines)\n",
        "\n",
        "        # widow/orphan guard\n",
        "        MIN_CHARS_WIDOW = 6\n",
        "        if len(out) >= 2:\n",
        "            last_chars = sum(len(w.text) for ln in out[-1] for w in ln)\n",
        "            if last_chars < MIN_CHARS_WIDOW:\n",
        "                out[-2] = out[-2] + out[-1]\n",
        "                out.pop()\n",
        "\n",
        "        used = max(1, sum(len(ln) for ln in lines))\n",
        "        i += used\n",
        "    return out\n",
        "\n",
        "\n",
        "# ---------------- main: generate_ass_track ----------------\n",
        "def generate_ass_track(\n",
        "    words: List[\"Word\"],\n",
        "    font_info: \"FontInfo\",\n",
        "    ui_font_size: int,\n",
        "    position: str,\n",
        "    margin_h: int,\n",
        "    margin_v: int,\n",
        "    border_thickness: int,\n",
        "    primary_color: str,\n",
        "    highlight_color: Optional[str],\n",
        "    time_offset: float,\n",
        "    karaoke_offset_ms: int,\n",
        "    style_profile: str,\n",
        "    highlight_mode_ui: str,\n",
        "    rw: int,\n",
        "    rh: int,\n",
        "    keyword_overlay: bool,\n",
        "    keyword_list: List[str],\n",
        "    key_txt_color: str,\n",
        "    key_bg_color: str,\n",
        "    key_pos: str,\n",
        "    audio_for_snap: Optional[Path],\n",
        "    force_bold_ui: bool,\n",
        "    outline_override: int,\n",
        "    line_count: int,\n",
        "    max_words_per_line: int,\n",
        "    max_words_per_caption: int,\n",
        "    strict_word: bool,\n",
        "    align_mode: str = \"left\",\n",
        "    safe_area_pct: int = 92,\n",
        "    line_space_pct: int = 100,\n",
        "    target_cps: int = 17,\n",
        "    min_caption_sec: float = BASE_MIN_CAP_DUR,\n",
        "    max_extend_sec: float = 0.40,\n",
        ") -> Path:\n",
        "    # ---- preflight guards (no side-effects) ----\n",
        "    REQUIRED_GLOBALS = (\"ui_size_to_ass\", \"measure_text_px\", \"sentenceize\", \"ass_timestamp\", \"bgr_hex\", \"FONTM\", \"WORK_CACHE\")\n",
        "    for name in REQUIRED_GLOBALS:\n",
        "        if name not in globals():\n",
        "            raise RuntimeError(f\"Missing dependency `{name}`. HOW_TO_FIX: run prior cells (Core Utils, Font Manager, Roots & Cache).\")\n",
        "    if audio_for_snap is not None and \"detect_silences\" not in globals():\n",
        "        raise RuntimeError(\"Missing `detect_silences`. HOW_TO_FIX: run the ASR/Text Utils cell providing silence detection.\")\n",
        "    if audio_for_snap is not None and \"snap_to_voice_onset\" not in globals():\n",
        "        raise RuntimeError(\"Missing `snap_to_voice_onset`. HOW_TO_FIX: run the ASR/Text Utils cell.\")\n",
        "    if which(\"ffmpeg\") is None or which(\"ffprobe\") is None:\n",
        "        raise RuntimeError(\"ffmpeg/ffprobe not found on PATH. HOW_TO_FIX: install ffmpeg (apt/pip/conda) or run your Install cell.\")\n",
        "\n",
        "    # ---- cache root sanity (no creation here) ----\n",
        "    if not isinstance(WORK_CACHE, Path) or not WORK_CACHE.exists() or not WORK_CACHE.is_dir():  # type: ignore[name-defined]\n",
        "        raise RuntimeError(\"WORK_CACHE is missing. HOW_TO_FIX: run the Roots & Cache cell to create the working cache directory.\")\n",
        "\n",
        "    # --------- geometry & styles ----------\n",
        "    rw = max(16, int(rw)); rh = max(16, int(rh))\n",
        "    margin_h = max(0, int(margin_h)); margin_v = max(0, int(margin_v))\n",
        "    mapped_fs = int(ui_size_to_ass(int(ui_font_size)))  # type: ignore[name-defined]\n",
        "\n",
        "    primary_color = primary_color or \"#FFFFFF\"\n",
        "    highlight_color = highlight_color or \"#19B5FF\"\n",
        "    text_bgr = bgr_hex(primary_color)   # type: ignore[name-defined]\n",
        "    box_bgr  = bgr_hex(highlight_color) # type: ignore[name-defined]\n",
        "\n",
        "    outline_source_val = int(border_thickness or 0)\n",
        "    if outline_override and int(outline_override) > 0:\n",
        "        outline_source_val = int(outline_override)\n",
        "    min_outline = max(1, int(round(mapped_fs * 0.04)))  # WCAG-AA guard\n",
        "    outline_px = max(min_outline, min(int(outline_source_val), 8))\n",
        "\n",
        "    safe_pct = max(60, min(100, int(safe_area_pct)))\n",
        "    safe_margin_h = int(round(rw * (1 - safe_pct / 100.0) / 2))\n",
        "    safe_margin_v = int(round(rh * (1 - safe_pct / 100.0) / 2))\n",
        "    margin_h = max(margin_h, safe_margin_h)\n",
        "    margin_v = max(margin_v, safe_margin_v)\n",
        "\n",
        "    align_norm = (align_mode or \"left\").strip().lower()\n",
        "    hl_mode = (highlight_mode_ui or \"word_pill\").strip().lower()\n",
        "    if hl_mode not in {\"word_pill\", \"word_fill\", \"word_bg\", \"none\"}:\n",
        "        hl_mode = \"word_pill\"\n",
        "    effective_hl = hl_mode if strict_word else (\"word_bg\" if hl_mode != \"none\" else \"none\")\n",
        "\n",
        "    asc, desc, line_h = _font_metrics(int(mapped_fs), font_info.path)\n",
        "    gap_factor = max(0.4, min(2.0, float(line_space_pct or 100) / 100.0))\n",
        "    gap_y = max(4, int(round(mapped_fs * BASE_LINE_SPACE * gap_factor)))\n",
        "\n",
        "    nlines = max(1, int(line_count))\n",
        "    block_h = int(line_h if nlines == 1 else (line_h * nlines + (nlines - 1) * gap_y))\n",
        "\n",
        "    pos_norm = (position or \"Bottom\").strip().lower()\n",
        "    if pos_norm == \"bottom\":\n",
        "        y_top = rh - margin_v - block_h\n",
        "    elif pos_norm == \"middle\":\n",
        "        y_top = max(0, rh // 2 - block_h // 2)\n",
        "    else:\n",
        "        y_top = max(margin_v, int(rh * 0.10))\n",
        "\n",
        "    pad_x = max(2, int(round(mapped_fs * BOX_PAD_X)))\n",
        "    pad_y = max(1, int(round(max(2, desc) * BOX_PAD_Y)))\n",
        "\n",
        "    # SCA clamp for karaoke offset (ms)\n",
        "    k_ms_in = int(karaoke_offset_ms)\n",
        "    k_ms = max(-1000, min(1000, k_ms_in))\n",
        "    base_off = float(time_offset or 0.0) + float(k_ms / 1000.0)\n",
        "\n",
        "    min_cap_dur = max(BASE_MIN_CAP_DUR, float(min_caption_sec))\n",
        "    max_extend = max(0.0, float(max_extend_sec))\n",
        "    min_word_dur = float(BASE_MIN_WORD_DUR)\n",
        "    target_cps = max(8, min(28, int(target_cps or 17)))  # SCA clamp\n",
        "\n",
        "    # --------- cache key ----------\n",
        "    words_fp = [{\"s\": float(w.start), \"e\": float(w.end), \"t\": w.text} for w in words]\n",
        "    text_hash = hashlib.sha1(\n",
        "        json.dumps(words_fp, ensure_ascii=False, separators=(\",\", \":\")).encode(\"utf-8\")\n",
        "    ).hexdigest()\n",
        "    ckey = {\n",
        "        \"v\": CACHE_VER, \"rw\": rw, \"rh\": rh,\n",
        "        \"fam\": font_info.family, \"fs\": mapped_fs,\n",
        "        \"mh\": margin_h, \"mv\": margin_v, \"txt\": text_hash,\n",
        "        \"out\": outline_px, \"lc\": nlines, \"pos\": pos_norm,\n",
        "        \"align\": align_norm, \"safe\": safe_pct, \"gap\": int(round(gap_factor * 100)),\n",
        "        \"hl\": hl_mode, \"strict\": bool(strict_word), \"target_cps\": target_cps,\n",
        "        \"mincap\": round(min_cap_dur, 3), \"extend\": round(max_extend, 3),\n",
        "        \"k_ms\": k_ms,\n",
        "    }\n",
        "    kpath = WORK_CACHE / f\"ass_{hashlib.sha1(json.dumps(ckey, sort_keys=True).encode()).hexdigest()}.ass\"  # type: ignore[name-defined]\n",
        "    if kpath.exists():\n",
        "        return kpath\n",
        "\n",
        "    # --------- text + audio landmarks ----------\n",
        "    sents = sentenceize(words)  # type: ignore[name-defined]\n",
        "    sils = detect_silences(audio_for_snap) if audio_for_snap else []  # type: ignore[name-defined]\n",
        "    _sils_tuple = tuple((float(a), float(b)) for a, b in sils) if sils else ()\n",
        "\n",
        "    _snap_cache: dict[tuple[float, float], float] = {}\n",
        "\n",
        "    def _snap(st: float, window: float) -> float:\n",
        "        key = (round(st, 3), round(window, 3))\n",
        "        v = _snap_cache.get(key)\n",
        "        if v is not None:\n",
        "            return v\n",
        "        val = snap_to_voice_onset(st, _sils_tuple, window=window) if _sils_tuple else st  # type: ignore[name-defined]\n",
        "        _snap_cache[key] = val\n",
        "        return val\n",
        "\n",
        "    # --------- write ASS ----------\n",
        "    tmp = kpath.with_suffix(\".tmp.ass\")\n",
        "    with tmp.open(\"w\", encoding=\"utf-8\", newline=\"\\n\") as f:\n",
        "        fw = f.write\n",
        "        fw(\n",
        "            \"[Script Info]\\n\"\n",
        "            \"ScriptType: v4.00+\\n\"\n",
        "            f\"PlayResX: {rw}\\nPlayResY: {rh}\\nWrapStyle: 2\\nScaledBorderAndShadow: yes\\nYCbCr Matrix: TV.709\\n\\n\"\n",
        "        )\n",
        "        fw(\n",
        "            \"[V4+ Styles]\\n\"\n",
        "            \"Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, \"\n",
        "            \"Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, \"\n",
        "            \"Alignment, MarginL, MarginR, MarginV, Encoding\\n\"\n",
        "        )\n",
        "        bold_flag = -1 if force_bold_ui else 0\n",
        "        fw(\n",
        "            f\"Style: Default,{font_info.family},{mapped_fs},&H00{text_bgr},&H00{text_bgr},&H00000000,&H00000000,\"\n",
        "            f\"{bold_flag},0,0,0,100,100,0,0,1,{outline_px},0,7,{margin_h},{margin_h},{margin_v},1\\n\\n\"\n",
        "        )\n",
        "        fw(\"[Events]\\nFormat: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text\\n\")\n",
        "\n",
        "        ts = ass_timestamp  # type: ignore[name-defined]\n",
        "        ass_align_map = {\"left\": 7, \"center\": 8, \"right\": 9}\n",
        "        an_default = ass_align_map.get(align_norm, 7)\n",
        "\n",
        "        for sent in sents:\n",
        "            caps = _split_sentence_to_captions(\n",
        "                sent,\n",
        "                font_info.path,\n",
        "                int(mapped_fs),\n",
        "                int(rw),\n",
        "                int(margin_h),\n",
        "                int(max_words_per_line) or 999,\n",
        "                int(max_words_per_caption) or 999,\n",
        "                nlines,\n",
        "                font_info.family,\n",
        "            )\n",
        "            if not caps:\n",
        "                continue\n",
        "\n",
        "            events: List[str] = []\n",
        "            apnd = events.append\n",
        "            sp_w_global = _space_w(font_info.path, int(mapped_fs), font_info.family)\n",
        "\n",
        "            for li_group, lines in enumerate(caps):\n",
        "                if not lines:\n",
        "                    continue\n",
        "\n",
        "                st_raw = float(lines[0][0].start)\n",
        "                et_raw = float(lines[-1][-1].end)\n",
        "                st_abs = max(0.0, _snap(st_raw, 0.18) + base_off)\n",
        "                et_abs = max(st_abs + min_cap_dur, et_raw + base_off)\n",
        "                st_abs, et_abs = _ensure_interval(st_abs, et_abs, min_cap_dur)\n",
        "\n",
        "                # pacing extension to meet target cps\n",
        "                caption_chars = sum(len(w.text) for ln in lines for w in ln)\n",
        "                current_span = max(0.001, et_abs - st_abs)\n",
        "                need_extend = max(0.0, (caption_chars / float(target_cps)) - current_span)\n",
        "                if max_extend > 0.0 and need_extend > 0.0:\n",
        "                    et_abs += min(max_extend, need_extend)\n",
        "                    st_abs, et_abs = _ensure_interval(st_abs, et_abs, min_cap_dur)\n",
        "\n",
        "                # active word window clamp\n",
        "                act_ws = min(\n",
        "                    max(0.0, _snap(float(w.start), 0.10) + base_off)\n",
        "                    for ln in lines\n",
        "                    for w in ln\n",
        "                )\n",
        "                act_we = max(max(0.0, float(w.end) + base_off) for ln in lines for w in ln)\n",
        "                first_ws, last_we = _ensure_interval(act_ws, act_we, min_cap_dur)\n",
        "                st_abs = min(st_abs, first_ws)\n",
        "                et_abs = max(et_abs, last_we)\n",
        "\n",
        "                for li, ln in enumerate(lines):\n",
        "                    # precompute widths/adv once per line\n",
        "                    tok_w = [_measure_tok_w_cached(font_info.path, int(mapped_fs), w.text, font_info.family) for w in ln]\n",
        "                    adv = _prefix_adv(tok_w, sp_w_global)\n",
        "                    spans, line_w, x_origin = _build_word_spans_from_adv(\n",
        "                        adv, int(rw), int(margin_h), align_norm, sp_w_global\n",
        "                    )\n",
        "                    if not spans:\n",
        "                        continue\n",
        "\n",
        "                    if align_norm == \"center\":\n",
        "                        anchor_x = int(round(x_origin + line_w / 2))\n",
        "                    elif align_norm == \"right\":\n",
        "                        anchor_x = int(round(x_origin + line_w))\n",
        "                    else:\n",
        "                        anchor_x = int(round(x_origin))\n",
        "                    anchor_x = max(0, min(int(rw), int(anchor_x)))\n",
        "\n",
        "                    y_line = int(y_top) + li * (line_h + gap_y)\n",
        "                    txt = _ass_escape(\" \".join(w.text for w in ln))\n",
        "\n",
        "                    # ----- highlight layers -----\n",
        "                    if effective_hl == \"word_bg\":\n",
        "                        # single line bar\n",
        "                        x1_line = max(0, spans[0][0] - pad_x)\n",
        "                        x2_line = min(int(rw), spans[-1][1] + pad_x)\n",
        "                        H = int(line_h + 2 * pad_y)\n",
        "                        yT = max(0, y_line - pad_y)\n",
        "                        yB = min(int(rh), yT + H)\n",
        "                        if x2_line > x1_line + 1:\n",
        "                            path = f\"m {x1_line} {yT} l {x2_line} {yT} {x2_line} {yB} {x1_line} {yB}\"\n",
        "                            apnd(\n",
        "                                f\"Dialogue: 4,{ts(st_abs)},{ts(et_abs)},Default,,0,0,0,\"\n",
        "                                f\"{{\\\\p1\\\\pos(0,0)\\\\bord0\\\\shad0\\\\c&H{box_bgr}&\\\\alpha&H{BOX_ALPHA}&\\\\blur0.8\\\\be0.8}}\"\n",
        "                                f\"{path}{{\\\\p0}}\\n\"\n",
        "                            )\n",
        "\n",
        "                    elif effective_hl in {\"word_pill\", \"word_fill\"}:\n",
        "                        for (x1, x2), w in zip(spans, ln):\n",
        "                            ws = max(0.0, _snap(float(w.start), 0.10) + base_off)\n",
        "                            we = max(ws + min_word_dur, float(w.end) + base_off)\n",
        "                            ws, we = _ensure_interval(ws, we, min_word_dur)\n",
        "                            ws = max(ws, st_abs)\n",
        "                            we = min(we, et_abs)\n",
        "                            if we - ws <= 1e-4:\n",
        "                                continue\n",
        "\n",
        "                            yT_box = max(0, y_line - pad_y)\n",
        "                            H = int(line_h + 2 * pad_y)\n",
        "                            yB_box = min(int(rh), yT_box + H)\n",
        "\n",
        "                            if effective_hl == \"word_pill\":\n",
        "                                FUDGE_L = max(0, int(round(outline_px * 0.6)))\n",
        "                                FUDGE_R = max(0, int(round(outline_px * 0.4)))\n",
        "                                EXTRA_SIDE = max(1, int(round(mapped_fs * 0.03)))\n",
        "                                xL = max(0, x1 - pad_x - FUDGE_L - EXTRA_SIDE)\n",
        "                                xR = min(int(rw), x2 + pad_x + FUDGE_R + EXTRA_SIDE)\n",
        "                                if xR <= xL + 1:\n",
        "                                    continue\n",
        "                                path = f\"m {xL} {yT_box} l {xR} {yT_box} {xR} {yB_box} {xL} {yB_box}\"\n",
        "                                apnd(\n",
        "                                    f\"Dialogue: 5,{ts(ws)},{ts(we)},Default,,0,0,0,\"\n",
        "                                    f\"{{\\\\p1\\\\pos(0,0)\\\\bord0\\\\shad0\\\\c&H{box_bgr}&\\\\alpha&H{BOX_ALPHA}&\\\\blur0.8\\\\be0.8}}\"\n",
        "                                    f\"{path}{{\\\\p0}}\\n\"\n",
        "                                )\n",
        "                            else:\n",
        "                                clip_left = max(0, x1 + 1)\n",
        "                                clip_right = min(int(rw), x2 - 1)\n",
        "                                if clip_right <= clip_left + 1:\n",
        "                                    continue\n",
        "                                clip_tag = f\"\\\\clip({clip_left},{yT_box},{clip_right},{yB_box})\"\n",
        "                                tag = (\n",
        "                                    \"{\\\\q2\\\\an\" + str(an_default) +\n",
        "                                    f\"\\\\pos({anchor_x},{y_line})\" +\n",
        "                                    f\"\\\\bord0\\\\shad0\\\\1a&H00&\\\\3a&H00&\\\\3c&H000000&\\\\c&H{box_bgr}&{clip_tag}\" +\n",
        "                                    \"}\"\n",
        "                                )\n",
        "                                apnd(\"Dialogue: 11,\" + ts(ws) + \",\" + ts(we) + \",Default,,0,0,0,\" + tag + txt + \"\\n\")\n",
        "\n",
        "                    # ----- text layer -----\n",
        "                    text_tag = (\n",
        "                        \"{\\\\q2\\\\an\" + str(an_default) +\n",
        "                        f\"\\\\pos({anchor_x},{y_line})\" +\n",
        "                        f\"\\\\bord{outline_px}\\\\shad0.7\\\\1a&H00&\\\\3a&H00&\\\\3c&H000000&\\\\c&H{text_bgr}&\" +\n",
        "                        \"}\"\n",
        "                    )\n",
        "                    apnd(\"Dialogue: 10,\" + ts(st_abs) + \",\" + ts(et_abs) + \",Default,,0,0,0,\" + text_tag + txt + \"\\n\")\n",
        "\n",
        "            if events:\n",
        "                fw(''.join(events))\n",
        "\n",
        "    os.replace(tmp, kpath)\n",
        "    return kpath\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "388e0832",
      "metadata": {
        "id": "388e0832",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title 7) Build Main Track — Clean, Font-locked, BT.709, NVENC→x264 fallback (FINAL API, Refactored • SCA v3)\n",
        "# Burns ASS at subscale, then upscales. Honors ASS_FONT_DIR for reliable font pick.\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import hashlib\n",
        "import json\n",
        "from pathlib import Path\n",
        "from typing import List, Optional, Tuple\n",
        "from shutil import which\n",
        "\n",
        "# Assumptions: _run, _json_dump, WORK_META, META, WORK_CACHE, ffesc, NVENC_AVAILABLE\n",
        "# effective_render_size, probe_image_wh, sha1_file\n",
        "\n",
        "# ---------------------------- small probes + cache ----------------------------\n",
        "\n",
        "def _path_sig(p: Path) -> Tuple[int, int]:\n",
        "    \"\"\"(mtime, size) tuple for cache keys; raises if path is missing.\"\"\"\n",
        "    st = p.stat()\n",
        "    return int(st.st_mtime), int(st.st_size)\n",
        "\n",
        "\n",
        "def has_audio_stream_cached(p: Optional[Path]) -> bool:\n",
        "    \"\"\"\n",
        "    Return True if the input has an audio stream, caching by file identity.\n",
        "    Falls back to False on probing failure.\n",
        "    \"\"\"\n",
        "    if not p or not p.exists():\n",
        "        return False\n",
        "    mt, sz = _path_sig(p)\n",
        "    key = f\"audiostream::{p}::{mt}::{sz}\"\n",
        "    if key in META:  # type: ignore[name-defined]\n",
        "        return bool(META[key])  # type: ignore[index]\n",
        "    try:\n",
        "        r = _run(  # type: ignore[name-defined]\n",
        "            [\"ffprobe\", \"-v\", \"error\", \"-select_streams\", \"a:0\", \"-show_entries\", \"stream=index\",\n",
        "             \"-of\", \"compact=p=0:nk=1\", str(p)],\n",
        "            check=False,\n",
        "        ).stdout.strip()\n",
        "        ok = bool(r)\n",
        "    except Exception:\n",
        "        ok = False\n",
        "    META[key] = ok  # type: ignore[name-defined]\n",
        "    _json_dump(WORK_META, META)  # type: ignore[name-defined]\n",
        "    return ok\n",
        "\n",
        "\n",
        "def probe_duration_cached(p: Optional[Path]) -> float:\n",
        "    \"\"\"\n",
        "    Return media duration in seconds using ffprobe, cached by file identity.\n",
        "    Returns 0.0 on error.\n",
        "    \"\"\"\n",
        "    if not p or not p.exists():\n",
        "        return 0.0\n",
        "    mt, sz = _path_sig(p)\n",
        "    key = f\"dur::{p}::{mt}::{sz}\"\n",
        "    if key in META:  # type: ignore[name-defined]\n",
        "        return float(META[key])  # type: ignore[index]\n",
        "    try:\n",
        "        r = _run(  # type: ignore[name-defined]\n",
        "            [\"ffprobe\", \"-v\", \"error\", \"-show_entries\", \"format=duration\",\n",
        "             \"-of\", \"default=nw=1:nk=1\", str(p)],\n",
        "            check=False,\n",
        "        ).stdout.strip()\n",
        "        d = float(r) if r else 0.0\n",
        "    except Exception:\n",
        "        d = 0.0\n",
        "    META[key] = d  # type: ignore[name-defined]\n",
        "    _json_dump(WORK_META, META)  # type: ignore[name-defined]\n",
        "    return d\n",
        "\n",
        "\n",
        "# ---------------------------- ffmpeg helpers ----------------------------\n",
        "\n",
        "def _existing_dirs(paths: List[Path]) -> List[Path]:\n",
        "    \"\"\"Return unique, existing directories from the given list, preserving order.\"\"\"\n",
        "    out: List[Path] = []\n",
        "    seen: set[Path] = set()\n",
        "    for p in paths:\n",
        "        try:\n",
        "            q = Path(p).expanduser().resolve()\n",
        "            if q.exists() and q.is_dir() and q not in seen:\n",
        "                out.append(q)\n",
        "                seen.add(q)\n",
        "        except Exception:\n",
        "            continue\n",
        "    return out\n",
        "\n",
        "\n",
        "def _ff_has_filter(name: str) -> bool:\n",
        "    \"\"\"True if ffmpeg has the named filter (cached).\"\"\"\n",
        "    name = f\" {name.strip()} \"\n",
        "    try:\n",
        "        out = _run([\"ffmpeg\", \"-hide_banner\", \"-filters\"], check=False).stdout  # type: ignore[name-defined]\n",
        "    except Exception:\n",
        "        return False\n",
        "    return name in out\n",
        "\n",
        "\n",
        "def _fonts_resolvable() -> bool:\n",
        "    \"\"\"\n",
        "    Ensure at least one font family is resolvable by libass/fontconfig.\n",
        "    Prefer fc-match; fall back to ~/.fonts presence.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if which(\"fc-match\"):\n",
        "            r = _run([\"fc-match\", \"-v\", \"Inter,DejaVu Sans\"], check=False).stdout  # type: ignore[name-defined]\n",
        "            return 'file: \"' in (r or \"\")\n",
        "    except Exception:\n",
        "        pass\n",
        "    try:\n",
        "        fdir = Path(\"~/.fonts\").expanduser()\n",
        "        if fdir.exists():\n",
        "            for ext in (\".ttf\", \".otf\", \".ttc\", \".otc\"):\n",
        "                if any(fdir.glob(f\"*{ext}\")):\n",
        "                    return True\n",
        "    except Exception:\n",
        "        pass\n",
        "    return False\n",
        "\n",
        "\n",
        "def _preflight_requirements() -> None:\n",
        "    \"\"\"Fail-fast checks with explicit remediation; no side-effects.\"\"\"\n",
        "    missing = [n for n in (\"_run\", \"WORK_CACHE\", \"ffesc\", \"effective_render_size\", \"probe_image_wh\", \"sha1_file\") if n not in globals()]\n",
        "    if missing:\n",
        "        raise RuntimeError(f\"Missing dependencies: {', '.join(missing)}. HOW_TO_FIX: run Roots/Core/Utils cells first.\")\n",
        "    if which(\"ffmpeg\") is None or which(\"ffprobe\") is None:\n",
        "        raise RuntimeError(\"ffmpeg/ffprobe not found on PATH. HOW_TO_FIX: install ffmpeg or run your Install cell.\")\n",
        "    wc = globals().get(\"WORK_CACHE\")\n",
        "    if not isinstance(wc, Path) or not wc.exists() or not wc.is_dir():  # type: ignore[func-returns-value]\n",
        "        raise RuntimeError(\"WORK_CACHE directory is missing. HOW_TO_FIX: run the Roots & Cache cell to initialize paths.\")\n",
        "    if not _ff_has_filter(\"subtitles\"):\n",
        "        raise RuntimeError(\"WHAT: FFmpeg subtitles filter check\\nWHY: 'subtitles' filter (libass) not available\\nHOW_TO_FIX: Install ffmpeg with libass enabled.\")\n",
        "    if not _fonts_resolvable():\n",
        "        raise RuntimeError(\"WHAT: Font resolution\\nWHY: No resolvable font family for libass\\nHOW_TO_FIX: Ensure at least one TTF/OTF is in ~/.fonts or system fonts (e.g., DejaVu Sans).\")\n",
        "\n",
        "\n",
        "def _compute_loudnorm_params(audio_path: Path) -> Optional[str]:\n",
        "    \"\"\"\n",
        "    Run a fast EBU R128 first pass and return a parameterized second-pass string.\n",
        "    Returns None if parsing fails or loudnorm is unavailable.\n",
        "    \"\"\"\n",
        "    if not has_audio_stream_cached(audio_path) or not _ff_has_filter(\"loudnorm\"):\n",
        "        return None\n",
        "    cmd = [\n",
        "        \"ffmpeg\", \"-hide_banner\", \"-nostdin\", \"-v\", \"error\",\n",
        "        \"-i\", str(audio_path),\n",
        "        \"-af\", \"loudnorm=I=-16:LRA=11:TP=-1.5:print_format=json\",\n",
        "        \"-f\", \"null\", \"-\"\n",
        "    ]\n",
        "    cp = _run(cmd, check=False)  # type: ignore[name-defined]\n",
        "    log = (cp.stderr or \"\") + (cp.stdout or \"\")\n",
        "    # Extract the last JSON object (ffmpeg prints one per stream)\n",
        "    start = log.rfind(\"{\")\n",
        "    end = log.rfind(\"}\")\n",
        "    if start == -1 or end == -1 or end <= start:\n",
        "        return None\n",
        "    try:\n",
        "        data = json.loads(log[start:end+1])\n",
        "        mi = data.get(\"input_i\"); mlra = data.get(\"input_lra\"); mtp = data.get(\"input_tp\")\n",
        "        mth = data.get(\"input_thresh\"); off = data.get(\"target_offset\", data.get(\"offset\"))\n",
        "        if None in (mi, mlra, mtp, mth, off):\n",
        "            return None\n",
        "        return (\n",
        "            \"loudnorm=I=-16:LRA=11:TP=-1.5:\"\n",
        "            f\"measured_I={mi}:measured_LRA={mlra}:measured_TP={mtp}:\"\n",
        "            f\"measured_thresh={mth}:offset={off}:linear=true:print_format=none\"\n",
        "        )\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "\n",
        "def _ass_probe(subtitles_filter: str) -> None:\n",
        "    \"\"\"\n",
        "    Minimal ASS parse probe (≤0.1s). Ensures filter arguments are valid.\n",
        "    \"\"\"\n",
        "    cmd = [\n",
        "        \"ffmpeg\", \"-hide_banner\", \"-loglevel\", \"error\", \"-nostdin\",\n",
        "        \"-f\", \"lavfi\", \"-i\", \"color=c=black:s=16x16:d=0.1\",\n",
        "        \"-vf\", subtitles_filter,\n",
        "        \"-f\", \"null\", \"-\"\n",
        "    ]\n",
        "    cp = _run(cmd, check=False)  # type: ignore[name-defined]\n",
        "    if cp.returncode != 0:\n",
        "        err = (cp.stderr or \"\").strip()\n",
        "        raise RuntimeError(\n",
        "            \"WHAT: ASS probe\\n\"\n",
        "            f\"WHY: ffmpeg subtitles filter failed to parse ({err or 'unknown error'})\\n\"\n",
        "            \"HOW_TO_FIX: Verify ASS path, fontsdir, and that ffmpeg is built with libass.\"\n",
        "        )\n",
        "\n",
        "\n",
        "# ---------------------------- video filtergraph ----------------------------\n",
        "\n",
        "def _build_video_filters_main(\n",
        "    bg_w: int,\n",
        "    bg_h: int,\n",
        "    render_w: int,\n",
        "    render_h: int,\n",
        "    do_subscale: bool,\n",
        "    subtitles_filter: str,\n",
        "    # inert CTA/outro params kept for API stability\n",
        "    main_d: float,\n",
        "    outro_d: float,\n",
        "    cta_times: Optional[List[float]],\n",
        "    cta_d: float,\n",
        "    cta_key_hex: str,\n",
        "    cta_similarity: float,\n",
        "    cta_blend: float,\n",
        "    cta_position: str,\n",
        ") -> Tuple[List[str], str]:\n",
        "    \"\"\"\n",
        "    Main-track filtergraph:\n",
        "      1) Fit background to 1920x1080 (pillarbox/letterbox), setsar=1\n",
        "      2) Optional downscale to render_w x render_h, burn ASS, upscale back to 1080p\n",
        "      3) Output label is 'vfinal'\n",
        "    \"\"\"\n",
        "    vf: List[str] = []\n",
        "    cur = \"vb\"\n",
        "\n",
        "    if int(bg_w) == 1920 and int(bg_h) == 1080:\n",
        "        vf.append(\"[0:v]setsar=1[vb]\")\n",
        "    else:\n",
        "        vf.append(\n",
        "            \"[0:v]scale=1920:1080:force_original_aspect_ratio=decrease,\"\n",
        "            \"pad=1920:1080:-1:-1:color=black,setsar=1[vb]\"\n",
        "        )\n",
        "\n",
        "    if do_subscale:\n",
        "        vf.append(f\"[{cur}]scale={int(render_w)}:{int(render_h)}:flags=lanczos[vbs]\"); cur = \"vbs\"\n",
        "        vf.append(f\"[{cur}]{subtitles_filter}[vss]\"); cur = \"vss\"\n",
        "        vf.append(f\"[{cur}]scale=1920:1080:flags=lanczos,format=yuv420p[vfinal]\")\n",
        "    else:\n",
        "        vf.append(f\"[{cur}]{subtitles_filter},format=yuv420p[vfinal]\")\n",
        "\n",
        "    return vf, \"vfinal\"\n",
        "\n",
        "\n",
        "# ---------------------------- main build ----------------------------\n",
        "\n",
        "def build_main_track_cached(\n",
        "    bg: Path,\n",
        "    ass_file: Path,\n",
        "    audio_norm: Path,\n",
        "    intro_delay: float,\n",
        "    total_d: float,\n",
        "    fps: int,\n",
        "    subscale: float,\n",
        ") -> Path:\n",
        "    \"\"\"\n",
        "    Assemble main track with ASS burn-in and NVENC→x264 fallback.\n",
        "    Deterministic cache key uses inputs' content/identity and render parameters.\n",
        "    \"\"\"\n",
        "    _preflight_requirements()\n",
        "\n",
        "    if not bg or not Path(bg).exists():\n",
        "        raise FileNotFoundError(f\"Background not found: {bg}\")\n",
        "    if not ass_file or not Path(ass_file).exists():\n",
        "        raise FileNotFoundError(f\"ASS file not found: {ass_file}\")\n",
        "    if total_d <= 0:\n",
        "        raise ValueError(\"total_d must be > 0\")\n",
        "\n",
        "    # SCA clamp subscale\n",
        "    subscale = float(max(0.70, min(1.00, subscale)))\n",
        "\n",
        "    fps_i = int(max(1, fps))\n",
        "    # Use shared helper directly (no duplicate wrapper)\n",
        "    rw, rh, do_sub = effective_render_size(1920, 1080, subscale)  # type: ignore[name-defined]\n",
        "\n",
        "    bw, bh = probe_image_wh(bg)  # type: ignore[name-defined]\n",
        "    if bw <= 0 or bh <= 0:\n",
        "        # Fallback to pipeline base; ffprobe sometimes fails on odd stills\n",
        "        bw, bh = 1920, 1080\n",
        "\n",
        "    # Cache key\n",
        "    bg_mt, bg_sz = _path_sig(bg)\n",
        "    aud_sha = sha1_file(audio_norm) if (audio_norm and Path(audio_norm).exists()) else None  # type: ignore[name-defined]\n",
        "    key = {\n",
        "        \"v\": 22,\n",
        "        \"bg\": str(bg), \"bg_m\": bg_mt, \"bg_s\": bg_sz,\n",
        "        \"ass\": sha1_file(ass_file),  # type: ignore[name-defined]\n",
        "        \"aud\": aud_sha,\n",
        "        \"aud_has\": has_audio_stream_cached(audio_norm),\n",
        "        \"fps\": fps_i,\n",
        "        \"rw\": int(rw), \"rh\": int(rh), \"subscale\": float(subscale), \"do_sub\": bool(do_sub),\n",
        "        \"bw\": int(bw), \"bh\": int(bh),\n",
        "        \"intro_ms\": int(round(intro_delay * 1000)),\n",
        "        \"total_ms\": int(round(total_d * 1000)),\n",
        "    }\n",
        "    out = WORK_CACHE / f\"main_{hashlib.sha1(json.dumps(key, sort_keys=True).encode()).hexdigest()}.mp4\"  # type: ignore[name-defined]\n",
        "    if out.exists() and out.stat().st_size > 0:\n",
        "        return out\n",
        "\n",
        "    # Inputs\n",
        "    inputs: List[str] = [\n",
        "        \"-thread_queue_size\", \"512\",\n",
        "        \"-f\", \"image2\", \"-loop\", \"1\",\n",
        "        \"-framerate\", str(fps_i),\n",
        "        \"-i\", str(bg),\n",
        "    ]\n",
        "    if has_audio_stream_cached(audio_norm):\n",
        "        inputs += [\"-thread_queue_size\", \"512\", \"-i\", str(audio_norm)]\n",
        "        audio_label = \"[1:a]\"\n",
        "    else:\n",
        "        inputs += [\"-f\", \"lavfi\", \"-i\", \"anullsrc=r=48000:cl=stereo\"]\n",
        "        audio_label = \"[1:a]\"\n",
        "\n",
        "    # Fonts and subtitles filter\n",
        "    ass_esc = ffesc(str(ass_file))  # type: ignore[name-defined]\n",
        "    font_dirs: List[Path] = _existing_dirs([Path(\"~/.fonts\").expanduser()])\n",
        "    try:\n",
        "        ar = ASSETS_ROOT if isinstance(ASSETS_ROOT, Path) else Path(ASSETS_ROOT)  # type: ignore[name-defined]\n",
        "        font_dirs += _existing_dirs([ar])\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    force_font = \"Inter 18pt ExtraBold\"\n",
        "    force_outline = 4\n",
        "    force_style = ffesc(f\"Fontname={force_font},Outline={int(force_outline)},Shadow=0,BorderStyle=3\")  # type: ignore[name-defined]\n",
        "\n",
        "    if font_dirs:\n",
        "        fontsdirs_arg = ffesc(str(font_dirs[0]))  # type: ignore[name-defined]\n",
        "        for extra in font_dirs[1:]:\n",
        "            fontsdirs_arg += \"|\" + ffesc(str(extra))  # type: ignore[name-defined]\n",
        "        sub_filter = (\n",
        "            f\"subtitles=filename='{ass_esc}':fontsdir='{fontsdirs_arg}':charenc=UTF-8:force_style='{force_style}'\"\n",
        "        )\n",
        "    else:\n",
        "        sub_filter = f\"subtitles=filename='{ass_esc}':charenc=UTF-8:force_style='{force_style}'\"\n",
        "\n",
        "    # ASS probe (parse-only; fast)\n",
        "    _ass_probe(sub_filter)\n",
        "\n",
        "    vf_parts, v_final_label = _build_video_filters_main(\n",
        "        int(bw), int(bh),\n",
        "        int(rw), int(rh),\n",
        "        bool(do_sub),\n",
        "        sub_filter,\n",
        "        main_d=float(max(0.0, total_d - intro_delay)),\n",
        "        outro_d=0.0,\n",
        "        cta_times=None,\n",
        "        cta_d=0.0,\n",
        "        cta_key_hex=\"0x00FF00\",\n",
        "        cta_similarity=0.42,\n",
        "        cta_blend=0.08,\n",
        "        cta_position=\"Middle\",\n",
        "    )\n",
        "\n",
        "    # Audio processing chain (SCA: EBU R128 order with deterministic downgrades)\n",
        "    dms = max(0, int(round(intro_delay * 1000)))\n",
        "    af: List[str] = [\n",
        "        f\"{audio_label}asetpts=PTS-STARTPTS,aresample=48000:async=1[min_a]\",\n",
        "        f\"[min_a]adelay={dms}|{dms}:all=1[aud_d]\",\n",
        "    ]\n",
        "    ln2 = _compute_loudnorm_params(audio_norm) if has_audio_stream_cached(audio_norm) else None\n",
        "    if ln2:\n",
        "        af.append(f\"[aud_d]{ln2}[aud_n]\")\n",
        "    elif _ff_has_filter(\"loudnorm\"):\n",
        "        af.append(\"[aud_d]loudnorm=I=-16:LRA=11:TP=-1.5[aud_n]\")\n",
        "    elif _ff_has_filter(\"dynaudnorm\"):\n",
        "        af.append(\"[aud_d]dynaudnorm=f=150:g=15[aud_n]\")\n",
        "    else:\n",
        "        af.append(\"[aud_d]volume=1.0[aud_n]\")\n",
        "    if _ff_has_filter(\"alimiter\"):\n",
        "        af.append(\"[aud_n]alimiter=limit=0.95[afinal]\")\n",
        "    else:\n",
        "        af.append(\"[aud_n]volume=0.98[afinal]\")\n",
        "\n",
        "    filter_complex = \";\".join(vf_parts + af)\n",
        "\n",
        "    # Common encoder flags\n",
        "    common = [\n",
        "        \"-threads\", \"0\",\n",
        "        \"-filter_threads\", \"2\",\n",
        "        \"-filter_complex_threads\", \"2\",\n",
        "        \"-sws_flags\", \"lanczos+accurate_rnd+full_chroma_int\",\n",
        "    ]\n",
        "    v_color = [\n",
        "        \"-colorspace\", \"bt709\",\n",
        "        \"-color_primaries\", \"bt709\",\n",
        "        \"-color_trc\", \"bt709\",\n",
        "        \"-color_range\", \"tv\",\n",
        "    ]\n",
        "    v_nvenc = [\n",
        "        \"-c:v\", \"h264_nvenc\",\n",
        "        \"-preset\", \"p4\", \"-tune\", \"hq\",\n",
        "        \"-rc\", \"vbr\", \"-cq\", \"19\",\n",
        "        \"-b:v\", \"6M\", \"-maxrate\", \"8M\", \"-bufsize\", \"12M\",\n",
        "        \"-g\", str(fps_i * 2), \"-bf\", \"2\",\n",
        "        \"-profile:v\", \"high\",\n",
        "        \"-pix_fmt\", \"yuv420p\",\n",
        "        \"-movflags\", \"+faststart\",\n",
        "        *v_color,\n",
        "    ]\n",
        "    v_x264 = [\n",
        "        \"-c:v\", \"libx264\",\n",
        "        \"-preset\", \"fast\", \"-crf\", \"21\",\n",
        "        \"-g\", str(fps_i * 2), \"-bf\", \"2\",\n",
        "        \"-profile:v\", \"high\",\n",
        "        \"-pix_fmt\", \"yuv420p\",\n",
        "        \"-movflags\", \"+faststart\",\n",
        "        *v_color,\n",
        "    ]\n",
        "\n",
        "    tmp = out.with_suffix(\".tmp.mp4\")\n",
        "    try:\n",
        "        if tmp.exists():\n",
        "            tmp.unlink()\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    def _encode(vargs: List[str]) -> None:\n",
        "        \"\"\"Run the ffmpeg encode with the provided video args.\"\"\"\n",
        "        cmd = [\n",
        "            \"ffmpeg\", \"-hide_banner\", \"-nostdin\", \"-y\",\n",
        "            \"-loglevel\", \"error\",\n",
        "            *common, *inputs,\n",
        "            \"-filter_complex\", filter_complex,\n",
        "            \"-map\", f\"[{v_final_label}]\", \"-map\", \"[afinal]\",\n",
        "            \"-t\", str(float(total_d)),\n",
        "            \"-r\", str(fps_i),\n",
        "            *vargs,\n",
        "            \"-c:a\", \"aac\", \"-b:a\", \"160k\", \"-ac\", \"2\",\n",
        "            \"-map_metadata\", \"-1\", \"-map_chapters\", \"-1\",\n",
        "            \"-max_muxing_queue_size\", \"1024\",\n",
        "            str(tmp),\n",
        "        ]\n",
        "        _run(cmd)  # type: ignore[name-defined]\n",
        "\n",
        "    used_nv = False\n",
        "    try:\n",
        "        if NVENC_AVAILABLE:  # type: ignore[name-defined]\n",
        "            _encode(v_nvenc); used_nv = True\n",
        "        else:\n",
        "            _encode(v_x264)\n",
        "    except Exception:\n",
        "        if used_nv:\n",
        "            _encode(v_x264)\n",
        "        else:\n",
        "            raise\n",
        "\n",
        "    if not tmp.exists() or tmp.stat().st_size <= 0:\n",
        "        raise RuntimeError(\"Main track encode failed. HOW_TO_FIX: verify NVENC availability, or disable it and ensure libx264 + ffmpeg are installed.\")\n",
        "    tmp.replace(out)\n",
        "    return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "042b089e",
      "metadata": {
        "id": "042b089e",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title 8) Asset Staging & Discovery — Hidden (HARDLOCK v3 • SCA)\n",
        "# Case-insensitive discovery and staging from Assets folder (atomic copy, safe fallbacks).\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import unicodedata\n",
        "from functools import lru_cache\n",
        "from pathlib import Path\n",
        "from typing import Any, Iterable, List, Optional, Tuple\n",
        "\n",
        "# =========================\n",
        "# Constants and categories\n",
        "# =========================\n",
        "\n",
        "AUDIO_EXTS = {\".mp3\", \".wav\", \".m4a\", \".aac\", \".flac\", \".ogg\"}\n",
        "BG_EXTS    = {\".png\", \".jpg\", \".jpeg\", \".webp\"}\n",
        "MP4_EXTS   = {\".mp4\"}\n",
        "FONT_EXTS  = {\".ttf\", \".otf\", \".ttc\", \".otc\"}\n",
        "\n",
        "\n",
        "# =========================\n",
        "# Prefight (no heavy I/O)\n",
        "# =========================\n",
        "\n",
        "def _preflight_assets() -> Path:\n",
        "    \"\"\"\n",
        "    Assert required shared globals exist and WORK_ASSETS is writable.\n",
        "    No heavy I/O; creates and deletes a tiny temp file to confirm writability.\n",
        "    \"\"\"\n",
        "    missing: List[str] = []\n",
        "    for name in (\"WORK_ASSETS\", \"_atomic_copy\"):\n",
        "        if name not in globals():\n",
        "            missing.append(name)\n",
        "    if missing:\n",
        "        raise RuntimeError(\n",
        "            \"WHAT: Missing shared dependencies for Asset Staging\\n\"\n",
        "            f\"WHY: Globals not defined: {', '.join(missing)}\\n\"\n",
        "            \"HOW_TO_FIX: Run the Roots & Cache cell (defines WORK_ASSETS) and the Font Manager cell (defines _atomic_copy).\"\n",
        "        )\n",
        "\n",
        "    wa_obj = globals()[\"WORK_ASSETS\"]\n",
        "    work_assets = wa_obj if isinstance(wa_obj, Path) else Path(wa_obj)\n",
        "    try:\n",
        "        work_assets = work_assets.expanduser().resolve()\n",
        "    except Exception:\n",
        "        work_assets = Path(wa_obj)  # type: ignore[arg-type]\n",
        "    work_assets.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Writable check (tiny temp)\n",
        "    probe = work_assets / \".w_probe.tmp\"\n",
        "    try:\n",
        "        probe.write_bytes(b\"\")\n",
        "        probe.unlink(missing_ok=True)  # type: ignore[call-arg]\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(\n",
        "            \"WHAT: WORK_ASSETS not writable\\n\"\n",
        "            f\"WHY: {e}\\n\"\n",
        "            \"HOW_TO_FIX: Change WORK_ASSETS to a writable directory or fix filesystem permissions.\"\n",
        "        )\n",
        "    return work_assets\n",
        "\n",
        "\n",
        "# =========================\n",
        "# Unicode & path utilities\n",
        "# =========================\n",
        "\n",
        "def _norm_casefold(s: str) -> str:\n",
        "    \"\"\"Case-insensitive, NFC-normalized key for robust filename matching.\"\"\"\n",
        "    return unicodedata.normalize(\"NFC\", s).casefold()\n",
        "\n",
        "\n",
        "def _path_signature(path: Path) -> Tuple[int, int]:\n",
        "    \"\"\"Stable signature (mtime, size) for quick equality checks; follows symlinks.\"\"\"\n",
        "    st = path.stat()\n",
        "    return int(st.st_mtime), int(st.st_size)\n",
        "\n",
        "\n",
        "def _same_enough(src: Path, dst: Path) -> bool:\n",
        "    \"\"\"True if dst exists and matches src by (mtime, size). Any error -> False.\"\"\"\n",
        "    try:\n",
        "        return dst.exists() and _path_signature(src) == _path_signature(dst)\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "\n",
        "def _existing_dir(p: Optional[Path]) -> Optional[Path]:\n",
        "    \"\"\"Return resolved directory path if it exists; else None.\"\"\"\n",
        "    if not p:\n",
        "        return None\n",
        "    try:\n",
        "        q = Path(p).expanduser().resolve()\n",
        "        return q if q.exists() and q.is_dir() else None\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "\n",
        "def _add_if_dir(paths: List[Path], candidate: Optional[Path]) -> None:\n",
        "    \"\"\"Append candidate if it exists and is a directory (order-preserving, no duplicates).\"\"\"\n",
        "    q = _existing_dir(candidate)\n",
        "    if q and q not in paths:\n",
        "        paths.append(q)\n",
        "\n",
        "\n",
        "# =========================\n",
        "# Environment resolution\n",
        "# =========================\n",
        "\n",
        "def _ensure_work_assets() -> Path:\n",
        "    \"\"\"Resolve and ensure WORK_ASSETS directory exists or raise RuntimeError.\"\"\"\n",
        "    wa = _preflight_assets()  # also asserts _atomic_copy presence\n",
        "    return wa\n",
        "\n",
        "\n",
        "@lru_cache(maxsize=8)\n",
        "def _bases_from_inputs(user_bases_key: Optional[Tuple[str, ...]] = None) -> List[Path]:\n",
        "    \"\"\"\n",
        "    Collect base asset folders from:\n",
        "      - WORK_ASSETS\n",
        "      - user_bases (if provided)\n",
        "      - DRIVE_ASSETS_FOLDERS() (if available)\n",
        "      - ASSETS_ROOT\n",
        "    Keep only existing, unique, resolved paths (order-preserving).\n",
        "    Memoized for stability across repeated lookups.\n",
        "    \"\"\"\n",
        "    bases: List[Path] = []\n",
        "    # WORK_ASSETS first\n",
        "    try:\n",
        "        _add_if_dir(bases, _ensure_work_assets())\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    # User-provided list or dynamic drive folders\n",
        "    if user_bases_key is not None:\n",
        "        for b in user_bases_key:\n",
        "            _add_if_dir(bases, Path(b))\n",
        "    else:\n",
        "        try:\n",
        "            for b in DRIVE_ASSETS_FOLDERS():  # type: ignore[name-defined]\n",
        "                _add_if_dir(bases, b)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    # ASSETS_ROOT fallback\n",
        "    try:\n",
        "        root = ASSETS_ROOT if isinstance(ASSETS_ROOT, Path) else Path(ASSETS_ROOT)  # type: ignore[name-defined]\n",
        "        _add_if_dir(bases, root)\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    # De-dup by resolved path while preserving order\n",
        "    seen = set()\n",
        "    uniq: List[Path] = []\n",
        "    for p in bases:\n",
        "        try:\n",
        "            rp = p.resolve()\n",
        "        except Exception:\n",
        "            rp = p\n",
        "        if rp not in seen:\n",
        "            uniq.append(rp)\n",
        "            seen.add(rp)\n",
        "    return uniq\n",
        "\n",
        "\n",
        "def _bases_from_list(user_bases: Optional[List[Path]]) -> List[Path]:\n",
        "    \"\"\"Wrapper to keep cached key deterministic from a list of paths.\"\"\"\n",
        "    if user_bases is None:\n",
        "        return _bases_from_inputs(None)\n",
        "    key = tuple(str(Path(b)) for b in user_bases)\n",
        "    return _bases_from_inputs(key)\n",
        "\n",
        "\n",
        "# =========================\n",
        "# Discovery helpers\n",
        "# =========================\n",
        "\n",
        "def _iter_top_files(base: Path) -> Iterable[Path]:\n",
        "    \"\"\"Efficient top-level file iterator using os.scandir (no recursion).\"\"\"\n",
        "    try:\n",
        "        with os.scandir(base) as it:\n",
        "            for de in it:\n",
        "                if de.is_file():\n",
        "                    yield Path(de.path)\n",
        "    except Exception:\n",
        "        return\n",
        "\n",
        "\n",
        "def _find_in_candidates(name: str, bases: List[Path]) -> Optional[Path]:\n",
        "    \"\"\"\n",
        "    Case-insensitive filename lookup across 'bases' (top-level only).\n",
        "    Try exact filename first; then normalized match via scandir.\n",
        "    \"\"\"\n",
        "    if not name:\n",
        "        return None\n",
        "    target_name = Path(str(name)).name\n",
        "\n",
        "    # Fast path: exact\n",
        "    for base in bases:\n",
        "        try:\n",
        "            p = base / target_name\n",
        "            if p.exists() and p.is_file():\n",
        "                return p\n",
        "        except Exception:\n",
        "            continue\n",
        "\n",
        "    # Slow path: normalized compare\n",
        "    key = _norm_casefold(target_name)\n",
        "    for base in bases:\n",
        "        for f in _iter_top_files(base):\n",
        "            if _norm_casefold(f.name) == key:\n",
        "                return f\n",
        "    return None\n",
        "\n",
        "\n",
        "def _copy_to_work(src: Path) -> Path:\n",
        "    \"\"\"\n",
        "    Ensure 'src' exists in WORK_ASSETS with atomic copy; skip if already identical.\n",
        "    Returns destination path.\n",
        "    \"\"\"\n",
        "    dst = _ensure_work_assets() / src.name\n",
        "    if not _same_enough(src, dst):\n",
        "        # Use shared atomic copy from Font Manager cell; do not re-declare here.\n",
        "        _atomic_copy(src, dst)  # type: ignore[name-defined]\n",
        "    return dst\n",
        "\n",
        "\n",
        "def _list_media_from(base: Path) -> Tuple[List[str], List[str], List[str], List[str]]:\n",
        "    \"\"\"\n",
        "    Collect file names (top-level only) for UI lists.\n",
        "    Sorted case-insensitively. Returns (audio, backgrounds, mp4s, fonts).\n",
        "    \"\"\"\n",
        "    if not base or not base.exists() or not base.is_dir():\n",
        "        return [], [], [], []\n",
        "\n",
        "    audio: List[str] = []\n",
        "    backgrounds: List[str] = []\n",
        "    mp4s: List[str] = []\n",
        "    fonts: List[str] = []\n",
        "\n",
        "    for f in _iter_top_files(base):\n",
        "        ext = f.suffix.lower()\n",
        "        name = f.name\n",
        "        if ext in AUDIO_EXTS:\n",
        "            audio.append(name)\n",
        "        elif ext in BG_EXTS:\n",
        "            backgrounds.append(name)\n",
        "        elif ext in MP4_EXTS:\n",
        "            mp4s.append(name)\n",
        "        elif ext in FONT_EXTS:\n",
        "            fonts.append(name)\n",
        "\n",
        "    key = _norm_casefold\n",
        "    return (\n",
        "        sorted(audio, key=key),\n",
        "        sorted(backgrounds, key=key),\n",
        "        sorted(mp4s, key=key),\n",
        "        sorted(fonts, key=key),\n",
        "    )\n",
        "\n",
        "\n",
        "def _uniq_casefold(items: List[str]) -> List[str]:\n",
        "    \"\"\"Case-insensitive de-duplication, preserving first occurrence.\"\"\"\n",
        "    seen = set()\n",
        "    out: List[str] = []\n",
        "    for s in items:\n",
        "        k = _norm_casefold(s)\n",
        "        if k not in seen:\n",
        "            out.append(s)\n",
        "            seen.add(k)\n",
        "    return out\n",
        "\n",
        "\n",
        "# =========================\n",
        "# Public API (unchanged)\n",
        "# =========================\n",
        "\n",
        "def stage_by_name(name: Optional[str], drive_asset_folders: Optional[List[Path]] = None) -> Optional[Path]:\n",
        "    \"\"\"\n",
        "    Locate a filename across asset bases (case-insensitive, top-level only),\n",
        "    then stage it into WORK_ASSETS if the file resides elsewhere.\n",
        "    Returns staged Path or None if not found.\n",
        "    \"\"\"\n",
        "    if not name or str(name).strip().lower() == \"none\":\n",
        "        return None\n",
        "    bases = _bases_from_list(drive_asset_folders)\n",
        "    candidate = _find_in_candidates(name, bases)\n",
        "    if not candidate:\n",
        "        return None\n",
        "    try:\n",
        "        wa = _ensure_work_assets()\n",
        "        if candidate.is_file() and candidate.parent.resolve() != wa.resolve():\n",
        "            return _copy_to_work(candidate)\n",
        "    except Exception:\n",
        "        return candidate\n",
        "    return candidate\n",
        "\n",
        "\n",
        "def stage_by_upload(upload_obj: Any) -> Optional[Path]:\n",
        "    \"\"\"\n",
        "    Stage an uploaded file to WORK_ASSETS.\n",
        "    Supports Gradio-like objects (name/orig_name) or raw paths.\n",
        "    Returns staged Path in WORK_ASSETS or None if unresolved.\n",
        "    \"\"\"\n",
        "    if upload_obj is None:\n",
        "        return None\n",
        "    src_name = (\n",
        "        getattr(upload_obj, \"name\", None)\n",
        "        or getattr(upload_obj, \"orig_name\", None)\n",
        "        or getattr(upload_obj, \"path\", None)\n",
        "        or str(upload_obj)\n",
        "    )\n",
        "    try:\n",
        "        p = Path(src_name)\n",
        "        if p.exists() and p.is_file():\n",
        "            return _copy_to_work(p)\n",
        "    except Exception:\n",
        "        pass\n",
        "    return None\n",
        "\n",
        "\n",
        "def discover_assets_union() -> Tuple[List[str], List[str], List[str], List[str]]:\n",
        "    \"\"\"\n",
        "    Union of assets from ASSETS_ROOT and WORK_ASSETS (top-level only).\n",
        "    Case-insensitive unique and sorted outputs for UI dropdowns.\n",
        "    Returns (audio_names, background_names, mp4_names, font_names).\n",
        "    \"\"\"\n",
        "    # Ensure environment is ready; do not fail on ASSETS_ROOT absence.\n",
        "    try:\n",
        "        _ensure_work_assets()\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    bases: List[Path] = []\n",
        "    # ASSETS_ROOT\n",
        "    try:\n",
        "        root = ASSETS_ROOT if isinstance(ASSETS_ROOT, Path) else Path(ASSETS_ROOT)  # type: ignore[name-defined]\n",
        "        q = _existing_dir(root)\n",
        "        if q:\n",
        "            bases.append(q)\n",
        "    except Exception:\n",
        "        pass\n",
        "    # WORK_ASSETS\n",
        "    try:\n",
        "        bases.append(_ensure_work_assets())\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    aud_all: List[str] = []\n",
        "    bg_all: List[str] = []\n",
        "    mp4_all: List[str] = []\n",
        "    font_all: List[str] = []\n",
        "\n",
        "    for b in bases:\n",
        "        a, bg, m, f = _list_media_from(b)\n",
        "        aud_all.extend(a); bg_all.extend(bg); mp4_all.extend(m); font_all.extend(f)\n",
        "\n",
        "    key = _norm_casefold\n",
        "    return (\n",
        "        sorted(_uniq_casefold(aud_all), key=key),\n",
        "        sorted(_uniq_casefold(bg_all),  key=key),\n",
        "        sorted(_uniq_casefold(mp4_all), key=key),\n",
        "        sorted(_uniq_casefold(font_all),key=key),\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "709c0a6c",
      "metadata": {
        "id": "709c0a6c",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title 9) Audio Normalize + Progress UI — Hidden (HARDLOCK v3 • SCA)\n",
        "# Loudness-safe normalize (fast 1-pass or true 2-pass), robust stream checks, and live progress widgets.\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import html\n",
        "import json\n",
        "import re\n",
        "import time\n",
        "import shutil\n",
        "from functools import lru_cache\n",
        "from pathlib import Path\n",
        "from typing import List, Optional, Tuple\n",
        "\n",
        "# Expected from the environment (asserted at runtime by _preflight_audio_env):\n",
        "# _run(cmd: List[str], check: bool = True, capture: bool = True) -> CompletedProcess-like\n",
        "# WORK_CACHE: Path\n",
        "# sha1_file(path: Path) -> str\n",
        "\n",
        "# =========================\n",
        "# Constants & precompiled\n",
        "# =========================\n",
        "\n",
        "FF_QUIET_ARGS: List[str] = [\"-hide_banner\", \"-nostdin\", \"-loglevel\", \"error\"]\n",
        "\n",
        "LN_TARGET_I = -16.0   # Integrated loudness\n",
        "LN_TARGET_LRA = 11.0  # Loudness range\n",
        "LN_TARGET_TP = -1.5   # True peak (dBTP)\n",
        "\n",
        "# ffmpeg prints the pass-1 stats as JSON; capture the first JSON object robustly\n",
        "_LN_JSON_RX = re.compile(r\"\\{\\s*\\\"input_i\\\".*?\\}\\s*\", re.DOTALL)\n",
        "\n",
        "\n",
        "# =========================\n",
        "# Preflight & probes (bounded, no side effects on success)\n",
        "# =========================\n",
        "\n",
        "def _triad_err(what: str, why: str, how: str) -> RuntimeError:\n",
        "    return RuntimeError(f\"WHAT: {what}\\nWHY: {why}\\nHOW_TO_FIX: {how}\")\n",
        "\n",
        "def _require_globals() -> None:\n",
        "    missing = []\n",
        "    for name in (\"_run\", \"WORK_CACHE\", \"sha1_file\"):\n",
        "        if name not in globals():\n",
        "            missing.append(name)\n",
        "    if missing:\n",
        "        raise _triad_err(\n",
        "            \"Missing globals\",\n",
        "            f\"Required names not defined: {', '.join(missing)}\",\n",
        "            \"Run the Roots/Cache & Core Utils cells that define these globals before this cell.\"\n",
        "        )\n",
        "    # basic type sanity\n",
        "    if not isinstance(globals()[\"WORK_CACHE\"], Path):\n",
        "        raise _triad_err(\n",
        "            \"WORK_CACHE type\",\n",
        "            f\"Expected pathlib.Path, got {type(globals()['WORK_CACHE']).__name__}\",\n",
        "            \"Ensure WORK_CACHE is created as a Path in the Roots & Cache cell.\"\n",
        "        )\n",
        "\n",
        "def _require_tools() -> None:\n",
        "    for binname in (\"ffmpeg\", \"ffprobe\"):\n",
        "        if shutil.which(binname) is None:\n",
        "            raise _triad_err(\n",
        "                f\"{binname} not found\",\n",
        "                f\"{binname} is not on PATH\",\n",
        "                f\"Install {binname} and ensure it's on PATH (e.g., apt-get install ffmpeg) before running this cell.\"\n",
        "            )\n",
        "\n",
        "def _writable_cache() -> None:\n",
        "    wc: Path = globals()[\"WORK_CACHE\"]\n",
        "    wc.mkdir(parents=True, exist_ok=True)\n",
        "    probe = wc / \".probe_write.tmp\"\n",
        "    try:\n",
        "        probe.write_bytes(b\"\")\n",
        "        probe.unlink()\n",
        "    except Exception as e:\n",
        "        raise _triad_err(\n",
        "            \"WORK_CACHE not writable\",\n",
        "            str(e),\n",
        "            f\"Fix filesystem permissions or set WORK_CACHE to a writable directory (current: {wc}).\"\n",
        "        )\n",
        "\n",
        "def _probe_nvenc_quick() -> bool:\n",
        "    \"\"\"64x64 color → h264_nvenc → null; returns availability, never raises.\"\"\"\n",
        "    try:\n",
        "        r = _run([  # type: ignore[name-defined]\n",
        "            \"ffmpeg\", *FF_QUIET_ARGS, \"-t\", \"0.10\",\n",
        "            \"-f\", \"lavfi\", \"-i\", \"color=black:s=64x64:r=24\",\n",
        "            \"-c:v\", \"h264_nvenc\", \"-f\", \"null\", \"-\"\n",
        "        ], check=False)\n",
        "        return r.returncode == 0\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "def _probe_x264_quick() -> None:\n",
        "    \"\"\"64x64 color → libx264 → null; must succeed.\"\"\"\n",
        "    r = _run([  # type: ignore[name-defined]\n",
        "        \"ffmpeg\", *FF_QUIET_ARGS, \"-t\", \"0.10\",\n",
        "        \"-f\", \"lavfi\", \"-i\", \"color=black:s=64x64:r=24\",\n",
        "        \"-c:v\", \"libx264\", \"-g\", \"48\", \"-bf\", \"2\", \"-pix_fmt\", \"yuv420p\",\n",
        "        \"-f\", \"null\", \"-\"\n",
        "    ], check=False)\n",
        "    if r.returncode != 0:\n",
        "        err = (r.stderr or \"\").strip()\n",
        "        raise _triad_err(\n",
        "            \"x264 probe failed\",\n",
        "            err or \"libx264 encode failed\",\n",
        "            \"Install ffmpeg with libx264 enabled, or use a build that includes x264.\"\n",
        "        )\n",
        "\n",
        "def _probe_ass_quick() -> None:\n",
        "    \"\"\"Minimal ASS parse via subtitles filter; must parse.\"\"\"\n",
        "    wc: Path = globals()[\"WORK_CACHE\"]\n",
        "    tmp_ass = wc / \".probe.ass\"\n",
        "    tmp_ass.write_text(\n",
        "        \"[Script Info]\\nPlayResX:64\\nPlayResY:64\\nWrapStyle:2\\nScaledBorderAndShadow:yes\\nYCbCr Matrix: TV.709\\n\\n\"\n",
        "        \"[V4+ Styles]\\n\"\n",
        "        \"Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, \"\n",
        "        \"Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, \"\n",
        "        \"Alignment, MarginL, MarginR, MarginV, Encoding\\n\"\n",
        "        \"Style: Default,Arial,16,&H00FFFFFF,&H00FFFFFF,&H00000000,&H00000000,0,0,0,0,100,100,0,0,1,1,0,7,2,2,2,1\\n\\n\"\n",
        "        \"[Events]\\nFormat: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text\\n\"\n",
        "        \"Dialogue: 0,0:00:00.00,0:00:00.10,Default,,0,0,0,,hello\\\\Nworld\\n\",\n",
        "        encoding=\"utf-8\"\n",
        "    )\n",
        "    try:\n",
        "        r = _run([  # type: ignore[name-defined]\n",
        "            \"ffmpeg\", *FF_QUIET_ARGS, \"-t\", \"0.10\",\n",
        "            \"-f\", \"lavfi\", \"-i\", \"color=black:s=64x64:r=24\",\n",
        "            \"-vf\", f\"subtitles={str(tmp_ass)}:charenc=UTF-8\",\n",
        "            \"-f\", \"null\", \"-\"\n",
        "        ], check=False)\n",
        "        if r.returncode != 0:\n",
        "            err = (r.stderr or \"\").strip()\n",
        "            raise _triad_err(\n",
        "                \"ASS probe failed\",\n",
        "                err or \"subtitles filter failed to initialize\",\n",
        "                \"Ensure libass is enabled in your ffmpeg build and the ASS file is valid UTF-8.\"\n",
        "            )\n",
        "    finally:\n",
        "        try:\n",
        "            tmp_ass.unlink()\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "def _has_filter(name: str) -> bool:\n",
        "    \"\"\"\n",
        "    Check if ffmpeg has a given filter.\n",
        "    Prefer a project-global helper named `_ff_has_filter` if present to avoid duplication.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        gf = globals().get(\"_ff_has_filter\")  # prefer previously defined shared helper\n",
        "        if callable(gf):\n",
        "            return bool(gf(name))\n",
        "    except Exception:\n",
        "        pass\n",
        "    try:\n",
        "        out = _run([\"ffmpeg\", \"-hide_banner\", \"-filters\"], check=False).stdout or \"\"  # type: ignore[name-defined]\n",
        "        name = f\" {name.strip()} \"\n",
        "        return name in out\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "def _probe_audio_chain(fast: bool) -> None:\n",
        "    \"\"\"0.1s anullsrc through planned filter chain; must succeed or deterministically downgrade.\"\"\"\n",
        "    if fast:\n",
        "        a_filter = \"aresample=48000:async=1,aformat=channel_layouts=stereo\"\n",
        "    else:\n",
        "        # Prefer loudnorm if present; otherwise dynaudnorm; otherwise volume\n",
        "        if _has_filter(\"loudnorm\"):\n",
        "            a_filter = f\"loudnorm=I={LN_TARGET_I}:LRA={LN_TARGET_LRA}:TP={LN_TARGET_TP},aresample=48000:async=1,aformat=channel_layouts=stereo\"\n",
        "        elif _has_filter(\"dynaudnorm\"):\n",
        "            a_filter = \"dynaudnorm=f=150:g=15,aresample=48000:async=1,aformat=channel_layouts=stereo\"\n",
        "        else:\n",
        "            a_filter = \"volume=0.98,aresample=48000:async=1,aformat=channel_layouts=stereo\"\n",
        "    r = _run([  # type: ignore[name-defined]\n",
        "        \"ffmpeg\", *FF_QUIET_ARGS, \"-t\", \"0.10\",\n",
        "        \"-f\", \"lavfi\", \"-i\", \"anullsrc=r=48000:cl=stereo\",\n",
        "        \"-af\", a_filter,\n",
        "        \"-f\", \"null\", \"-\"\n",
        "    ], check=False)\n",
        "    if r.returncode != 0:\n",
        "        err = (r.stderr or \"\").strip()\n",
        "        raise _triad_err(\n",
        "            \"Audio probe failed\",\n",
        "            err or \"filter chain failed\",\n",
        "            \"Use a recent ffmpeg build with loudnorm/dynaudnorm or switch to fast=True to bypass loudness processing.\"\n",
        "        )\n",
        "\n",
        "def _preflight_audio_env(fast: bool) -> None:\n",
        "    \"\"\"Run zero/heavy-min preflight + bounded probes (≤ ~3s each).\"\"\"\n",
        "    _require_globals()\n",
        "    _require_tools()\n",
        "    _writable_cache()\n",
        "    # Probes (bounded, safe)\n",
        "    _probe_x264_quick()          # must pass\n",
        "    _probe_nvenc_quick()         # availability only; ignore result\n",
        "    _probe_ass_quick()           # must pass\n",
        "    _probe_audio_chain(fast)     # must pass for chosen path\n",
        "\n",
        "\n",
        "# =========================\n",
        "# FFmpeg / ffprobe helpers\n",
        "# =========================\n",
        "\n",
        "def _ff_args_common() -> List[str]:\n",
        "    \"\"\"Deterministic, quiet ffmpeg args.\"\"\"\n",
        "    return list(FF_QUIET_ARGS)\n",
        "\n",
        "def _ffprobe_has_audio(src: Path) -> bool:\n",
        "    \"\"\"True if there is at least one audio stream; quiet on failure.\"\"\"\n",
        "    try:\n",
        "        res = _run(  # type: ignore[name-defined]\n",
        "            [\"ffprobe\", \"-v\", \"error\", \"-select_streams\", \"a:0\",\n",
        "             \"-show_entries\", \"stream=index\", \"-of\", \"compact=p=0:nk=1\", str(src)],\n",
        "            check=False,\n",
        "        )\n",
        "        return bool((res.stdout or \"\").strip())\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "def _ffprobe_audio_format(src: Path) -> Tuple[int, int, str]:\n",
        "    \"\"\"Return (sample_rate, channels, codec_name) or (0, 0, \"\") on failure.\"\"\"\n",
        "    try:\n",
        "        res = _run(  # type: ignore[name-defined]\n",
        "            [\"ffprobe\", \"-v\", \"error\", \"-select_streams\", \"a:0\",\n",
        "             \"-show_entries\", \"stream=sample_rate,channels,codec_name\", \"-of\", \"json\", str(src)],\n",
        "            check=False,\n",
        "        )\n",
        "        data = json.loads(res.stdout or \"{}\")\n",
        "        st = (data.get(\"streams\") or [{}])[0]\n",
        "        sr = int(st.get(\"sample_rate\") or 0)\n",
        "        ch = int(st.get(\"channels\") or 0)\n",
        "        cc = str(st.get(\"codec_name\") or \"\")\n",
        "        return sr, ch, cc\n",
        "    except Exception:\n",
        "        return 0, 0, \"\"\n",
        "\n",
        "# =========================\n",
        "# Loudnorm 2-pass helpers\n",
        "# =========================\n",
        "\n",
        "def _loudnorm_measure(src: Path) -> Optional[dict]:\n",
        "    \"\"\"\n",
        "    Pass-1: measure loudness using loudnorm with print_format=json.\n",
        "    Returns JSON dict or None on failure or when loudnorm is missing.\n",
        "    \"\"\"\n",
        "    if not _has_filter(\"loudnorm\"):\n",
        "        return None\n",
        "    cmd = [\n",
        "        \"ffmpeg\", *_ff_args_common(), \"-i\", str(src),\n",
        "        \"-vn\", \"-sn\", \"-dn\", \"-map\", \"a:0\",\n",
        "        \"-af\", f\"loudnorm=I={LN_TARGET_I}:LRA={LN_TARGET_LRA}:TP={LN_TARGET_TP}:print_format=json\",\n",
        "        \"-f\", \"null\", \"-\"\n",
        "    ]\n",
        "    r = _run(cmd, check=False)  # type: ignore[name-defined]\n",
        "    blob = ((r.stderr or \"\") + \"\\n\" + (r.stdout or \"\"))\n",
        "    m = _LN_JSON_RX.search(blob)\n",
        "    if not m:\n",
        "        return None\n",
        "    try:\n",
        "        return json.loads(m.group(0))\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "def _loudnorm_filter_from_measure(meas: dict) -> str:\n",
        "    \"\"\"\n",
        "    Build pass-2 loudnorm filter using measured values.\n",
        "    Missing fields fall back to 0.0 which loudnorm accepts.\n",
        "    \"\"\"\n",
        "    def gv(key: str, default: float = 0.0) -> float:\n",
        "        try:\n",
        "            return float(meas.get(key, default))\n",
        "        except Exception:\n",
        "            return float(default)\n",
        "\n",
        "    return (\n",
        "        \"loudnorm=\"\n",
        "        f\"I={LN_TARGET_I}:LRA={LN_TARGET_LRA}:TP={LN_TARGET_TP}:\"\n",
        "        f\"measured_I={gv('input_i')}:measured_LRA={gv('input_lra')}:\"\n",
        "        f\"measured_TP={gv('input_tp')}:measured_thresh={gv('input_thresh')}:\"\n",
        "        f\"offset={gv('target_offset')}:linear=true:print_format=summary\"\n",
        "    )\n",
        "\n",
        "\n",
        "# =========================\n",
        "# Encoding strategies\n",
        "# =========================\n",
        "\n",
        "def _should_remux_fast(sr: int, ch: int, codec: str) -> bool:\n",
        "    \"\"\"True if we can stream-copy AAC stereo 48 kHz.\"\"\"\n",
        "    return sr == 48000 and ch == 2 and codec.lower() in {\"aac\", \"aac_latm\"}\n",
        "\n",
        "def _remux_copy(src: Path, tmp_out: Path) -> bool:\n",
        "    \"\"\"Attempt AAC stream copy. Return True on success.\"\"\"\n",
        "    cmd = [\n",
        "        \"ffmpeg\", *_ff_args_common(), \"-y\",\n",
        "        \"-i\", str(src), \"-vn\", \"-sn\", \"-dn\", \"-map\", \"a:0\",\n",
        "        \"-c:a\", \"copy\",\n",
        "        \"-movflags\", \"+faststart\",\n",
        "        str(tmp_out),\n",
        "    ]\n",
        "    r = _run(cmd, check=False)  # type: ignore[name-defined]\n",
        "    return r.returncode == 0 and tmp_out.exists() and tmp_out.stat().st_size > 0\n",
        "\n",
        "def _encode_fast_resample(src: Path, tmp_out: Path) -> None:\n",
        "    \"\"\"Fast one-pass path: enforce 48 kHz stereo without changing loudness.\"\"\"\n",
        "    a_filter = \"aresample=48000:async=1,aformat=channel_layouts=stereo\"\n",
        "    cmd = [\n",
        "        \"ffmpeg\", *_ff_args_common(), \"-y\",\n",
        "        \"-i\", str(src),\n",
        "        \"-vn\", \"-sn\", \"-dn\", \"-map\", \"a:0\",\n",
        "        \"-af\", a_filter, \"-ac\", \"2\",\n",
        "        \"-c:a\", \"aac\", \"-b:a\", \"160k\",\n",
        "        \"-movflags\", \"+faststart\",\n",
        "        \"-map_metadata\", \"-1\", \"-map_chapters\", \"-1\",\n",
        "        str(tmp_out),\n",
        "    ]\n",
        "    r = _run(cmd, check=False)  # type: ignore[name-defined]\n",
        "    if r.returncode != 0 or (not tmp_out.exists()) or tmp_out.stat().st_size <= 0:\n",
        "        err = (r.stderr or \"\").strip()\n",
        "        raise _triad_err(\n",
        "            \"Audio normalize (fast)\",\n",
        "            err or \"ffmpeg returned non-zero status\",\n",
        "            \"Use a recent ffmpeg with AAC encoder; verify input has a valid a:0 stream; try fast=False if persistent.\"\n",
        "        )\n",
        "\n",
        "def _encode_loudnorm_two_pass(src: Path, tmp_out: Path) -> None:\n",
        "    \"\"\"\n",
        "    Accurate path: EBU R128 loudnorm then 48 kHz stereo.\n",
        "    If loudnorm is unavailable, fall back to dynaudnorm or conservative volume.\n",
        "    \"\"\"\n",
        "    if _has_filter(\"loudnorm\"):\n",
        "        meas = _loudnorm_measure(src)\n",
        "        ln2 = (\n",
        "            _loudnorm_filter_from_measure(meas)\n",
        "            if meas\n",
        "            else f\"loudnorm=I={LN_TARGET_I}:LRA={LN_TARGET_LRA}:TP={LN_TARGET_TP}:print_format=summary\"\n",
        "        )\n",
        "    elif _has_filter(\"dynaudnorm\"):\n",
        "        ln2 = \"dynaudnorm=f=150:g=15\"\n",
        "    else:\n",
        "        ln2 = \"volume=0.98\"\n",
        "\n",
        "    a_filter = f\"{ln2},aresample=48000:async=1,aformat=channel_layouts=stereo\"\n",
        "    cmd = [\n",
        "        \"ffmpeg\", *_ff_args_common(), \"-y\",\n",
        "        \"-i\", str(src),\n",
        "        \"-vn\", \"-sn\", \"-dn\", \"-map\", \"a:0\",\n",
        "        \"-af\", a_filter, \"-ac\", \"2\",\n",
        "        \"-c:a\", \"aac\", \"-b:a\", \"160k\",\n",
        "        \"-movflags\", \"+faststart\",\n",
        "        \"-map_metadata\", \"-1\", \"-map_chapters\", \"-1\",\n",
        "        str(tmp_out),\n",
        "    ]\n",
        "    r = _run(cmd, check=False)  # type: ignore[name-defined]\n",
        "    if r.returncode != 0 or (not tmp_out.exists()) or tmp_out.stat().st_size <= 0:\n",
        "        err = (r.stderr or \"\").strip()\n",
        "        raise _triad_err(\n",
        "            \"Audio normalize (2-pass)\",\n",
        "            err or \"ffmpeg returned non-zero status\",\n",
        "            \"Ensure loudnorm/dynaudnorm filters are available, or run with fast=True to bypass loudness correction.\"\n",
        "        )\n",
        "\n",
        "\n",
        "# =========================\n",
        "# Public API (cached, API unchanged)\n",
        "# =========================\n",
        "\n",
        "def normalize_audio_cached(src: Path, fast: bool = True) -> Path:\n",
        "    \"\"\"\n",
        "    Normalize `src` into AAC stereo 48 kHz .m4a with cache by SHA1.\n",
        "      - fast=True  → 1-pass: resample + stereo mix only (no loudness change)\n",
        "      - fast=False → loudness normalization (loudnorm/dynaudnorm fallback) + resample + stereo\n",
        "\n",
        "    Returns:\n",
        "        Path to normalized .m4a file in WORK_CACHE.\n",
        "\n",
        "    Raises:\n",
        "        FileNotFoundError if src is missing\n",
        "        RuntimeError if no audio stream or encode fails\n",
        "    \"\"\"\n",
        "    _preflight_audio_env(bool(fast))  # light checks + bounded probes\n",
        "\n",
        "    if not src or not Path(src).exists():\n",
        "        raise FileNotFoundError(f\"Audio source not found: {src}\")\n",
        "    if not _ffprobe_has_audio(src):\n",
        "        raise _triad_err(\n",
        "            \"Missing audio stream\",\n",
        "            f\"No a:0 stream in {src}\",\n",
        "            \"Provide a media file with an audio track; verify with ffprobe.\"\n",
        "        )\n",
        "\n",
        "    ah = sha1_file(src)  # type: ignore[name-defined]\n",
        "    out = WORK_CACHE / (f\"norm_{ah}.m4a\" if fast else f\"normln_{ah}.m4a\")  # type: ignore[name-defined]\n",
        "    if out.exists() and out.stat().st_size > 0:\n",
        "        return out\n",
        "\n",
        "    tmp = out.with_suffix(\".tmp.m4a\")\n",
        "    try:\n",
        "        if tmp.exists():\n",
        "            tmp.unlink()\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    sr, ch, codec = _ffprobe_audio_format(src)\n",
        "    if fast and _should_remux_fast(sr, ch, codec):\n",
        "        if _remux_copy(src, tmp):\n",
        "            tmp.replace(out)\n",
        "            return out\n",
        "        # Fall through to re-encode if copy failed silently\n",
        "\n",
        "    if fast:\n",
        "        _encode_fast_resample(src, tmp)\n",
        "    else:\n",
        "        _encode_loudnorm_two_pass(src, tmp)\n",
        "\n",
        "    tmp.replace(out)\n",
        "    return out\n",
        "\n",
        "\n",
        "# =========================\n",
        "# Lightweight progress UI (unchanged API)\n",
        "# =========================\n",
        "\n",
        "def status_steps() -> List[Tuple[str, float]]:\n",
        "    \"\"\"\n",
        "    Weighted pipeline steps for an overall progress estimate.\n",
        "    Weights sum to ~1.0 and can be tuned without breaking callers.\n",
        "    \"\"\"\n",
        "    return [\n",
        "        (\"Mount/Discover\",        0.06),\n",
        "        (\"Fonts\",                 0.02),\n",
        "        (\"Transcribe+Normalize\",  0.18),\n",
        "        (\"Timing\",                0.04),\n",
        "        (\"ASS\",                   0.12),\n",
        "        (\"MainTrack\",             0.30),\n",
        "        (\"Overlay+Mix\",           0.12),\n",
        "        (\"Encode\",                0.16),\n",
        "        (\"Cleanup\",               0.01),\n",
        "        (\"Done\",                  0.00),\n",
        "    ]\n",
        "\n",
        "STEPS: List[Tuple[str, float]] = status_steps()\n",
        "\n",
        "def _clamp(x: float, lo: float, hi: float) -> float:\n",
        "    \"\"\"Clamp x to [lo, hi].\"\"\"\n",
        "    return lo if x < lo else hi if x > hi else x\n",
        "\n",
        "def _progress_fraction(cur_idx: int, hint: float) -> float:\n",
        "    \"\"\"Convert (step index, in-step hint 0..1) to a 0..1 overall fraction.\"\"\"\n",
        "    if not STEPS:\n",
        "        return 1.0\n",
        "    last = len(STEPS) - 1\n",
        "    idx = min(int(cur_idx), last)\n",
        "    done = sum(w for i, (_, w) in enumerate(STEPS) if i < idx)\n",
        "    cur_w = STEPS[idx][1]\n",
        "    frac = done + float(hint or 0.0) * cur_w\n",
        "    if cur_idx >= len(STEPS):\n",
        "        frac = 1.0\n",
        "    return _clamp(frac, 0.0, 1.0)\n",
        "\n",
        "def status_html(cur_idx: int, started: float, hint: Optional[float] = None, note: str = \"\") -> str:\n",
        "    \"\"\"\n",
        "    Render a compact HTML status widget with steps, percent, elapsed and ETA.\n",
        "    'hint' is 0..1 for progress within the current step.\n",
        "    \"\"\"\n",
        "    now = time.monotonic()\n",
        "    elapsed = max(0.0, now - float(started))\n",
        "    frac = _progress_fraction(cur_idx, float(hint or 0.0))\n",
        "    pct_cap = 100.0 if cur_idx >= len(STEPS) else 99.9  # avoid showing 100% early\n",
        "    pct = _clamp(frac * 100.0, 0.0, pct_cap)\n",
        "\n",
        "    eta = 0.0\n",
        "    if 0.005 < frac < 0.999 and elapsed > 0.2:\n",
        "        eta = elapsed * (1.0 / max(frac, 1e-3) - 1.0)\n",
        "\n",
        "    rows = [\n",
        "        f\"<li>{('✅' if i < cur_idx else ('⏳' if i == cur_idx else '▫️'))} {html.escape(name)}</li>\"\n",
        "        for i, (name, _) in enumerate(STEPS)\n",
        "    ]\n",
        "    eta_str = f\"~{int(eta // 60)}m {int(eta % 60)}s\" if eta > 0 else \"—\"\n",
        "    note_html = f\"<div style='margin-top:6px;opacity:.85'><i>{html.escape(note)}</i></div>\" if note else \"\"\n",
        "\n",
        "    return (\n",
        "        \"<div style='font-family:system-ui,Segoe UI,Roboto,Arial,sans-serif;line-height:1.4'>\"\n",
        "        \"<div><b>Pipeline</b></div>\"\n",
        "        f\"<ul style='margin:6px 0 8px 18px;padding:0'>{''.join(rows)}</ul>\"\n",
        "        f\"<div>Progress: <b>{pct:.1f}%</b> &nbsp;|&nbsp; Elapsed: \"\n",
        "        f\"<b>{int(elapsed//60)}m {int(elapsed%60)}s</b> &nbsp;|&nbsp; ETA: <b>{eta_str}</b></div>{note_html}</div>\"\n",
        "    )\n",
        "\n",
        "def _overall_percent(cur_idx: int, hint: float) -> float:\n",
        "    \"\"\"Return overall percent (0..100) with one decimal precision.\"\"\"\n",
        "    return round(_progress_fraction(cur_idx, float(hint or 0.0)) * 100.0, 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "b83dc6d2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b83dc6d2",
        "outputId": "537e2b5d-335e-4bfc-b359-838d38ca3e94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UI factory ready.\n"
          ]
        }
      ],
      "source": [
        "# @title 10) Gradio UI & Render — Clean & Aligned (Refactored) { display-mode: \"form\" }\n",
        "# @markdown Minimal UI; options match ASS generator (Cell 6). NVENC→x264 fallback kept.\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import datetime\n",
        "import os\n",
        "import shutil\n",
        "import subprocess as sp\n",
        "import time\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "# =========================\n",
        "# Constants\n",
        "# =========================\n",
        "\n",
        "HL_FIXED_COLOR: str = \"#19B5FF\"\n",
        "\n",
        "# =========================\n",
        "# Asset index map (enables audio overlays for intro/outro/CTA)\n",
        "# =========================\n",
        "\n",
        "_ASSET_INDEX_MAP: Dict[int, Path] = {}\n",
        "\n",
        "def _idx_to_asset(idx: int) -> Optional[Path]:\n",
        "    \"\"\"Resolve ffmpeg input index to a staged asset Path for audio-stream checks.\"\"\"\n",
        "    try:\n",
        "        return _ASSET_INDEX_MAP.get(int(idx))\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "# =========================\n",
        "# Environment helpers\n",
        "# =========================\n",
        "\n",
        "def _safe_env() -> Dict[str, str]:\n",
        "    \"\"\"Return a copy of the environment from upstream _env() if present, else os.environ.\"\"\"\n",
        "    try:\n",
        "        return _env()  # type: ignore[name-defined]\n",
        "    except Exception:\n",
        "        return dict(os.environ)\n",
        "\n",
        "\n",
        "def _ensure_fonts_env(font_path: Optional[Path], fallback_dir: Optional[Path] = None) -> Tuple[Optional[str], Dict[str, str]]:\n",
        "    \"\"\"\n",
        "    Ensure ASS_FONT_DIR points to the chosen font directory (font file parent or provided fallback).\n",
        "    Returns (fontsdir string or None, effective environment dict).\n",
        "    \"\"\"\n",
        "    env = _safe_env()\n",
        "    fontsdir: Optional[str] = None\n",
        "    try:\n",
        "        if font_path and font_path.exists():\n",
        "            fontsdir = str(font_path.parent.resolve())\n",
        "        elif fallback_dir and fallback_dir.exists():\n",
        "            fontsdir = str(fallback_dir.resolve())\n",
        "        if fontsdir:\n",
        "            env[\"ASS_FONT_DIR\"] = fontsdir\n",
        "    except Exception:\n",
        "        pass\n",
        "    return fontsdir, env\n",
        "\n",
        "\n",
        "def _extract_internal_font_name(font_file: Optional[Path]) -> Optional[str]:\n",
        "    \"\"\"\n",
        "    Attempt to extract a human-readable font name (Full name or Family) from a TTF/OTF/TTC.\n",
        "    Returns None if fonttools is unavailable or parsing fails.\n",
        "    \"\"\"\n",
        "    if not font_file or not font_file.exists():\n",
        "        return None\n",
        "    try:\n",
        "        from fontTools.ttLib import TTFont  # type: ignore\n",
        "    except Exception:\n",
        "        return None\n",
        "    try:\n",
        "        tt = TTFont(str(font_file))\n",
        "        full: Optional[str] = None\n",
        "        fam: Optional[str] = None\n",
        "        for n in tt[\"name\"].names:\n",
        "            try:\n",
        "                val = n.toUnicode()\n",
        "            except Exception:\n",
        "                try:\n",
        "                    val = n.string.decode(\"utf-16-be\", errors=\"ignore\")\n",
        "                except Exception:\n",
        "                    continue\n",
        "            if n.nameID == 4 and not full:\n",
        "                full = val\n",
        "            if n.nameID == 1 and not fam:\n",
        "                fam = val\n",
        "        return full or fam\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "\n",
        "def _safe_local_copy(final_path: Path) -> Path:\n",
        "    \"\"\"\n",
        "    Copy the final artifact to a static 'web' folder for lightweight serving/preview.\n",
        "    Returns the copied path if successful, otherwise the original.\n",
        "    \"\"\"\n",
        "    web_dir = WORK_ROOT / \"web\"  # type: ignore[name-defined]\n",
        "    web_dir.mkdir(parents=True, exist_ok=True)\n",
        "    ts = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    local = web_dir / f\"{ts}_output.mp4\"\n",
        "    try:\n",
        "        if local.exists():\n",
        "            local.unlink()\n",
        "    except Exception:\n",
        "        pass\n",
        "    try:\n",
        "        shutil.copy2(str(final_path), str(local))\n",
        "    except Exception:\n",
        "        sp.run([\"/bin/cp\", \"-f\", str(final_path), str(local)], check=False)\n",
        "    return local if local.exists() and local.stat().st_size > 0 else final_path\n",
        "\n",
        "\n",
        "def _status_or(*args, default: str = \"\") -> str:\n",
        "    \"\"\"Call status_html if available; otherwise return a provided default string.\"\"\"\n",
        "    try:\n",
        "        return status_html(*args)  # type: ignore[name-defined]\n",
        "    except Exception:\n",
        "        return default\n",
        "\n",
        "# =========================\n",
        "# Asset helpers\n",
        "# =========================\n",
        "\n",
        "def refresh_assets():\n",
        "    \"\"\"\n",
        "    Refresh dropdowns from the union of Assets and WORK_ASSETS.\n",
        "    Returns gr.update configs for audio/bg/mp4/font selectors.\n",
        "    \"\"\"\n",
        "    audio_files, bg_files, mp4_files, font_files = discover_assets_union()  # type: ignore[name-defined]\n",
        "    mp4_opts = [\"None\"] + mp4_files\n",
        "    return (\n",
        "        gr.update(choices=audio_files, value=(audio_files[0] if audio_files else None)),\n",
        "        gr.update(choices=bg_files, value=(bg_files[0] if bg_files else None)),\n",
        "        gr.update(choices=mp4_opts, value=\"None\"),\n",
        "        gr.update(choices=mp4_opts, value=\"None\"),\n",
        "        gr.update(choices=mp4_opts, value=\"None\"),\n",
        "        gr.update(choices=[\"None\"] + font_files, value=\"None\"),\n",
        "    )\n",
        "\n",
        "\n",
        "def _stage_optional(name: Optional[str]) -> Optional[Path]:\n",
        "    \"\"\"Stage an optional asset by name; graceful None for 'None' or empty.\"\"\"\n",
        "    if not name or str(name).strip().lower() == \"none\":\n",
        "        return None\n",
        "    return stage_by_name(name)  # type: ignore[name-defined]\n",
        "\n",
        "# =========================\n",
        "# Core pipeline helpers\n",
        "# =========================\n",
        "\n",
        "def _transcribe_and_normalize(audio_path: Path, whisper_size: str, fast_audio: bool) -> Tuple[List[\"Word\"], Path]:  # type: ignore[name-defined]\n",
        "    \"\"\"\n",
        "    Parallelize transcription and audio normalization (2 futures).\n",
        "    Returns (list of Word, normalized audio path).\n",
        "    \"\"\"\n",
        "    with ThreadPoolExecutor(max_workers=2) as ex:\n",
        "        fut_tr = ex.submit(transcribe_cached, audio_path, whisper_size, \"en\")  # type: ignore[name-defined]\n",
        "        fut_norm = ex.submit(normalize_audio_cached, audio_path, bool(fast_audio))  # type: ignore[name-defined]\n",
        "        words = fut_tr.result()\n",
        "        norm_path = Path(fut_norm.result())\n",
        "    return words, norm_path\n",
        "\n",
        "\n",
        "def _probe_durations(intro: Optional[Path], outro: Optional[Path], main_audio: Path) -> Tuple[float, float, float]:\n",
        "    \"\"\"\n",
        "    Probe durations with ≤2 threads. Returns (intro_d, outro_d, main_d).\n",
        "    \"\"\"\n",
        "    with ThreadPoolExecutor(max_workers=2) as ex:\n",
        "        fut_main = ex.submit(probe_duration_cached, main_audio)  # type: ignore[name-defined]\n",
        "        fut_intro = ex.submit(probe_duration_cached, intro) if intro else None  # type: ignore[name-defined]\n",
        "        intro_d = fut_intro.result() if fut_intro else 0.0\n",
        "        main_d = fut_main.result()\n",
        "    outro_d = probe_duration_cached(outro) if outro else 0.0  # type: ignore[name-defined]\n",
        "    return float(intro_d), float(outro_d), float(main_d)\n",
        "\n",
        "\n",
        "def _compute_cta_schedule(\n",
        "    start_sec: float,\n",
        "    repeat_sec: float,\n",
        "    intro_d: float,\n",
        "    main_d: float,\n",
        "    cta_d: float,\n",
        "    cap_offset: float,\n",
        "    max_instances: int = 50\n",
        ") -> List[float]:\n",
        "    \"\"\"\n",
        "    Compute CTA insertion times across the main section (intro + main).\n",
        "    Returns a list of start times in seconds.\n",
        "    \"\"\"\n",
        "    times: List[float] = []\n",
        "    if cta_d <= 0 or repeat_sec <= 0:\n",
        "        return times\n",
        "    t = float(cap_offset) + float(start_sec or 0.0)\n",
        "    end_main = float(intro_d) + float(main_d)\n",
        "    while t < end_main - 0.1 and len(times) < max_instances:\n",
        "        times.append(round(t, 3))\n",
        "        t += float(repeat_sec)\n",
        "    return times\n",
        "\n",
        "# ---------------- video filter graph (intro/cta/outro) ----------------\n",
        "\n",
        "def _compose_video_filters(\n",
        "    fps: int,\n",
        "    cur_label: str,\n",
        "    intro_idx: Optional[int],\n",
        "    outro_idx: Optional[int],\n",
        "    cta_idx: Optional[int],\n",
        "    intro_d: float,\n",
        "    main_d: float,\n",
        "    outro_d: float,\n",
        "    cta_times: List[float],\n",
        "    cta_d: float,\n",
        "    cta_key_hex: str,\n",
        "    cta_similarity: float,\n",
        "    cta_blend: float,\n",
        "    cta_position: str,\n",
        "    intro_chroma_key: bool,\n",
        "    outro_chroma_key: bool\n",
        ") -> Tuple[List[str], str]:\n",
        "    \"\"\"\n",
        "    Compose the overlay filtergraph for optional intro/outro and repeatable CTA insertions.\n",
        "    Returns (list of vf clauses, last video label).\n",
        "    \"\"\"\n",
        "    vf: List[str] = [f\"[0:v]fps={int(fps)},format=yuv420p[{cur_label}]\"]\n",
        "    cur = cur_label\n",
        "\n",
        "    # Intro overlay\n",
        "    if intro_idx is not None and intro_d > 0:\n",
        "        ck = (f\",colorkey=0x00FF00:{cta_similarity:.2f}:{cta_blend:.2f}\") if intro_chroma_key else \"\"\n",
        "        vf.append(\n",
        "            f\"[{intro_idx}:v]scale=1920:1080:force_original_aspect_ratio=decrease,\"\n",
        "            f\"pad=1920:1080:-1:-1,fps={int(fps)},format=rgba{ck},\"\n",
        "            f\"trim=duration={intro_d:.3f},setpts=PTS-STARTPTS[intro]\"\n",
        "        )\n",
        "        vf.append(f\"[{cur}][intro]overlay=eof_action=pass:repeatlast=0:enable='between(t,0,{intro_d:.3f})'[v1]\")\n",
        "        cur = \"v1\"\n",
        "\n",
        "    # CTA overlays\n",
        "    if cta_idx is not None and cta_times:\n",
        "        vf.append(f\"[{cta_idx}:v]scale=1152:-1:force_original_aspect_ratio=decrease,fps={int(fps)},format=rgba[cta_base]\")\n",
        "        vf.append(f\"[cta_base]split={len(cta_times)}\" + \"\".join(f\"[cta{i}]\" for i in range(len(cta_times))))\n",
        "        cta_y = \"20\" if cta_position == \"Top\" else \"(H-h)/2\" if cta_position == \"Middle\" else \"H-h-20\"\n",
        "        for i, stt in enumerate(cta_times):\n",
        "            en = stt + cta_d\n",
        "            vf.append(\n",
        "                f\"[cta{i}]colorkey={cta_key_hex}:{cta_similarity:.2f}:{cta_blend:.2f},\"\n",
        "                f\"trim=duration={cta_d:.3f},setpts=PTS-STARTPTS+{stt:.3f}/TB[ct{i}]\"\n",
        "            )\n",
        "            vf.append(\n",
        "                f\"[{cur}][ct{i}]overlay=x=(W-w)/2:y={cta_y}:eof_action=pass:repeatlast=0:\"\n",
        "                f\"enable='between(t,{stt:.3f},{en:.3f})'[vct{i}]\"\n",
        "            )\n",
        "            cur = f\"vct{i}\"\n",
        "\n",
        "    # Outro overlay\n",
        "    if outro_idx is not None and outro_d > 0:\n",
        "        out_start = float(intro_d) + float(main_d)\n",
        "        ck = (f\",colorkey=0x00FF00:{cta_similarity:.2f}:{cta_blend:.2f}\") if outro_chroma_key else \"\"\n",
        "        vf.append(\n",
        "            f\"[{outro_idx}:v]scale=1920:1080:force_original_aspect_ratio=decrease,\"\n",
        "            f\"pad=1920:1080:-1:-1,fps={int(fps)},format=rgba{ck},\"\n",
        "            f\"trim=duration={outro_d:.3f},setpts=PTS-STARTPTS+{out_start:.3f}/TB[outro]\"\n",
        "        )\n",
        "        vf.append(\n",
        "            f\"[{cur}][outro]overlay=eof_action=pass:repeatlast=0:\"\n",
        "            f\"enable='between(t,{out_start:.3f},{(out_start+outro_d):.3f})'[vout]\"\n",
        "        )\n",
        "        cur = \"vout\"\n",
        "\n",
        "    return vf, cur\n",
        "\n",
        "# ---------------- audio mix graph ----------------\n",
        "\n",
        "def _build_audio_filters(\n",
        "    main_idx: int,\n",
        "    intro_idx: Optional[int],\n",
        "    outro_idx: Optional[int],\n",
        "    cta_idx: Optional[int],\n",
        "    intro_d: float,\n",
        "    main_d: float,\n",
        "    cta_times: List[float],\n",
        "    cta_d: float\n",
        ") -> List[str]:\n",
        "    \"\"\"\n",
        "    Build audio filtergraph: mix main with optional intro/outro/CTA stems.\n",
        "    Returns a list of af clauses ending in [afinal].\n",
        "    \"\"\"\n",
        "    af: List[str] = []\n",
        "    inputs: List[str] = [f\"[{main_idx}:a]\"]\n",
        "\n",
        "    if intro_idx is not None and has_audio_stream_cached(_idx_to_asset(intro_idx)):  # type: ignore[name-defined]\n",
        "        af.append(f\"[{intro_idx}:a]volume=0.5,aresample=48000[introa]\")\n",
        "        inputs.append(\"[introa]\")\n",
        "\n",
        "    if outro_idx is not None and has_audio_stream_cached(_idx_to_asset(outro_idx)):  # type: ignore[name-defined]\n",
        "        ms = int((float(intro_d) + float(main_d)) * 1000)\n",
        "        af.append(f\"[{outro_idx}:a]volume=0.5,adelay={ms}|{ms}:all=1,aresample=48000[outroa]\")\n",
        "        inputs.append(\"[outroa]\")\n",
        "\n",
        "    if cta_idx is not None and cta_times and has_audio_stream_cached(_idx_to_asset(cta_idx)):  # type: ignore[name-defined]\n",
        "        af.append(f\"[{cta_idx}:a]volume=0.5,aresample=48000[ctab]\")\n",
        "        for i, stt in enumerate(cta_times):\n",
        "            ms = int(stt * 1000)\n",
        "            af.append(f\"[ctab]atrim=0:{cta_d:.3f},asetpts=PTS-STARTPTS,adelay={ms}|{ms}:all=1[cta{i}]\")\n",
        "            inputs.append(f\"[cta{i}]\")\n",
        "\n",
        "    if len(inputs) > 1:\n",
        "        af.append(f\"{''.join(inputs)}amix=inputs={len(inputs)}:duration=longest:normalize=0,\"\n",
        "                  f\"dynaudnorm=f=150:g=15,alimiter=limit=0.95[afinal]\")\n",
        "    else:\n",
        "        af.append(f\"{inputs[0]}dynaudnorm=f=150:g=15,alimiter=limit=0.95[afinal]\")\n",
        "\n",
        "    return af\n",
        "\n",
        "# ---------------- ffmpeg runner ----------------\n",
        "\n",
        "def _run_ffmpeg_with_env(cmd: List[str], env: Dict[str, str]) -> Tuple[int, str]:\n",
        "    \"\"\"\n",
        "    Run ffmpeg with a custom environment, capturing a bounded stderr tail.\n",
        "    Returns (returncode, stderr_tail).\n",
        "    \"\"\"\n",
        "    p = sp.Popen(cmd, stdout=sp.PIPE, stderr=sp.PIPE, universal_newlines=True, bufsize=1, env=env)\n",
        "    err_buf: List[str] = []\n",
        "    while True:\n",
        "        ln = p.stderr.readline()\n",
        "        if not ln:\n",
        "            break\n",
        "        err_buf.append(ln)\n",
        "        if len(err_buf) > 400:\n",
        "            err_buf = err_buf[-300:]\n",
        "    p.wait()\n",
        "    return p.returncode, \"\".join(err_buf[-2000:])\n",
        "\n",
        "# =========================\n",
        "# Main render coroutine\n",
        "# =========================\n",
        "\n",
        "def render_video(\n",
        "    audio_name, audio_upload, bg_name, bg_upload,\n",
        "    whisper_size, font_file,\n",
        "    ui_font_size, caption_color, border_thickness,\n",
        "    caption_pos, caption_hmargin, caption_vmargin, karaoke_offset_ms,\n",
        "    intro_mp4, intro_chroma_key, outro_mp4, outro_chroma_key,\n",
        "    cta_mp4, cta_start_sec, cta_repeat_sec, cta_key_color, cta_similarity, cta_blend, cta_position,\n",
        "    profile, fps, fast_audio, subscale_percent, enc_mode, smart_mode,\n",
        "    line_count, max_words_per_line, max_words_per_caption, strict_word,\n",
        "    force_bold_ui,\n",
        "    highlight_mode_ui, align_mode, safe_area_pct, target_cps, line_space_pct, max_extend_sec,\n",
        "    progress=gr.Progress()\n",
        "):\n",
        "    \"\"\"\n",
        "    Orchestrate the full pipeline: stage assets, ASR, ASS, main track, overlays, encode.\n",
        "    Yields (video_path_or_None, status_html, percent).\n",
        "    \"\"\"\n",
        "    started = time.monotonic()\n",
        "\n",
        "    def tick(step_index: int, hint: float = 0.0, note: str = \"\"):\n",
        "        pc = _overall_percent(step_index, hint)  # type: ignore[name-defined]\n",
        "        yield None, _status_or(step_index, started, hint, note, default=\"Working...\"), pc  # type: ignore[name-defined]\n",
        "\n",
        "    try:\n",
        "        # Drive prep\n",
        "        try:\n",
        "            if _in_colab() and not Path(\"/content/drive\").exists():  # type: ignore[name-defined]\n",
        "                _mount_drive(force=False)  # type: ignore[name-defined]\n",
        "        except Exception:\n",
        "            pass\n",
        "        ensure_drive_tree(DRIVE_ROOT)  # type: ignore[name-defined]\n",
        "        for r in tick(0, 0.35, \"Scanning assets...\"):\n",
        "            yield r\n",
        "\n",
        "        # Stage core assets\n",
        "        st_audio = stage_by_upload(audio_upload) or stage_by_name(audio_name)  # type: ignore[name-defined]\n",
        "        st_bg = stage_by_upload(bg_upload) or stage_by_name(bg_name)  # type: ignore[name-defined]\n",
        "        if not st_audio:\n",
        "            yield None, _status_or(0, started), 0.0\n",
        "            yield None, \"Provide an Audio (upload or from Assets).\", 0.0\n",
        "            return\n",
        "        if not st_bg:\n",
        "            yield None, _status_or(0, started), 0.0\n",
        "            yield None, \"Provide a Background image (upload or from Assets).\", 0.0\n",
        "            return\n",
        "\n",
        "        st_intro = _stage_optional(intro_mp4)\n",
        "        st_outro = _stage_optional(outro_mp4)\n",
        "        st_cta = _stage_optional(cta_mp4)\n",
        "\n",
        "        # Font resolution and outline\n",
        "        font_info = FONTM.resolve_font_selection(font_file if font_file and str(font_file).lower() != \"none\" else None)  # type: ignore[name-defined]\n",
        "        selected_font_path = Path(font_file) if font_file and str(font_file).lower() != \"none\" else None\n",
        "        internal_name = _extract_internal_font_name(selected_font_path) if selected_font_path else None\n",
        "        if internal_name:\n",
        "            font_info.family = internal_name  # type: ignore[attr-defined]\n",
        "\n",
        "        mapped_fs = ui_size_to_ass(int(ui_font_size))  # type: ignore[name-defined]\n",
        "        thinish = any(k in (getattr(font_info, \"subfam\", \"\") or \"\").lower() for k in [\"thin\", \"extralight\", \"ultralight\", \"light\"])\n",
        "        auto_outline = max(int(border_thickness or 0), max(2, int(round(mapped_fs * 0.05)))) if thinish else int(border_thickness or 0)\n",
        "        for r in tick(1):\n",
        "            yield r\n",
        "\n",
        "        # Transcription + normalization\n",
        "        words, norm_audio = _transcribe_and_normalize(st_audio, whisper_size, bool(fast_audio))\n",
        "        for r in tick(2):\n",
        "            yield r\n",
        "\n",
        "        # Durations & timing config\n",
        "        intro_d, outro_d, main_d = _probe_durations(st_intro, st_outro, norm_audio)\n",
        "        total_d = float(intro_d + main_d + (outro_d or 0.0))\n",
        "        if total_d <= 0:\n",
        "            yield None, _status_or(2, started), 5.0\n",
        "            yield None, \"Invalid duration\", 5.0\n",
        "            return\n",
        "\n",
        "        cap_offset = float(intro_d)\n",
        "        subscale = max(0.7, min(1.0, (subscale_percent or 80) / 100.0))\n",
        "        rw, rh, _ = effective_render_size(1920, 1080, subscale)  # type: ignore[name-defined]\n",
        "        fps_val = int(fps or 24)\n",
        "\n",
        "        # Smart assist (optional)\n",
        "        if smart_mode:\n",
        "            dec = smart_decide(words, st_bg)  # type: ignore[name-defined]\n",
        "            caption_hmargin, caption_vmargin = dec[\"hmargin\"], dec[\"vmargin\"]\n",
        "            fps_val, enc_mode = dec[\"fps\"], dec[\"enc_mode\"]\n",
        "            wpm = int(extract_speech_stats(words)[\"wpm\"])  # type: ignore[name-defined]\n",
        "            note = f\"{wpm}wpm • {fps_val}fps • sub {int(subscale*100)}% • {str(enc_mode).upper()}\"\n",
        "            for r in tick(3, 0.22, note):\n",
        "                yield r\n",
        "        else:\n",
        "            for r in tick(3, 0.22):\n",
        "                yield r\n",
        "\n",
        "        # Fonts env for ffmpeg\n",
        "        default_assets = DRIVE_ROOT / \"VideoRobot\" / \"Assets\"  # type: ignore[name-defined]\n",
        "        _, env_ffmpeg = _ensure_fonts_env(selected_font_path, default_assets)\n",
        "\n",
        "        # ASS generation\n",
        "        ass_file = generate_ass_track(  # type: ignore[name-defined]\n",
        "            words=words,\n",
        "            font_info=font_info,\n",
        "            ui_font_size=int(ui_font_size),\n",
        "            position=str(caption_pos),\n",
        "            margin_h=int(caption_hmargin),\n",
        "            margin_v=int(caption_vmargin),\n",
        "            border_thickness=int(border_thickness or 0),\n",
        "            primary_color=(caption_color or \"#FFFFFF\"),\n",
        "            highlight_color=HL_FIXED_COLOR,\n",
        "            time_offset=cap_offset,\n",
        "            karaoke_offset_ms=int(karaoke_offset_ms or 0),\n",
        "            style_profile=str(profile),\n",
        "            highlight_mode_ui=str(highlight_mode_ui),\n",
        "            rw=int(rw),\n",
        "            rh=int(rh),\n",
        "            keyword_overlay=False,\n",
        "            keyword_list=[],\n",
        "            key_txt_color=\"#FFFFFF\",\n",
        "            key_bg_color=\"#000000\",\n",
        "            key_pos=\"Top\",\n",
        "            audio_for_snap=Path(norm_audio),\n",
        "            force_bold_ui=bool(force_bold_ui),\n",
        "            outline_override=int(auto_outline),\n",
        "            line_count=int(line_count),\n",
        "            max_words_per_line=int(max_words_per_line),\n",
        "            max_words_per_caption=int(max_words_per_caption),\n",
        "            strict_word=bool(strict_word),\n",
        "            align_mode=str(align_mode),\n",
        "            safe_area_pct=int(safe_area_pct),\n",
        "            line_space_pct=int(line_space_pct),\n",
        "            target_cps=int(target_cps),\n",
        "            min_caption_sec=0.25,\n",
        "            max_extend_sec=float(max_extend_sec),\n",
        "        )\n",
        "        if not ass_file.exists():\n",
        "            yield None, _status_or(5, started), 0.0\n",
        "            yield None, f\"ASS not generated: {ass_file}\", 0.0\n",
        "            return\n",
        "        for r in tick(4, 0.55):\n",
        "            yield r\n",
        "\n",
        "        # Main track (burn ASS)\n",
        "        main_track = build_main_track_cached(  # type: ignore[name-defined]\n",
        "            st_bg, ass_file, Path(norm_audio), float(intro_d), float(total_d), int(fps_val), float(subscale)\n",
        "        )\n",
        "        if not main_track.exists():\n",
        "            yield None, _status_or(6, started), 0.0\n",
        "            yield None, f\"Main track not built: {main_track}\", 0.0\n",
        "            return\n",
        "        for r in tick(5):\n",
        "            yield r\n",
        "\n",
        "        # Optional overlays: intro/outro/cta\n",
        "        inputs: List[str] = [\"-thread_queue_size\", \"512\", \"-i\", str(main_track)]\n",
        "        idx = 1\n",
        "        intro_idx = outro_idx = cta_idx = None\n",
        "        cta_d = 0.0\n",
        "        cta_times: List[float] = []\n",
        "\n",
        "        if st_intro and intro_d > 0:\n",
        "            inputs += [\"-thread_queue_size\", \"512\", \"-i\", str(st_intro)]\n",
        "            intro_idx = idx\n",
        "            idx += 1\n",
        "        if st_outro and outro_d > 0:\n",
        "            inputs += [\"-thread_queue_size\", \"512\", \"-i\", str(st_outro)]\n",
        "            outro_idx = idx\n",
        "            idx += 1\n",
        "        if st_cta:\n",
        "            cta_d = probe_duration_cached(st_cta)  # type: ignore[name-defined]\n",
        "            if cta_d > 0:\n",
        "                inputs += [\"-thread_queue_size\", \"512\", \"-i\", str(st_cta)]\n",
        "                cta_idx = idx\n",
        "                idx += 1\n",
        "                cta_times = _compute_cta_schedule(\n",
        "                    start_sec=float(cta_start_sec or 0.0),\n",
        "                    repeat_sec=float(cta_repeat_sec or 0.0),\n",
        "                    intro_d=float(intro_d),\n",
        "                    main_d=float(main_d),\n",
        "                    cta_d=float(cta_d),\n",
        "                    cap_offset=float(cap_offset),\n",
        "                )\n",
        "\n",
        "        # Map indexes → asset Paths for audio-stream checks\n",
        "        _ASSET_INDEX_MAP.clear()\n",
        "        if intro_idx is not None and st_intro:\n",
        "            _ASSET_INDEX_MAP[int(intro_idx)] = Path(st_intro)\n",
        "        if outro_idx is not None and st_outro:\n",
        "            _ASSET_INDEX_MAP[int(outro_idx)] = Path(st_outro)\n",
        "        if cta_idx is not None and st_cta:\n",
        "            _ASSET_INDEX_MAP[int(cta_idx)] = Path(st_cta)\n",
        "\n",
        "        vf_parts, last_v_label = _compose_video_filters(\n",
        "            fps=int(fps_val),\n",
        "            cur_label=\"vbg\",\n",
        "            intro_idx=intro_idx,\n",
        "            outro_idx=outro_idx,\n",
        "            cta_idx=cta_idx,\n",
        "            intro_d=float(intro_d),\n",
        "            main_d=float(main_d),\n",
        "            outro_d=float(outro_d),\n",
        "            cta_times=cta_times,\n",
        "            cta_d=float(cta_d),\n",
        "            cta_key_hex=\"0x\" + str(cta_key_color or \"#00FF00\").lstrip(\"#\").upper(),\n",
        "            cta_similarity=float(max(0.0, min(1.0, float(cta_similarity or 0.0)))),\n",
        "            cta_blend=float(max(0.0, min(1.0, float(cta_blend or 0.0)))),\n",
        "            cta_position=str(cta_position),\n",
        "            intro_chroma_key=bool(intro_chroma_key),\n",
        "            outro_chroma_key=bool(outro_chroma_key),\n",
        "        )\n",
        "\n",
        "        af_parts = _build_audio_filters(\n",
        "            main_idx=0,\n",
        "            intro_idx=intro_idx,\n",
        "            outro_idx=outro_idx,\n",
        "            cta_idx=cta_idx,\n",
        "            intro_d=float(intro_d),\n",
        "            main_d=float(main_d),\n",
        "            cta_times=cta_times,\n",
        "            cta_d=float(cta_d),\n",
        "        )\n",
        "\n",
        "        filter_complex = \";\".join(vf_parts + af_parts)\n",
        "        enc_common = [\"-threads\", \"0\", \"-filter_threads\", \"2\", \"-filter_complex_threads\", \"2\"]\n",
        "\n",
        "        out_dir = OUTPUT_ROOT  # type: ignore[name-defined]\n",
        "        out_dir.mkdir(parents=True, exist_ok=True)\n",
        "        ts = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        out_path = out_dir / f\"{ts}_{Path(st_audio).stem}_1920x1080_{str(enc_mode).upper()}.mp4\"\n",
        "        tmp = out_path.with_name(out_path.stem + \".tmp.mp4\")\n",
        "        try:\n",
        "            if tmp.exists():\n",
        "                tmp.unlink()\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        v_color = [\"-colorspace\", \"bt709\", \"-color_primaries\", \"bt709\", \"-color_trc\", \"bt709\", \"-color_range\", \"tv\"]\n",
        "\n",
        "        v_nv = [\"-c:v\", \"h264_nvenc\"] + (\n",
        "            [\"-preset\", \"p3\", \"-rc\", \"constqp\", \"-qp\", \"18\"] if str(enc_mode) == \"race\"\n",
        "            else [\"-preset\", \"p4\", \"-tune\", \"hq\", \"-rc\", \"vbr\", \"-cq\", \"19\", \"-b:v\", \"6M\", \"-maxrate\", \"8M\", \"-bufsize\", \"12M\"]\n",
        "        ) + [\"-g\", str(int(fps_val) * 2), \"-bf\", \"2\", \"-profile:v\", \"high\", \"-pix_fmt\", \"yuv420p\", \"-movflags\", \"+faststart\", *v_color]\n",
        "\n",
        "        v_x = [\"-c:v\", \"libx264\", \"-preset\", \"fast\", \"-crf\", \"21\",\n",
        "               \"-g\", str(int(fps_val) * 2), \"-bf\", \"2\", \"-profile:v\", \"high\", \"-pix_fmt\", \"yuv420p\", \"-movflags\", \"+faststart\", *v_color]\n",
        "\n",
        "        vmap = f\"[{last_v_label}]\"\n",
        "        cmd_base = [\"ffmpeg\", \"-hide_banner\", \"-nostdin\", \"-loglevel\", \"error\", \"-y\",\n",
        "                    *enc_common, *inputs,\n",
        "                    \"-filter_complex\", filter_complex, \"-map\", vmap, \"-map\", \"[afinal]\",\n",
        "                    \"-t\", str(float(total_d)), \"-r\", str(int(fps_val))]\n",
        "        cmd_nv = [*cmd_base, *v_nv, \"-c:a\", \"aac\", \"-b:a\", \"128k\", \"-ac\", \"2\",\n",
        "                  \"-map_metadata\", \"-1\", \"-map_chapters\", \"-1\", \"-max_muxing_queue_size\", \"1024\", str(tmp)]\n",
        "        cmd_x  = [*cmd_base, *v_x , \"-c:a\", \"aac\", \"-b:a\", \"128k\", \"-ac\", \"2\",\n",
        "                  \"-map_metadata\", \"-1\", \"-map_chapters\", \"-1\", \"-max_muxing_queue_size\", \"1024\", str(tmp)]\n",
        "\n",
        "        for r in tick(7, 0.05, \"Encoding...\"):\n",
        "            yield r\n",
        "\n",
        "        used_nv = False\n",
        "        if NVENC_AVAILABLE:  # type: ignore[name-defined]\n",
        "            rc, tail = _run_ffmpeg_with_env(cmd_nv, env_ffmpeg); used_nv = True\n",
        "            if rc != 0:\n",
        "                rc2, tail2 = _run_ffmpeg_with_env(cmd_nv, env_ffmpeg)\n",
        "                if rc2 != 0:\n",
        "                    rcx, tailx = _run_ffmpeg_with_env(cmd_x, env_ffmpeg)\n",
        "                    if rcx != 0 or (not tmp.exists()) or tmp.stat().st_size <= 0:\n",
        "                        yield None, _status_or(7, started), _overall_percent(7, 0.0)  # type: ignore[name-defined]\n",
        "                        yield None, f\"FFmpeg failed:\\n{(tailx or tail2 or tail)[-2000:]}\", _overall_percent(7, 0.0)  # type: ignore[name-defined]\n",
        "                        return\n",
        "        else:\n",
        "            rcx, tailx = _run_ffmpeg_with_env(cmd_x, env_ffmpeg)\n",
        "            if rcx != 0 or (not tmp.exists()) or tmp.stat().st_size <= 0:\n",
        "                yield None, _status_or(7, started), _overall_percent(7, 0.0)  # type: ignore[name-defined]\n",
        "                yield None, f\"FFmpeg failed:\\n{(tailx or '')[-2000:]}\", _overall_percent(7, 0.0)  # type: ignore[name-defined]\n",
        "                return\n",
        "\n",
        "        for r in tick(8, 0.7):\n",
        "            yield r\n",
        "\n",
        "        try:\n",
        "            tmp.replace(out_path)\n",
        "        except Exception:\n",
        "            yield None, _status_or(8, started), _overall_percent(8, 0.7)  # type: ignore[name-defined]\n",
        "            yield None, \"Failed to finalize output file\", _overall_percent(8, 0.7)  # type: ignore[name-defined]\n",
        "            return\n",
        "\n",
        "        try:\n",
        "            if hasattr(os, \"sync\"):\n",
        "                os.sync()\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        local_play = _safe_local_copy(out_path)\n",
        "        size_mb = (out_path.stat().st_size / (1024 * 1024)) if out_path.exists() else 0.0\n",
        "        msg = f\"Rendered<br>{out_path.name}<br>{size_mb:.1f} MB<br>1920x1080@{fps_val}fps\"\n",
        "        yield str(local_play), _status_or(len(STEPS), started, 1.0) + f\"<div style='margin-top:8px'>{msg}</div>\", 100.0  # type: ignore[name-defined]\n",
        "\n",
        "    except Exception as e:\n",
        "        import traceback\n",
        "        yield None, _status_or(0, started), 0.0  # type: ignore[name-defined]\n",
        "        yield None, f\"Failed:<br><pre>{traceback.format_exc()}\\n{e}</pre>\", 0.0\n",
        "        return\n",
        "\n",
        "# =========================\n",
        "# UI factory\n",
        "# =========================\n",
        "\n",
        "def create_ui():\n",
        "    \"\"\"\n",
        "    Build the Gradio Blocks UI and wire callbacks.\n",
        "    Returns the Blocks instance.\n",
        "    \"\"\"\n",
        "    ensure_drive_tree(DRIVE_ROOT)  # type: ignore[name-defined]\n",
        "    a, b, m, f = discover_assets_union()  # type: ignore[name-defined]\n",
        "    nv = \"✅\" if NVENC_AVAILABLE else \"❌\"  # type: ignore[name-defined]\n",
        "\n",
        "    theme = gr.themes.Soft(primary_hue=\"blue\", secondary_hue=\"cyan\", neutral_hue=\"slate\")\n",
        "    css = \".pro-header{background:linear-gradient(135deg,#667eea 0%,#764ba2 100%);padding:1rem;border-radius:0.9rem;margin-bottom:1rem;color:white;text-align:center;}\"\n",
        "\n",
        "    with gr.Blocks(theme=theme, title=\"VideoRobot Studio Pro — CLEAN\", css=css) as ui:\n",
        "        gr.HTML(\n",
        "            f'<div class=\"pro-header\"><h1>🎬 VideoRobot Studio Pro</h1>'\n",
        "            f'<p style=\"opacity:.9\">WORK:{WORK_ROOT} • DRIVE:{DRIVE_ROOT} • NVENC {nv}</p></div>'  # type: ignore[name-defined]\n",
        "        )\n",
        "\n",
        "        with gr.Tabs():\n",
        "            with gr.Tab(\"Inputs\"):\n",
        "                with gr.Row():\n",
        "                    with gr.Column():\n",
        "                        audio    = gr.Dropdown(choices=a, value=(a[0] if a else None), label=\"Audio (Assets)\")\n",
        "                        audio_up = gr.File(file_count=\"single\", file_types=[\".mp3\", \".wav\", \".m4a\", \".aac\"], label=\"Or upload audio\")\n",
        "                        bg       = gr.Dropdown(choices=b, value=(b[0] if b else None), label=\"Background (Assets)\")\n",
        "                        bg_up    = gr.File(file_count=\"single\", file_types=[\".png\", \".jpg\", \".jpeg\"], label=\"Or upload background\")\n",
        "                        whisper  = gr.Radio([\"large-v3\", \"medium\", \"small\"], value=\"small\", label=\"Whisper\")\n",
        "                        refresh  = gr.Button(\"🔄 Refresh Assets\", variant=\"secondary\")\n",
        "                    with gr.Column():\n",
        "                        gr.HTML(\"<div style='opacity:.85'>Preview and live progress are in the <b>Output</b> tab.</div>\")\n",
        "\n",
        "            with gr.Tab(\"Captions\"):\n",
        "                with gr.Row():\n",
        "                    with gr.Column():\n",
        "                        size         = gr.Slider(10, 100, 60, 1, label=\"Caption Size (0–100)\")\n",
        "                        color        = gr.ColorPicker(\"#FFFFFF\", label=\"Text Color\")\n",
        "                        border       = gr.Slider(1, 12, 3, 1, label=\"Outline\")\n",
        "                        pos          = gr.Radio([\"Top\", \"Middle\", \"Bottom\"], value=\"Bottom\", label=\"Position\")\n",
        "                        hmargin      = gr.Slider(0, 400, 154, 2, label=\"Horizontal Margin (px)\")\n",
        "                        vmargin      = gr.Slider(0, 400, 97, 2, label=\"Vertical Margin (px)\")\n",
        "                        koffset      = gr.Slider(-400, 400, 60, 10, label=\"Karaoke Offset (ms)\")\n",
        "                        strict_word  = gr.Checkbox(True, label=\"Strict per-word box\")\n",
        "                        line_count   = gr.Radio([1, 2], value=1, label=\"Lines per Caption\")\n",
        "                        max_wpl      = gr.Slider(1, 12, 6, 1, label=\"Max Words per Line\")\n",
        "                        max_wpc      = gr.Slider(1, 24, 12, 1, label=\"Max Words per Caption\")\n",
        "                    with gr.Column():\n",
        "                        highlight    = gr.Radio([\"word_fill\", \"word_pill\", \"word_bg\", \"none\"], value=\"word_fill\", label=\"Highlight Mode\")\n",
        "                        align_mode   = gr.Radio([\"left\", \"center\", \"right\"], value=\"left\", label=\"Align\")\n",
        "                        safe_area    = gr.Slider(60, 100, 92, 1, label=\"Safe Area %\")\n",
        "                        target_cps   = gr.Slider(8, 28, 17, 1, label=\"Target CPS\")\n",
        "                        line_space   = gr.Slider(60, 200, 100, 2, label=\"Line Spacing %\")\n",
        "                        max_extend   = gr.Slider(0.0, 1.0, 0.40, 0.01, label=\"Max Extend (s)\")\n",
        "                        font         = gr.Dropdown([\"None\"] + f, value=\"None\", label=\"Font file (TTF/OTF)\")\n",
        "                        force_bold_ui= gr.Checkbox(False, label=\"Force Bold text\")\n",
        "\n",
        "            with gr.Tab(\"Intro / Outro / CTA\"):\n",
        "                a2, b2, m2, f2 = discover_assets_union()  # type: ignore[name-defined]\n",
        "                mp4_opts = [\"None\"] + m2\n",
        "                with gr.Row():\n",
        "                    with gr.Column():\n",
        "                        intro    = gr.Dropdown(mp4_opts, value=\"None\", label=\"Intro\")\n",
        "                        intro_ck = gr.Checkbox(False, label=\"Chroma Key Intro\")\n",
        "                        outro    = gr.Dropdown(mp4_opts, value=\"None\", label=\"Outro\")\n",
        "                        outro_ck = gr.Checkbox(False, label=\"Chroma Key Outro\")\n",
        "                    with gr.Column():\n",
        "                        cta       = gr.Dropdown(mp4_opts, value=\"None\", label=\"CTA Loop\")\n",
        "                        cta_pos   = gr.Radio([\"Top\", \"Middle\", \"Bottom\"], value=\"Middle\", label=\"CTA Position\")\n",
        "                        cta_start = gr.Slider(5, 300, 30, 5, label=\"CTA Start (s)\")\n",
        "                        cta_repeat= gr.Slider(10, 600, 120, 10, label=\"CTA Repeat every (s)\")\n",
        "                        cta_key   = gr.ColorPicker(\"#00FF00\", label=\"Chroma Key Color\")\n",
        "                        cta_sim   = gr.Slider(0.01, 1.0, 0.42, 0.01, label=\"Similarity\")\n",
        "                        cta_blend = gr.Slider(0.0, 1.0, 0.08, 0.01, label=\"Blend\")\n",
        "\n",
        "            with gr.Tab(\"Performance\"):\n",
        "                with gr.Row():\n",
        "                    with gr.Column():\n",
        "                        profile    = gr.Radio([\"balanced\", \"turbo\"], value=\"turbo\", label=\"Style Profile\")\n",
        "                        fps        = gr.Slider(24, 60, 24, step=6, label=\"FPS\")\n",
        "                        fast_audio = gr.Checkbox(True, label=\"Fast Audio (skip loudnorm)\")\n",
        "                        subscale   = gr.Slider(70, 100, 80, 1, label=\"Subtitle Subscale %\")\n",
        "                        enc_mode   = gr.Radio([\"studio\", \"race\"], value=\"studio\", label=\"Encoder Mode\")\n",
        "                        smart_mode = gr.Checkbox(True, label=\"Smart Assist\", value=True)\n",
        "\n",
        "            with gr.Tab(\"Output\"):\n",
        "                with gr.Row():\n",
        "                    with gr.Column(scale=1):\n",
        "                        btn  = gr.Button(\"🎬 Render\", variant=\"primary\")\n",
        "                        sout = gr.HTML(value=_status_or(0, time.monotonic()), label=\"📊 Status\")\n",
        "                        pbar = gr.Slider(0, 100, 0, step=1, interactive=False, label=\"Live Progress %\")\n",
        "                    with gr.Column(scale=1):\n",
        "                        vout = gr.Video(label=\"📹 Output Preview\", height=420, autoplay=True, show_download_button=True)\n",
        "\n",
        "        btn.click(\n",
        "            render_video,\n",
        "            [\n",
        "                audio, audio_up, bg, bg_up, whisper, font,\n",
        "                size, color, border, pos, hmargin, vmargin, koffset,\n",
        "                intro, intro_ck, outro, outro_ck,\n",
        "                cta, cta_start, cta_repeat, cta_key, cta_sim, cta_blend, cta_pos,\n",
        "                profile, fps, fast_audio, subscale, enc_mode, smart_mode,\n",
        "                line_count, max_wpl, max_wpc, strict_word,\n",
        "                force_bold_ui,\n",
        "                highlight, align_mode, safe_area, target_cps, line_space, max_extend\n",
        "            ],\n",
        "            [vout, sout, pbar],\n",
        "        )\n",
        "        refresh.click(refresh_assets, outputs=[audio, bg, intro, outro, cta, font])\n",
        "    return ui\n",
        "\n",
        "print(\"UI factory ready.\")\n",
        "ui = create_ui()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "55b270d4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        },
        "id": "55b270d4",
        "outputId": "ca8dea77-8ee4-49c6-f524-bf2767e27416",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://9f5dd1a10eeb841a6d.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://9f5dd1a10eeb841a6d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "READY\n"
          ]
        }
      ],
      "source": [
        "#@title 11) Launch — Hidden\n",
        "#@markdown Start the app inline in Colab.\n",
        "ui = create_ui()\n",
        "ui.queue(api_open=False).launch(inline=True, show_error=True, prevent_thread_lock=True, debug=False)\n",
        "print(\"READY\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    },
    "nbformat_minor": 5
  },
  "nbformat": 4,
  "nbformat_minor": 5
}