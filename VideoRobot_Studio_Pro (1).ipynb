{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "# @title 1) System Bootstrap \u2014 Dependencies & Probes\n",
        "from __future__ import annotations\n",
        "\n",
        "import os\n",
        "import shlex\n",
        "import shutil\n",
        "import subprocess\n",
        "import sys\n",
        "from pathlib import Path\n",
        "from typing import Iterable, Mapping, MutableMapping, Optional\n",
        "\n",
        "NOTEBOOK_VERSION = \"2025.02\"\n",
        "PYTHON_MIN = (3, 10)\n",
        "\n",
        "if sys.version_info < PYTHON_MIN:\n",
        "    raise RuntimeError(\n",
        "        f\"Python {PYTHON_MIN[0]}.{PYTHON_MIN[1]}+ is required \u2014 detected {sys.version_info.major}.{sys.version_info.minor}\"\n",
        "    )\n",
        "\n",
        "ENV_DEFAULTS: Mapping[str, str] = {\n",
        "    \"PIP_DISABLE_PIP_VERSION_CHECK\": \"1\",\n",
        "    \"PIP_NO_PYTHON_VERSION_WARNING\": \"1\",\n",
        "    \"PIP_ROOT_USER_ACTION\": \"ignore\",\n",
        "    \"DEBIAN_FRONTEND\": \"noninteractive\",\n",
        "    \"LC_ALL\": \"C.UTF-8\",\n",
        "    \"LANG\": \"C.UTF-8\",\n",
        "    \"PYTHONIOENCODING\": \"utf-8\",\n",
        "    \"PYTHONWARNINGS\": \"default\",\n",
        "}\n",
        "\n",
        "def build_env(extra: Optional[Mapping[str, str]] = None) -> MutableMapping[str, str]:\n",
        "    env = os.environ.copy()\n",
        "    for k, v in ENV_DEFAULTS.items():\n",
        "        env.setdefault(k, v)\n",
        "    if extra:\n",
        "        env.update(extra)\n",
        "    return env\n",
        "\n",
        "def run(\n",
        "    cmd: Iterable[str] | str,\n",
        "    *,\n",
        "    check: bool = False,\n",
        "    capture: bool = True,\n",
        "    cwd: Optional[Path] = None,\n",
        "    timeout: Optional[float] = None,\n",
        "    env: Optional[Mapping[str, str]] = None,\n",
        ") -> subprocess.CompletedProcess[str]:\n",
        "    args = shlex.split(cmd) if isinstance(cmd, str) else [str(c) for c in cmd]\n",
        "    try:\n",
        "        proc = subprocess.run(\n",
        "            args,\n",
        "            check=False,\n",
        "            stdout=subprocess.PIPE if capture else None,\n",
        "            stderr=subprocess.PIPE if capture else None,\n",
        "            text=True,\n",
        "            cwd=str(cwd) if cwd else None,\n",
        "            timeout=timeout,\n",
        "            env=build_env(env),\n",
        "        )\n",
        "    except FileNotFoundError as exc:\n",
        "        raise RuntimeError(f\"Command not found: {args[0] if args else '<empty>'}\") from exc\n",
        "    except subprocess.TimeoutExpired as exc:\n",
        "        raise RuntimeError(f\"Command timed out: {' '.join(args)}\") from exc\n",
        "\n",
        "    if check and proc.returncode != 0:\n",
        "        output = proc.stderr or proc.stdout or \"\"\n",
        "        raise RuntimeError(output.strip() or f\"Command failed: {' '.join(args)}\")\n",
        "    return proc\n",
        "\n",
        "\n",
        "def apt_install(packages: Iterable[str]) -> None:\n",
        "    pkgs = [p for p in packages if p]\n",
        "    if not pkgs:\n",
        "        return\n",
        "    if not shutil.which(\"apt-get\"):\n",
        "        print(\"\u26a0\ufe0f  apt-get unavailable; skipping APT installs\")\n",
        "        return\n",
        "    update = run([\"apt-get\", \"update\", \"-qq\"], capture=True)\n",
        "    if update.returncode != 0:\n",
        "        print(\"\u26a0\ufe0f  apt-get update failed:\", (update.stderr or update.stdout or \"\").strip())\n",
        "    install = run([\"apt-get\", \"install\", \"-y\", \"-qq\", *pkgs], capture=True)\n",
        "    if install.returncode != 0:\n",
        "        print(\"\u26a0\ufe0f  apt-get install issues:\", (install.stderr or install.stdout or \"\").strip())\n",
        "\n",
        "\n",
        "def pip_install(specifiers: Iterable[str]) -> None:\n",
        "    specs = [s for s in specifiers if s]\n",
        "    if not specs:\n",
        "        return\n",
        "    cmd = [sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", \"--no-input\", \"--no-cache-dir\", *specs]\n",
        "    proc = run(cmd, capture=True)\n",
        "    if proc.returncode != 0:\n",
        "        print(\"\u26a0\ufe0f  pip install issues:\", (proc.stderr or proc.stdout or \"\").strip())\n",
        "\n",
        "\n",
        "def probe_ffmpeg() -> None:\n",
        "    for tool in (\"ffmpeg\", \"ffprobe\", \"fc-match\"):\n",
        "        if shutil.which(tool):\n",
        "            print(f\"\u2705 {tool} detected\")\n",
        "        else:\n",
        "            print(f\"\u274c {tool} missing \u2014 install via apt-get\")\n",
        "\n",
        "APT_REQUIREMENTS = (\"ffmpeg\", \"fontconfig\", \"unzip\", \"fonts-dejavu-core\")\n",
        "PIP_REQUIREMENTS = (\n",
        "    \"gradio==5.49.0\",\n",
        "    \"pydantic==2.10.6\",\n",
        "    \"Pillow==11.3.0\",\n",
        "    \"faster-whisper==1.0.3\",\n",
        "    \"ctranslate2==4.5.0\",\n",
        ")\n",
        "apt_install(APT_REQUIREMENTS)\n",
        "pip_install(PIP_REQUIREMENTS)\n",
        "probe_ffmpeg()\n",
        "print(f\"System bootstrap complete \u2014 notebook v{NOTEBOOK_VERSION} \u2705\")\n",
        "# \u2705\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "# @title 2) Paths, Logging & Deterministic Configuration\n",
        "from __future__ import annotations\n",
        "\n",
        "import logging\n",
        "import os\n",
        "import random\n",
        "import tempfile\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format=\"[%(asctime)s] %(levelname)s - %(message)s\",\n",
        ")\n",
        "logger = logging.getLogger(\"videorobot\")\n",
        "\n",
        "PROJECT_ROOT = Path.cwd()\n",
        "DRIVE_ROOT = Path(os.getenv(\"DRIVE_PATH\", \"/content/drive/MyDrive/VideoRobot\"))\n",
        "WORK_ROOT = Path(os.getenv(\"WORK_PATH\", PROJECT_ROOT / \"workspace\"))\n",
        "CACHE_ROOT = WORK_ROOT / \".cache\"\n",
        "ASSETS_ROOT = WORK_ROOT / \"assets\"\n",
        "RENDERS_ROOT = WORK_ROOT / \"renders\"\n",
        "MODELS_ROOT = WORK_ROOT / \"models\"\n",
        "\n",
        "RANDOM_SEED = int(os.getenv(\"VR_SEED\", \"20250201\"))\n",
        "random.seed(RANDOM_SEED)\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class StudioPaths:\n",
        "    project: Path\n",
        "    drive: Path\n",
        "    work: Path\n",
        "    cache: Path\n",
        "    assets: Path\n",
        "    renders: Path\n",
        "    models: Path\n",
        "\n",
        "    def ensure(self) -> \"StudioPaths\":\n",
        "        for path in (self.work, self.cache, self.assets, self.renders, self.models):\n",
        "            path.mkdir(parents=True, exist_ok=True)\n",
        "        return self\n",
        "\n",
        "PATHS = StudioPaths(\n",
        "    project=PROJECT_ROOT,\n",
        "    drive=DRIVE_ROOT,\n",
        "    work=WORK_ROOT,\n",
        "    cache=CACHE_ROOT,\n",
        "    assets=ASSETS_ROOT,\n",
        "    renders=RENDERS_ROOT,\n",
        "    models=MODELS_ROOT,\n",
        ").ensure()\n",
        "\n",
        "logger.info(\"Project root: %s\", PATHS.project)\n",
        "logger.info(\"Working directory: %s\", PATHS.work)\n",
        "logger.info(\"Cache directory: %s\", PATHS.cache)\n",
        "logger.info(\"Renders directory: %s\", PATHS.renders)\n",
        "logger.info(\"Random seed: %s\", RANDOM_SEED)\n",
        "\n",
        "def clean_temp_directories(prefix: str = \"vr-\", keep_last: int = 3) -> None:\n",
        "    temp_dir = Path(tempfile.gettempdir())\n",
        "    candidates = sorted(\n",
        "        (p for p in temp_dir.glob(f\"{prefix}*\")),\n",
        "        key=lambda p: p.stat().st_mtime,\n",
        "        reverse=True,\n",
        "    )\n",
        "    for stale in candidates[keep_last:]:\n",
        "        try:\n",
        "            if stale.is_dir():\n",
        "                import shutil\n",
        "                shutil.rmtree(stale, ignore_errors=True)\n",
        "            else:\n",
        "                stale.unlink(missing_ok=True)\n",
        "        except Exception as exc:\n",
        "            logger.warning(\"Failed to prune temp %s: %s\", stale, exc)\n",
        "\n",
        "clean_temp_directories()\n",
        "print(\"Studio paths prepared \u2705\")\n",
        "# \u2705\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "# @title 3) Utility Toolkit \u2014 Hashing, IO, and Timing\n",
        "from __future__ import annotations\n",
        "\n",
        "import contextlib\n",
        "import hashlib\n",
        "import json\n",
        "import math\n",
        "import time\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "from typing import Any, Dict, Iterable, Iterator, Tuple\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class TimedResult:\n",
        "    value: Any\n",
        "    seconds: float\n",
        "\n",
        "@contextlib.contextmanager\n",
        "def time_block(label: str) -> Iterator[None]:\n",
        "    start = time.perf_counter()\n",
        "    try:\n",
        "        yield\n",
        "    finally:\n",
        "        duration = time.perf_counter() - start\n",
        "        logger.info(\"%s completed in %.2fs\", label, duration)\n",
        "\n",
        "\n",
        "def sha1_path(path: Path, chunk_size: int = 1 << 20) -> str:\n",
        "    h = hashlib.sha1()\n",
        "    with path.open('rb') as fh:\n",
        "        for chunk in iter(lambda: fh.read(chunk_size), b''):\n",
        "            h.update(chunk)\n",
        "    return h.hexdigest()\n",
        "\n",
        "\n",
        "def safe_slug(name: str, max_length: int = 64) -> str:\n",
        "    import re\n",
        "    cleaned = re.sub(r\"[^A-Za-z0-9._-]+\", \"-\", name).strip('-._')\n",
        "    return cleaned[:max_length] or \"item\"\n",
        "\n",
        "\n",
        "def load_json(path: Path) -> Dict[str, Any]:\n",
        "    if not path.exists():\n",
        "        return {}\n",
        "    with path.open('r', encoding='utf-8') as fh:\n",
        "        return json.load(fh)\n",
        "\n",
        "\n",
        "def save_json(path: Path, payload: Dict[str, Any]) -> None:\n",
        "    path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    with path.open('w', encoding='utf-8') as fh:\n",
        "        json.dump(payload, fh, indent=2, ensure_ascii=False)\n",
        "\n",
        "\n",
        "def thumbnail(path: Path, size: Tuple[int, int] = (640, 640)) -> Path:\n",
        "    out_path = PATHS.cache / f\"thumb-{sha1_path(path)}.png\"\n",
        "    if out_path.exists():\n",
        "        return out_path\n",
        "    with Image.open(path) as img:\n",
        "        img.thumbnail(size, Image.Resampling.LANCZOS)\n",
        "        out_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "        img.save(out_path, format='PNG')\n",
        "    return out_path\n",
        "\n",
        "print(\"Utility toolkit loaded \u2705\")\n",
        "# \u2705\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "# @title 4) Asset Discovery & Metadata Helpers\n",
        "from __future__ import annotations\n",
        "\n",
        "import itertools\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "from typing import List, Sequence, Tuple\n",
        "\n",
        "AUDIO_EXTS = (\".wav\", \".mp3\", \".m4a\", \".aac\", \".flac\")\n",
        "IMAGE_EXTS = (\".png\", \".jpg\", \".jpeg\")\n",
        "VIDEO_EXTS = (\".mp4\", \".mov\", \".mkv\")\n",
        "FONT_EXTS = (\".ttf\", \".otf\")\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class AssetCatalog:\n",
        "    audio: List[Path]\n",
        "    backgrounds: List[Path]\n",
        "    videos: List[Path]\n",
        "    fonts: List[Path]\n",
        "\n",
        "    def as_choices(self) -> Tuple[List[str], List[str], List[str], List[str]]:\n",
        "        return (\n",
        "            [str(p) for p in self.audio],\n",
        "            [str(p) for p in self.backgrounds],\n",
        "            [str(p) for p in self.videos],\n",
        "            [str(p) for p in self.fonts],\n",
        "        )\n",
        "\n",
        "\n",
        "def discover_assets(root: Path = PATHS.assets) -> AssetCatalog:\n",
        "    audio: List[Path] = []\n",
        "    backgrounds: List[Path] = []\n",
        "    videos: List[Path] = []\n",
        "    fonts: List[Path] = []\n",
        "\n",
        "    if not root.exists():\n",
        "        logger.warning(\"Assets directory missing: %s\", root)\n",
        "        return AssetCatalog(audio, backgrounds, videos, fonts)\n",
        "\n",
        "    for path in root.rglob('*'):\n",
        "        if not path.is_file():\n",
        "            continue\n",
        "        suffix = path.suffix.lower()\n",
        "        if suffix in AUDIO_EXTS:\n",
        "            audio.append(path)\n",
        "        elif suffix in IMAGE_EXTS:\n",
        "            backgrounds.append(path)\n",
        "        elif suffix in VIDEO_EXTS:\n",
        "            videos.append(path)\n",
        "        elif suffix in FONT_EXTS:\n",
        "            fonts.append(path)\n",
        "\n",
        "    audio.sort()\n",
        "    backgrounds.sort()\n",
        "    videos.sort()\n",
        "    fonts.sort()\n",
        "    logger.info(\n",
        "        \"Assets discovered \u2014 audio:%d background:%d video:%d font:%d\",\n",
        "        len(audio), len(backgrounds), len(videos), len(fonts)\n",
        "    )\n",
        "    return AssetCatalog(audio, backgrounds, videos, fonts)\n",
        "\n",
        "ASSETS = discover_assets()\n",
        "print(\"Asset catalog built \u2705\")\n",
        "# \u2705\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "# @title 5) Audio Pipeline \u2014 Analysis, Normalization, and Caching\n",
        "from __future__ import annotations\n",
        "\n",
        "import json\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "from typing import Dict\n",
        "\n",
        "LN_TARGET_I = -16.0\n",
        "LN_TARGET_LRA = 7.0\n",
        "LN_TARGET_TP = -1.5\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class AudioInfo:\n",
        "    path: Path\n",
        "    codec: str\n",
        "    sample_rate: int\n",
        "    channels: int\n",
        "    duration: float\n",
        "\n",
        "\n",
        "def ffprobe_audio(path: Path) -> AudioInfo:\n",
        "    if not path.exists():\n",
        "        raise FileNotFoundError(path)\n",
        "    probe_cmd = [\n",
        "        \"ffprobe\",\n",
        "        \"-hide_banner\",\n",
        "        \"-v\",\n",
        "        \"error\",\n",
        "        \"-print_format\",\n",
        "        \"json\",\n",
        "        \"-show_streams\",\n",
        "        \"-i\",\n",
        "        str(path),\n",
        "    ]\n",
        "    result = run(probe_cmd, capture=True)\n",
        "    if result.returncode != 0 or not result.stdout:\n",
        "        raise RuntimeError(f\"ffprobe failed for {path}: {result.stderr}\")\n",
        "    payload = json.loads(result.stdout)\n",
        "    streams = payload.get(\"streams\", [])\n",
        "    audio_stream = next((s for s in streams if s.get(\"codec_type\") == \"audio\"), None)\n",
        "    if not audio_stream:\n",
        "        raise RuntimeError(f\"No audio stream found in {path}\")\n",
        "    duration = float(audio_stream.get(\"duration\") or payload.get(\"format\", {}).get(\"duration\") or 0.0)\n",
        "    return AudioInfo(\n",
        "        path=path,\n",
        "        codec=str(audio_stream.get(\"codec_name\", \"unknown\")),\n",
        "        sample_rate=int(audio_stream.get(\"sample_rate\", 0)),\n",
        "        channels=int(audio_stream.get(\"channels\", 0)),\n",
        "        duration=duration,\n",
        "    )\n",
        "\n",
        "\n",
        "def loudnorm_filters(info: AudioInfo, enable: bool) -> str:\n",
        "    if not enable:\n",
        "        return \"aresample=48000:async=1,aformat=channel_layouts=stereo\"\n",
        "    measure_cmd = [\n",
        "        \"ffmpeg\",\n",
        "        \"-hide_banner\",\n",
        "        \"-loglevel\",\n",
        "        \"error\",\n",
        "        \"-i\",\n",
        "        str(info.path),\n",
        "        \"-vn\",\n",
        "        \"-sn\",\n",
        "        \"-dn\",\n",
        "        \"-af\",\n",
        "        \"loudnorm=I=-16:TP=-1.5:LRA=7:print_format=json\",\n",
        "        \"-f\",\n",
        "        \"null\",\n",
        "        \"-\",\n",
        "    ]\n",
        "    measure = run(measure_cmd, capture=True)\n",
        "    summary: Dict[str, float] = {}\n",
        "    if measure.stderr:\n",
        "        for line in measure.stderr.splitlines():\n",
        "            text = line.strip()\n",
        "            if text.startswith('{') and text.endswith('}'):\n",
        "                try:\n",
        "                    summary = json.loads(text)\n",
        "                    break\n",
        "                except json.JSONDecodeError:\n",
        "                    continue\n",
        "    if summary:\n",
        "        return (\n",
        "            \"loudnorm=\"\n",
        "            f\"I={LN_TARGET_I}:LRA={LN_TARGET_LRA}:TP={LN_TARGET_TP}:\"\n",
        "            f\"measured_I={summary.get('input_i', 0.0)}:\"\n",
        "            f\"measured_LRA={summary.get('input_lra', 0.0)}:\"\n",
        "            f\"measured_TP={summary.get('input_tp', 0.0)}:\"\n",
        "            f\"measured_thresh={summary.get('input_thresh', 0.0)}:\"\n",
        "            f\"offset={summary.get('target_offset', 0.0)}:\"\n",
        "            \"linear=true:print_format=summary,\"\n",
        "            \"aresample=48000:async=1,aformat=channel_layouts=stereo\"\n",
        "        )\n",
        "    return \"dynaudnorm=f=125:g=15,aresample=48000:async=1,aformat=channel_layouts=stereo\"\n",
        "\n",
        "\n",
        "def normalize_audio(path: Path, *, fast: bool = True) -> Path:\n",
        "    info = ffprobe_audio(path)\n",
        "    cache_key = f\"audio-{sha1_path(info.path)}-{'fast' if fast else 'loud'}\"\n",
        "    target = PATHS.cache / f\"{cache_key}.m4a\"\n",
        "    if target.exists():\n",
        "        return target\n",
        "    filter_graph = loudnorm_filters(info, enable=not fast)\n",
        "    cmd = [\n",
        "        \"ffmpeg\",\n",
        "        \"-hide_banner\",\n",
        "        \"-loglevel\",\n",
        "        \"error\",\n",
        "        \"-y\",\n",
        "        \"-i\",\n",
        "        str(info.path),\n",
        "        \"-vn\",\n",
        "        \"-sn\",\n",
        "        \"-dn\",\n",
        "        \"-af\",\n",
        "        filter_graph,\n",
        "        \"-ac\",\n",
        "        \"2\",\n",
        "        \"-c:a\",\n",
        "        \"aac\",\n",
        "        \"-b:a\",\n",
        "        \"160k\",\n",
        "        \"-movflags\",\n",
        "        \"+faststart\",\n",
        "        str(target),\n",
        "    ]\n",
        "    result = run(cmd, capture=True)\n",
        "    if result.returncode != 0:\n",
        "        raise RuntimeError(f\"Audio normalize failed for {path}: {result.stderr}\")\n",
        "    return target\n",
        "\n",
        "print(\"Audio pipeline ready \u2705\")\n",
        "# \u2705\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "# @title 6) Speech-To-Text \u2014 Faster-Whisper Integration\n",
        "from __future__ import annotations\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from functools import lru_cache\n",
        "from pathlib import Path\n",
        "from typing import Iterable, List, Optional\n",
        "\n",
        "from faster_whisper import WhisperModel\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class WordTiming:\n",
        "    word: str\n",
        "    start: float\n",
        "    end: float\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class SegmentTiming:\n",
        "    id: int\n",
        "    start: float\n",
        "    end: float\n",
        "    text: str\n",
        "    words: List[WordTiming]\n",
        "\n",
        "\n",
        "@lru_cache(maxsize=2)\n",
        "def load_whisper(model_size: str = \"small\", compute_type: str = \"default\") -> WhisperModel:\n",
        "    model_path = PATHS.models / f\"whisper-{model_size}\"\n",
        "    model_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    logger.info(\"Loading Whisper model %s (cache: %s)\", model_size, model_path)\n",
        "    return WhisperModel(model_size, device=\"auto\", compute_type=compute_type, download_root=str(model_path))\n",
        "\n",
        "\n",
        "def transcribe_audio(\n",
        "    audio_file: Path,\n",
        "    model_size: str = \"small\",\n",
        "    language: Optional[str] = None,\n",
        "    beam_size: int = 5,\n",
        "    vad_filter: bool = True,\n",
        "    condition_on_previous: bool = True,\n",
        ") -> List[SegmentTiming]:\n",
        "    if not audio_file.exists():\n",
        "        raise FileNotFoundError(audio_file)\n",
        "    model = load_whisper(model_size)\n",
        "    logger.info(\"Transcribing %s\", audio_file)\n",
        "    segments, _ = model.transcribe(\n",
        "        str(audio_file),\n",
        "        beam_size=beam_size,\n",
        "        language=language,\n",
        "        condition_on_previous_text=condition_on_previous,\n",
        "        vad_filter=vad_filter,\n",
        "        suppress_tokens=\"-1\",\n",
        "    )\n",
        "    parsed: List[SegmentTiming] = []\n",
        "    for idx, segment in enumerate(segments):\n",
        "        words = [\n",
        "            WordTiming(word=w.word, start=w.start or segment.start, end=w.end or segment.end)\n",
        "            for w in (segment.words or [])\n",
        "        ]\n",
        "        parsed.append(\n",
        "            SegmentTiming(\n",
        "                id=idx,\n",
        "                start=float(segment.start),\n",
        "                end=float(segment.end),\n",
        "                text=segment.text.strip(),\n",
        "                words=words,\n",
        "            )\n",
        "        )\n",
        "    logger.info(\"Transcription produced %d segments\", len(parsed))\n",
        "    return parsed\n",
        "\n",
        "print(\"Speech-to-text module armed \u2705\")\n",
        "# \u2705\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "# @title 7) Caption Authoring \u2014 Styles, Layout & Export\n",
        "from __future__ import annotations\n",
        "\n",
        "import datetime as dt\n",
        "import os\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "from typing import Iterable, List\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class CaptionStyle:\n",
        "    font: str = \"Inter\"\n",
        "    font_size: int = 64\n",
        "    primary_color: str = \"&H00FFFFFF\"\n",
        "    secondary_color: str = \"&H00FFFFFF\"\n",
        "    outline_color: str = \"&H00000000\"\n",
        "    background_color: str = \"&H64000000\"\n",
        "    outline_width: float = 3.0\n",
        "    shadow: float = 0.0\n",
        "    alignment: int = 2\n",
        "    margin_h: int = 80\n",
        "    margin_v: int = 80\n",
        "    bold: bool = False\n",
        "\n",
        "    def ass_style(self) -> str:\n",
        "        weight = -1 if self.bold else 0\n",
        "        return (\n",
        "            \"Style: VRDefault,{font},{size},{primary},{secondary},{outline},{background},\"\n",
        "            \"{bold},0,0,0,100,100,0,0,1,{outline_width},{shadow},{align},{margin_h},{margin_h},{margin_v},0\"\n",
        "        ).format(\n",
        "            font=self.font,\n",
        "            size=self.font_size,\n",
        "            primary=self.primary_color,\n",
        "            secondary=self.secondary_color,\n",
        "            outline=self.outline_color,\n",
        "            background=self.background_color,\n",
        "            bold=weight,\n",
        "            outline_width=self.outline_width,\n",
        "            shadow=self.shadow,\n",
        "            align=self.alignment,\n",
        "            margin_h=self.margin_h,\n",
        "            margin_v=self.margin_v,\n",
        "        )\n",
        "\n",
        "\n",
        "def srt_timestamp(seconds: float) -> str:\n",
        "    td = dt.timedelta(seconds=max(seconds, 0.0))\n",
        "    total = int(td.total_seconds())\n",
        "    hours = total // 3600\n",
        "    minutes = (total % 3600) // 60\n",
        "    secs = total % 60\n",
        "    millis = int((td.total_seconds() - total) * 1000)\n",
        "    return f\"{hours:02}:{minutes:02}:{secs:02},{millis:03}\"\n",
        "\n",
        "\n",
        "def export_srt(segments: Iterable[SegmentTiming], path: Path) -> Path:\n",
        "    newline = os.linesep\n",
        "    lines: List[str] = []\n",
        "    for idx, seg in enumerate(segments, start=1):\n",
        "        lines.append(str(idx))\n",
        "        lines.append(f\"{srt_timestamp(seg.start)} --> {srt_timestamp(seg.end)}\")\n",
        "        lines.append(seg.text)\n",
        "        lines.append(\"\")\n",
        "    payload = newline.join(lines).strip() + newline\n",
        "    path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    path.write_text(payload, encoding='utf-8')\n",
        "    return path\n",
        "\n",
        "\n",
        "def export_ass(segments: Iterable[SegmentTiming], path: Path, style: CaptionStyle) -> Path:\n",
        "    newline = os.linesep\n",
        "    header = [\n",
        "        \"[Script Info]\",\n",
        "        \"ScriptType: v4.00+\",\n",
        "        \"WrapStyle: 2\",\n",
        "        \"ScaledBorderAndShadow: yes\",\n",
        "        \"YCbCr Matrix: TV.709\",\n",
        "        \"\",\n",
        "        \"[V4+ Styles]\",\n",
        "        \"Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, \"\n",
        "        \"Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, \"\n",
        "        \"Alignment, MarginL, MarginR, MarginV, Encoding\",\n",
        "        style.ass_style(),\n",
        "        \"\",\n",
        "        \"[Events]\",\n",
        "        \"Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text\",\n",
        "    ]\n",
        "    body: List[str] = []\n",
        "    for seg in segments:\n",
        "        clean_text = seg.text.replace(chr(10), \"\\\\N\")\n",
        "        body.append(\n",
        "            f\"Dialogue: 0,{srt_timestamp(seg.start).replace(',', '.')},{srt_timestamp(seg.end).replace(',', '.')},\"\n",
        "            f\"VRDefault,,0,0,0,,{clean_text}\"\n",
        "        )\n",
        "    payload = newline.join(header + body) + newline\n",
        "    path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    path.write_text(payload, encoding='utf-8')\n",
        "    return path\n",
        "\n",
        "print(\"Caption authoring utilities ready \u2705\")\n",
        "# \u2705\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "# @title 8) Video Composition \u2014 FFmpeg Assembly\n",
        "from __future__ import annotations\n",
        "\n",
        "import shutil\n",
        "import tempfile\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "from typing import Optional, Tuple\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class RenderConfig:\n",
        "    audio: Path\n",
        "    background: Optional[Path]\n",
        "    captions_ass: Optional[Path]\n",
        "    output: Path\n",
        "    fps: int = 30\n",
        "    resolution: Tuple[int, int] = (1080, 1920)\n",
        "    use_nvenc: bool = False\n",
        "    intro: Optional[Path] = None\n",
        "    outro: Optional[Path] = None\n",
        "    cta_loop: Optional[Path] = None\n",
        "\n",
        "\n",
        "def validate_config(cfg: RenderConfig) -> None:\n",
        "    if not cfg.audio.exists():\n",
        "        raise FileNotFoundError(cfg.audio)\n",
        "    if cfg.background and not cfg.background.exists():\n",
        "        raise FileNotFoundError(cfg.background)\n",
        "    if cfg.captions_ass and not cfg.captions_ass.exists():\n",
        "        raise FileNotFoundError(cfg.captions_ass)\n",
        "    cfg.output.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "def background_input(cfg: RenderConfig) -> Tuple[str, ...]:\n",
        "    if cfg.background and cfg.background.exists():\n",
        "        if cfg.background.suffix.lower() in IMAGE_EXTS:\n",
        "            return (\"-loop\", \"1\", \"-framerate\", str(cfg.fps), \"-i\", str(cfg.background))\n",
        "        return (\"-i\", str(cfg.background))\n",
        "    width, height = cfg.resolution\n",
        "    return (\"-f\", \"lavfi\", \"-i\", f\"color=size={width}x{height}:rate={cfg.fps}:color=black\")\n",
        "\n",
        "\n",
        "def encoder_args(cfg: RenderConfig) -> Tuple[str, ...]:\n",
        "    if cfg.use_nvenc and shutil.which(\"nvidia-smi\"):\n",
        "        return (\"-c:v\", \"h264_nvenc\", \"-preset\", \"p4\", \"-b:v\", \"12M\", \"-maxrate\", \"16M\", \"-bufsize\", \"24M\")\n",
        "    return (\"-c:v\", \"libx264\", \"-preset\", \"slow\", \"-crf\", \"18\", \"-x264-params\", \"keyint=96:min-keyint=48\")\n",
        "\n",
        "\n",
        "def subtitles_expr(path: Path) -> str:\n",
        "    if not path:\n",
        "        return \"\"\n",
        "    escaped = path.as_posix().replace(\"'\", r\"'\")\n",
        "    return f\",subtitles='{escaped}'\"\n",
        "\n",
        "\n",
        "def render_video(cfg: RenderConfig) -> Path:\n",
        "    validate_config(cfg)\n",
        "    temp_dir = Path(tempfile.mkdtemp(prefix=\"vr-render-\", dir=PATHS.cache))\n",
        "    try:\n",
        "        video_label = \"[vout]\"\n",
        "        sub_expr = subtitles_expr(cfg.captions_ass) if cfg.captions_ass else \"\"\n",
        "        scale_filter = (\n",
        "            f\"[0:v]scale={cfg.resolution[0]}:{cfg.resolution[1]}:force_original_aspect_ratio=increase\"\n",
        "            f\",crop={cfg.resolution[0]}:{cfg.resolution[1]}{sub_expr}{video_label}\"\n",
        "        )\n",
        "        filters = [scale_filter, \"[1:a]anull[aout]\"]\n",
        "        cmd = [\n",
        "            \"ffmpeg\",\n",
        "            \"-hide_banner\",\n",
        "            \"-loglevel\",\n",
        "            \"error\",\n",
        "            \"-y\",\n",
        "            *background_input(cfg),\n",
        "            \"-i\",\n",
        "            str(cfg.audio),\n",
        "            \"-filter_complex\",\n",
        "            \";\".join(filters),\n",
        "            \"-map\",\n",
        "            video_label,\n",
        "            \"-map\",\n",
        "            \"[aout]\",\n",
        "            *encoder_args(cfg),\n",
        "            \"-r\",\n",
        "            str(cfg.fps),\n",
        "            \"-pix_fmt\",\n",
        "            \"yuv420p\",\n",
        "            \"-movflags\",\n",
        "            \"+faststart\",\n",
        "            \"-c:a\",\n",
        "            \"aac\",\n",
        "            \"-b:a\",\n",
        "            \"192k\",\n",
        "            str(cfg.output),\n",
        "        ]\n",
        "        result = run(cmd, capture=True)\n",
        "        if result.returncode != 0:\n",
        "            raise RuntimeError(f\"FFmpeg render failed: {result.stderr}\")\n",
        "        return cfg.output\n",
        "    finally:\n",
        "        shutil.rmtree(temp_dir, ignore_errors=True)\n",
        "\n",
        "print(\"Video composition engine primed \u2705\")\n",
        "# \u2705\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "# @title 9) End-to-End Renderer \u2014 Orchestration Logic\n",
        "from __future__ import annotations\n",
        "\n",
        "import datetime as dt\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "from typing import Optional, Tuple\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class RenderRequest:\n",
        "    audio: Path\n",
        "    background: Optional[Path]\n",
        "    whisper_model: str = \"small\"\n",
        "    language: Optional[str] = None\n",
        "    fast_audio: bool = True\n",
        "    fps: int = 30\n",
        "    resolution: Tuple[int, int] = (1080, 1920)\n",
        "    use_nvenc: bool = False\n",
        "    font: Optional[Path] = None\n",
        "    bold: bool = False\n",
        "\n",
        "\n",
        "def build_style(req: RenderRequest) -> CaptionStyle:\n",
        "    font_name = req.font.name if req.font else \"Inter\"\n",
        "    return CaptionStyle(font=font_name, bold=req.bold)\n",
        "\n",
        "\n",
        "def workflow(request: RenderRequest) -> Tuple[Path, Path, Path]:\n",
        "    slug = safe_slug(request.audio.stem)\n",
        "    logger.info(\"Starting render for %s\", slug)\n",
        "\n",
        "    normalized_audio = normalize_audio(request.audio, fast=request.fast_audio)\n",
        "    segments = transcribe_audio(normalized_audio, model_size=request.whisper_model, language=request.language)\n",
        "\n",
        "    captions_dir = PATHS.cache / f\"captions-{slug}\"\n",
        "    captions_dir.mkdir(parents=True, exist_ok=True)\n",
        "    style = build_style(request)\n",
        "    ass_path = export_ass(segments, captions_dir / f\"{slug}.ass\", style)\n",
        "    srt_path = export_srt(segments, captions_dir / f\"{slug}.srt\")\n",
        "\n",
        "    output = PATHS.renders / f\"{dt.datetime.utcnow():%Y%m%d-%H%M%S}-{slug}.mp4\"\n",
        "    cfg = RenderConfig(\n",
        "        audio=normalized_audio,\n",
        "        background=request.background,\n",
        "        captions_ass=ass_path,\n",
        "        output=output,\n",
        "        fps=request.fps,\n",
        "        resolution=request.resolution,\n",
        "        use_nvenc=request.use_nvenc,\n",
        "    )\n",
        "    render_video(cfg)\n",
        "    logger.info(\"Render complete: %s\", output)\n",
        "    return output, ass_path, srt_path\n",
        "\n",
        "print(\"Workflow coordinator armed \u2705\")\n",
        "# \u2705\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "# @title 10) Interactive Studio \u2014 Gradio UI Definition\n",
        "from __future__ import annotations\n",
        "\n",
        "from pathlib import Path\n",
        "from typing import Optional, Tuple\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "THEME = gr.themes.Soft(primary_hue=\"blue\", secondary_hue=\"cyan\", neutral_hue=\"slate\")\n",
        "\n",
        "def refresh_catalog() -> Tuple[gr.Dropdown, gr.Dropdown]:\n",
        "    global ASSETS\n",
        "    ASSETS = discover_assets()\n",
        "    audio_choices, bg_choices, *_ = ASSETS.as_choices()\n",
        "    return (\n",
        "        gr.Dropdown.update(choices=audio_choices, value=audio_choices[0] if audio_choices else None),\n",
        "        gr.Dropdown.update(choices=bg_choices, value=bg_choices[0] if bg_choices else None),\n",
        "    )\n",
        "\n",
        "\n",
        "def persist_upload(file: Optional[gr.FileData], subdir: str) -> Optional[Path]:\n",
        "    if not file:\n",
        "        return None\n",
        "    target_dir = PATHS.assets / subdir\n",
        "    target_dir.mkdir(parents=True, exist_ok=True)\n",
        "    source = Path(file.path)\n",
        "    target = target_dir / safe_slug(source.stem + source.suffix)\n",
        "    target.write_bytes(Path(file.path).read_bytes())\n",
        "    return target\n",
        "\n",
        "\n",
        "def render_entry(\n",
        "    audio_choice: str,\n",
        "    audio_upload: Optional[gr.FileData],\n",
        "    background_choice: str,\n",
        "    background_upload: Optional[gr.FileData],\n",
        "    whisper_model: str,\n",
        "    language: str,\n",
        "    fast_audio: bool,\n",
        "    fps: float,\n",
        "    use_nvenc: bool,\n",
        "    bold: bool,\n",
        ") -> Tuple[str, str, int]:\n",
        "    progress = gr.Progress(track_tqdm=False)\n",
        "    progress(0, desc=\"Preparing\")\n",
        "\n",
        "    audio_path = Path(audio_choice) if audio_choice else None\n",
        "    if audio_upload:\n",
        "        uploaded = persist_upload(audio_upload, \"uploads/audio\")\n",
        "        audio_path = uploaded or audio_path\n",
        "    if not audio_path:\n",
        "        raise gr.Error(\"Select or upload an audio track\")\n",
        "\n",
        "    background_path = Path(background_choice) if background_choice else None\n",
        "    if background_upload:\n",
        "        uploaded_bg = persist_upload(background_upload, \"uploads/background\")\n",
        "        background_path = uploaded_bg or background_path\n",
        "\n",
        "    request = RenderRequest(\n",
        "        audio=audio_path,\n",
        "        background=background_path,\n",
        "        whisper_model=whisper_model,\n",
        "        language=language or None,\n",
        "        fast_audio=fast_audio,\n",
        "        fps=int(fps),\n",
        "        use_nvenc=use_nvenc,\n",
        "        bold=bold,\n",
        "    )\n",
        "\n",
        "    progress(30, desc=\"Transcribing & styling\")\n",
        "    video_path, ass_path, srt_path = workflow(request)\n",
        "    progress(100, desc=\"Done\")\n",
        "\n",
        "    status = (\n",
        "        f\"<div><h3>Render complete</h3><ul>\"\n",
        "        f\"<li>Video: {video_path}</li>\"\n",
        "        f\"<li>ASS: {ass_path}</li>\"\n",
        "        f\"<li>SRT: {srt_path}</li></ul></div>\"\n",
        "    )\n",
        "    return str(video_path), status, 100\n",
        "\n",
        "\n",
        "def create_ui() -> gr.Blocks:\n",
        "    audio_choices, bg_choices, *_ = ASSETS.as_choices()\n",
        "    with gr.Blocks(theme=THEME, title=\"VideoRobot Studio Pro \u2014 Refactored\") as demo:\n",
        "        gr.Markdown(\"## \ud83c\udfac VideoRobot Studio Pro \u2014 Production Edition\")\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=1):\n",
        "                audio = gr.Dropdown(audio_choices, label=\"Audio\", value=audio_choices[0] if audio_choices else None)\n",
        "                audio_up = gr.File(label=\"Upload audio\", file_count=\"single\", file_types=[\"audio\"])\n",
        "                bg = gr.Dropdown(bg_choices, label=\"Background\", value=bg_choices[0] if bg_choices else None)\n",
        "                bg_up = gr.File(label=\"Upload background\", file_count=\"single\", file_types=[\"image\"])\n",
        "                refresh = gr.Button(\"\ud83d\udd04 Refresh assets\", variant=\"secondary\")\n",
        "            with gr.Column(scale=1):\n",
        "                model = gr.Radio([\"large-v3\", \"medium\", \"small\"], value=\"small\", label=\"Whisper size\")\n",
        "                language = gr.Textbox(value=\"\", label=\"Language hint (optional)\")\n",
        "                fast_audio = gr.Checkbox(True, label=\"Fast audio path (skip loudnorm)\")\n",
        "                fps = gr.Slider(24, 60, 30, step=6, label=\"FPS\")\n",
        "                use_nvenc = gr.Checkbox(False, label=\"Use NVENC (if available)\")\n",
        "                bold = gr.Checkbox(False, label=\"Bold captions\")\n",
        "        with gr.Row():\n",
        "            run_btn = gr.Button(\"Render\", variant=\"primary\")\n",
        "        with gr.Row():\n",
        "            video = gr.Video(label=\"Preview\", height=420, autoplay=True, show_download_button=True)\n",
        "            status = gr.HTML(\"Awaiting render\u2026\")\n",
        "            progress = gr.Slider(0, 100, 0, interactive=False, label=\"Progress %\")\n",
        "\n",
        "        run_btn.click(\n",
        "            render_entry,\n",
        "            inputs=[audio, audio_up, bg, bg_up, model, language, fast_audio, fps, use_nvenc, bold],\n",
        "            outputs=[video, status, progress],\n",
        "        )\n",
        "\n",
        "        refresh.click(refresh_catalog, outputs=[audio, bg])\n",
        "    return demo\n",
        "\n",
        "print(\"UI factory configured \u2705\")\n",
        "# \u2705\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "# @title 11) Launch Studio \u2014 Gradio App\n",
        "from __future__ import annotations\n",
        "\n",
        "try:\n",
        "    ui = create_ui()\n",
        "    ui.queue(api_open=False).launch(inline=True, show_error=True, prevent_thread_lock=True)\n",
        "    print(\"Studio ready \u2705\")\n",
        "except Exception as exc:\n",
        "    raise RuntimeError(f\"Failed to launch UI: {exc}\")\n",
        "# \u2705\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "# @title 2) Paths, Logging & Deterministic Configuration\n",
    "from __future__ import annotations\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import tempfile\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"[%(asctime)s] %(levelname)s - %(message)s\",\n",
    ")\n",
    "logger = logging.getLogger(\"videorobot\")\n",
    "\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "DRIVE_ROOT = Path(os.getenv(\"DRIVE_PATH\", \"/content/drive/MyDrive/VideoRobot\"))\n",
    "WORK_ROOT = Path(os.getenv(\"WORK_PATH\", PROJECT_ROOT / \"workspace\"))\n",
    "CACHE_ROOT = WORK_ROOT / \".cache\"\n",
    "ASSETS_ROOT = WORK_ROOT / \"assets\"\n",
    "RENDERS_ROOT = WORK_ROOT / \"renders\"\n",
    "MODELS_ROOT = WORK_ROOT / \"models\"\n",
    "\n",
    "RANDOM_SEED = int(os.getenv(\"VR_SEED\", \"20250201\"))\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class StudioPaths:\n",
    "    project: Path\n",
    "    drive: Path\n",
    "    work: Path\n",
    "    cache: Path\n",
    "    assets: Path\n",
    "    renders: Path\n",
    "    models: Path\n",
    "\n",
    "    def ensure(self) -> \"StudioPaths\":\n",
    "        for path in (self.work, self.cache, self.assets, self.renders, self.models):\n",
    "            path.mkdir(parents=True, exist_ok=True)\n",
    "        return self\n",
    "\n",
    "PATHS = StudioPaths(\n",
    "    project=PROJECT_ROOT,\n",
    "    drive=DRIVE_ROOT,\n",
    "    work=WORK_ROOT,\n",
    "    cache=CACHE_ROOT,\n",
    "    assets=ASSETS_ROOT,\n",
    "    renders=RENDERS_ROOT,\n",
    "    models=MODELS_ROOT,\n",
    ").ensure()\n",
    "\n",
    "logger.info(\"Project root: %s\", PATHS.project)\n",
    "logger.info(\"Working directory: %s\", PATHS.work)\n",
    "logger.info(\"Cache directory: %s\", PATHS.cache)\n",
    "logger.info(\"Renders directory: %s\", PATHS.renders)\n",
    "logger.info(\"Random seed: %s\", RANDOM_SEED)\n",
    "\n",
    "def clean_temp_directories(prefix: str = \"vr-\", keep_last: int = 3) -> None:\n",
    "    temp_dir = Path(tempfile.gettempdir())\n",
    "    candidates = sorted(\n",
    "        (p for p in temp_dir.glob(f\"{prefix}*\")),\n",
    "        key=lambda p: p.stat().st_mtime,\n",
    "        reverse=True,\n",
    "    )\n",
    "    for stale in candidates[keep_last:]:\n",
    "        try:\n",
    "            if stale.is_dir():\n",
    "                import shutil\n",
    "                shutil.rmtree(stale, ignore_errors=True)\n",
    "            else:\n",
    "                stale.unlink(missing_ok=True)\n",
    "        except Exception as exc:\n",
    "            logger.warning(\"Failed to prune temp %s: %s\", stale, exc)\n",
    "\n",
    "clean_temp_directories()\n",
    "print(\"Studio paths prepared ✅\")\n",
    "# ✅\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# @title 3) Utility Toolkit — Hashing, IO, and Timing\n",
    "from __future__ import annotations\n",
    "\n",
    "import contextlib\n",
    "import hashlib\n",
    "import json\n",
    "import shutil\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Iterable, Iterator, Tuple\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class TimedResult:\n",
    "    value: Any\n",
    "    seconds: float\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def time_block(label: str) -> Iterator[None]:\n",
    "    start = time.perf_counter()\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        duration = time.perf_counter() - start\n",
    "        logger.info(\"%s completed in %.2fs\", label, duration)\n",
    "\n",
    "\n",
    "def sha1_path(path: Path, chunk_size: int = 1 << 20) -> str:\n",
    "    h = hashlib.sha1()\n",
    "    with path.open('rb') as fh:\n",
    "        for chunk in iter(lambda: fh.read(chunk_size), b''):\n",
    "            h.update(chunk)\n",
    "    return h.hexdigest()\n",
    "\n",
    "\n",
    "def safe_slug(name: str, max_length: int = 64) -> str:\n",
    "    import re\n",
    "    cleaned = re.sub(r\"[^A-Za-z0-9._-]+\", \"-\", name).strip('-._')\n",
    "    return cleaned[:max_length] or \"item\"\n",
    "\n",
    "\n",
    "def load_json(path: Path) -> Dict[str, Any]:\n",
    "    if not path.exists():\n",
    "        return {}\n",
    "    with path.open('r', encoding='utf-8') as fh:\n",
    "        return json.load(fh)\n",
    "\n",
    "\n",
    "def save_json(path: Path, payload: Dict[str, Any]) -> None:\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with path.open('w', encoding='utf-8') as fh:\n",
    "        json.dump(payload, fh, indent=2, ensure_ascii=False)\n",
    "\n",
    "\n",
    "def thumbnail(path: Path, size: Tuple[int, int] = (640, 640)) -> Path:\n",
    "    out_path = PATHS.cache / f\"thumb-{sha1_path(path)}.png\"\n",
    "    if out_path.exists():\n",
    "        return out_path\n",
    "    with Image.open(path) as img:\n",
    "        img.thumbnail(size, Image.Resampling.LANCZOS)\n",
    "        out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        img.save(out_path, format='PNG')\n",
    "    return out_path\n",
    "\n",
    "\n",
    "def font_available(family: str) -> bool:\n",
    "    if not family:\n",
    "        return False\n",
    "    if not shutil.which(\"fc-list\"):\n",
    "        return False\n",
    "    probe = run([\"fc-list\", family], capture=True)\n",
    "    output = (probe.stdout or \"\").strip()\n",
    "    return bool(output)\n",
    "\n",
    "\n",
    "def choose_font_family(candidates: Iterable[str], default: str = \"DejaVu Sans\") -> str:\n",
    "    for name in candidates:\n",
    "        if font_available(name):\n",
    "            return name\n",
    "    return default\n",
    "\n",
    "\n",
    "def register_font(font_file: Path) -> None:\n",
    "    if not font_file.exists():\n",
    "        return\n",
    "    if shutil.which(\"fc-cache\"):\n",
    "        run([\"fc-cache\", \"-f\", str(font_file.parent)], capture=True)\n",
    "\n",
    "print(\"Utility toolkit loaded ✅\")\n",
    "# ✅\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "# @title 4) Asset Discovery & Metadata Helpers\n",
    "from __future__ import annotations\n",
    "\n",
    "import itertools\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import List, Sequence, Tuple\n",
    "\n",
    "AUDIO_EXTS = (\".wav\", \".mp3\", \".m4a\", \".aac\", \".flac\")\n",
    "IMAGE_EXTS = (\".png\", \".jpg\", \".jpeg\")\n",
    "VIDEO_EXTS = (\".mp4\", \".mov\", \".mkv\")\n",
    "FONT_EXTS = (\".ttf\", \".otf\")\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class AssetCatalog:\n",
    "    audio: List[Path]\n",
    "    backgrounds: List[Path]\n",
    "    videos: List[Path]\n",
    "    fonts: List[Path]\n",
    "\n",
    "    def as_choices(self) -> Tuple[List[str], List[str], List[str], List[str]]:\n",
    "        return (\n",
    "            [str(p) for p in self.audio],\n",
    "            [str(p) for p in self.backgrounds],\n",
    "            [str(p) for p in self.videos],\n",
    "            [str(p) for p in self.fonts],\n",
    "        )\n",
    "\n",
    "\n",
    "def discover_assets(root: Path = PATHS.assets) -> AssetCatalog:\n",
    "    audio: List[Path] = []\n",
    "    backgrounds: List[Path] = []\n",
    "    videos: List[Path] = []\n",
    "    fonts: List[Path] = []\n",
    "\n",
    "    if not root.exists():\n",
    "        logger.warning(\"Assets directory missing: %s\", root)\n",
    "        return AssetCatalog(audio, backgrounds, videos, fonts)\n",
    "\n",
    "    for path in root.rglob('*'):\n",
    "        if not path.is_file():\n",
    "            continue\n",
    "        suffix = path.suffix.lower()\n",
    "        if suffix in AUDIO_EXTS:\n",
    "            audio.append(path)\n",
    "        elif suffix in IMAGE_EXTS:\n",
    "            backgrounds.append(path)\n",
    "        elif suffix in VIDEO_EXTS:\n",
    "            videos.append(path)\n",
    "        elif suffix in FONT_EXTS:\n",
    "            fonts.append(path)\n",
    "\n",
    "    audio.sort()\n",
    "    backgrounds.sort()\n",
    "    videos.sort()\n",
    "    fonts.sort()\n",
    "    logger.info(\n",
    "        \"Assets discovered — audio:%d background:%d video:%d font:%d\",\n",
    "        len(audio), len(backgrounds), len(videos), len(fonts)\n",
    "    )\n",
    "    return AssetCatalog(audio, backgrounds, videos, fonts)\n",
    "\n",
    "ASSETS = discover_assets()\n",
    "print(\"Asset catalog built ✅\")\n",
    "# ✅\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "# @title 5) Audio Pipeline — Analysis, Normalization, and Caching\n",
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict\n",
    "\n",
    "LN_TARGET_I = -16.0\n",
    "LN_TARGET_LRA = 7.0\n",
    "LN_TARGET_TP = -1.5\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class AudioInfo:\n",
    "    path: Path\n",
    "    codec: str\n",
    "    sample_rate: int\n",
    "    channels: int\n",
    "    duration: float\n",
    "\n",
    "\n",
    "def ffprobe_audio(path: Path) -> AudioInfo:\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(path)\n",
    "    probe_cmd = [\n",
    "        \"ffprobe\",\n",
    "        \"-hide_banner\",\n",
    "        \"-v\",\n",
    "        \"error\",\n",
    "        \"-print_format\",\n",
    "        \"json\",\n",
    "        \"-show_streams\",\n",
    "        \"-i\",\n",
    "        str(path),\n",
    "    ]\n",
    "    result = run(probe_cmd, capture=True)\n",
    "    if result.returncode != 0 or not result.stdout:\n",
    "        raise RuntimeError(f\"ffprobe failed for {path}: {result.stderr}\")\n",
    "    payload = json.loads(result.stdout)\n",
    "    streams = payload.get(\"streams\", [])\n",
    "    audio_stream = next((s for s in streams if s.get(\"codec_type\") == \"audio\"), None)\n",
    "    if not audio_stream:\n",
    "        raise RuntimeError(f\"No audio stream found in {path}\")\n",
    "    duration = float(audio_stream.get(\"duration\") or payload.get(\"format\", {}).get(\"duration\") or 0.0)\n",
    "    return AudioInfo(\n",
    "        path=path,\n",
    "        codec=str(audio_stream.get(\"codec_name\", \"unknown\")),\n",
    "        sample_rate=int(audio_stream.get(\"sample_rate\", 0)),\n",
    "        channels=int(audio_stream.get(\"channels\", 0)),\n",
    "        duration=duration,\n",
    "    )\n",
    "\n",
    "\n",
    "def loudnorm_filters(info: AudioInfo, enable: bool) -> str:\n",
    "    if not enable:\n",
    "        return \"aresample=48000:async=1,aformat=channel_layouts=stereo\"\n",
    "    measure_cmd = [\n",
    "        \"ffmpeg\",\n",
    "        \"-hide_banner\",\n",
    "        \"-loglevel\",\n",
    "        \"error\",\n",
    "        \"-i\",\n",
    "        str(info.path),\n",
    "        \"-vn\",\n",
    "        \"-sn\",\n",
    "        \"-dn\",\n",
    "        \"-af\",\n",
    "        \"loudnorm=I=-16:TP=-1.5:LRA=7:print_format=json\",\n",
    "        \"-f\",\n",
    "        \"null\",\n",
    "        \"-\",\n",
    "    ]\n",
    "    measure = run(measure_cmd, capture=True)\n",
    "    summary: Dict[str, float] = {}\n",
    "    if measure.stderr:\n",
    "        for line in measure.stderr.splitlines():\n",
    "            text = line.strip()\n",
    "            if text.startswith('{') and text.endswith('}'):\n",
    "                try:\n",
    "                    summary = json.loads(text)\n",
    "                    break\n",
    "                except json.JSONDecodeError:\n",
    "                    continue\n",
    "    if summary:\n",
    "        return (\n",
    "            \"loudnorm=\"\n",
    "            f\"I={LN_TARGET_I}:LRA={LN_TARGET_LRA}:TP={LN_TARGET_TP}:\"\n",
    "            f\"measured_I={summary.get('input_i', 0.0)}:\"\n",
    "            f\"measured_LRA={summary.get('input_lra', 0.0)}:\"\n",
    "            f\"measured_TP={summary.get('input_tp', 0.0)}:\"\n",
    "            f\"measured_thresh={summary.get('input_thresh', 0.0)}:\"\n",
    "            f\"offset={summary.get('target_offset', 0.0)}:\"\n",
    "            \"linear=true:print_format=summary,\"\n",
    "            \"aresample=48000:async=1,aformat=channel_layouts=stereo\"\n",
    "        )\n",
    "    return \"dynaudnorm=f=125:g=15,aresample=48000:async=1,aformat=channel_layouts=stereo\"\n",
    "\n",
    "\n",
    "def normalize_audio(path: Path, *, fast: bool = True) -> Path:\n",
    "    info = ffprobe_audio(path)\n",
    "    cache_key = f\"audio-{sha1_path(info.path)}-{'fast' if fast else 'loud'}\"\n",
    "    target = PATHS.cache / f\"{cache_key}.m4a\"\n",
    "    if target.exists():\n",
    "        return target\n",
    "    filter_graph = loudnorm_filters(info, enable=not fast)\n",
    "    cmd = [\n",
    "        \"ffmpeg\",\n",
    "        \"-hide_banner\",\n",
    "        \"-loglevel\",\n",
    "        \"error\",\n",
    "        \"-y\",\n",
    "        \"-i\",\n",
    "        str(info.path),\n",
    "        \"-vn\",\n",
    "        \"-sn\",\n",
    "        \"-dn\",\n",
    "        \"-af\",\n",
    "        filter_graph,\n",
    "        \"-ac\",\n",
    "        \"2\",\n",
    "        \"-c:a\",\n",
    "        \"aac\",\n",
    "        \"-b:a\",\n",
    "        \"160k\",\n",
    "        \"-movflags\",\n",
    "        \"+faststart\",\n",
    "        str(target),\n",
    "    ]\n",
    "    result = run(cmd, capture=True)\n",
    "    if result.returncode != 0:\n",
    "        raise RuntimeError(f\"Audio normalize failed for {path}: {result.stderr}\")\n",
    "    return target\n",
    "\n",
    "print(\"Audio pipeline ready ✅\")\n",
    "# ✅\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "# @title 6) Speech-To-Text — Faster-Whisper Integration\n",
    "from __future__ import annotations\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from functools import lru_cache\n",
    "from pathlib import Path\n",
    "from typing import Iterable, List, Optional\n",
    "\n",
    "from faster_whisper import WhisperModel\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class WordTiming:\n",
    "    word: str\n",
    "    start: float\n",
    "    end: float\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class SegmentTiming:\n",
    "    id: int\n",
    "    start: float\n",
    "    end: float\n",
    "    text: str\n",
    "    words: List[WordTiming]\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=2)\n",
    "def load_whisper(model_size: str = \"small\", compute_type: str = \"default\") -> WhisperModel:\n",
    "    model_path = PATHS.models / f\"whisper-{model_size}\"\n",
    "    model_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    logger.info(\"Loading Whisper model %s (cache: %s)\", model_size, model_path)\n",
    "    return WhisperModel(model_size, device=\"auto\", compute_type=compute_type, download_root=str(model_path))\n",
    "\n",
    "\n",
    "def transcribe_audio(\n",
    "    audio_file: Path,\n",
    "    model_size: str = \"small\",\n",
    "    language: Optional[str] = None,\n",
    "    beam_size: int = 5,\n",
    "    vad_filter: bool = True,\n",
    "    condition_on_previous: bool = True,\n",
    ") -> List[SegmentTiming]:\n",
    "    if not audio_file.exists():\n",
    "        raise FileNotFoundError(audio_file)\n",
    "    model = load_whisper(model_size)\n",
    "    logger.info(\"Transcribing %s\", audio_file)\n",
    "    segments, _ = model.transcribe(\n",
    "        str(audio_file),\n",
    "        beam_size=beam_size,\n",
    "        language=language,\n",
    "        condition_on_previous_text=condition_on_previous,\n",
    "        vad_filter=vad_filter,\n",
    "        suppress_tokens=\"-1\",\n",
    "    )\n",
    "    parsed: List[SegmentTiming] = []\n",
    "    for idx, segment in enumerate(segments):\n",
    "        words = [\n",
    "            WordTiming(word=w.word, start=w.start or segment.start, end=w.end or segment.end)\n",
    "            for w in (segment.words or [])\n",
    "        ]\n",
    "        parsed.append(\n",
    "            SegmentTiming(\n",
    "                id=idx,\n",
    "                start=float(segment.start),\n",
    "                end=float(segment.end),\n",
    "                text=segment.text.strip(),\n",
    "                words=words,\n",
    "            )\n",
    "        )\n",
    "    logger.info(\"Transcription produced %d segments\", len(parsed))\n",
    "    return parsed\n",
    "\n",
    "print(\"Speech-to-text module armed ✅\")\n",
    "# ✅\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# @title 7) Caption Authoring — Styles, Layout & Export\n",
    "from __future__ import annotations\n",
    "\n",
    "import datetime as dt\n",
    "import os\n",
    "import shutil\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Iterable, List, Optional\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class CaptionStyle:\n",
    "    font: str = \"Inter\"\n",
    "    font_size: int = 64\n",
    "    primary_color: str = \"&H00FFFFFF\"\n",
    "    secondary_color: str = \"&H00FFFFFF\"\n",
    "    outline_color: str = \"&H00000000\"\n",
    "    background_color: str = \"&H64000000\"\n",
    "    outline_width: float = 3.0\n",
    "    shadow: float = 0.0\n",
    "    alignment: int = 2\n",
    "    margin_h: int = 80\n",
    "    margin_v: int = 80\n",
    "    bold: bool = False\n",
    "\n",
    "    def ass_style(self) -> str:\n",
    "        weight = -1 if self.bold else 0\n",
    "        return (\n",
    "            \"Style: VRDefault,{font},{size},{primary},{secondary},{outline},{background},\"\n",
    "            \"{bold},0,0,0,100,100,0,0,1,{outline_width},{shadow},{align},{margin_h},{margin_h},{margin_v},0\"\n",
    "        ).format(\n",
    "            font=self.font,\n",
    "            size=self.font_size,\n",
    "            primary=self.primary_color,\n",
    "            secondary=self.secondary_color,\n",
    "            outline=self.outline_color,\n",
    "            background=self.background_color,\n",
    "            bold=weight,\n",
    "            outline_width=self.outline_width,\n",
    "            shadow=self.shadow,\n",
    "            align=self.alignment,\n",
    "            margin_h=self.margin_h,\n",
    "            margin_v=self.margin_v,\n",
    "        )\n",
    "\n",
    "ASS_ALIGNMENT_CHOICES: dict[str, int] = {\n",
    "    \"Bottom Left\": 1,\n",
    "    \"Bottom Center\": 2,\n",
    "    \"Bottom Right\": 3,\n",
    "    \"Middle Left\": 4,\n",
    "    \"Middle Center\": 5,\n",
    "    \"Middle Right\": 6,\n",
    "    \"Top Left\": 7,\n",
    "    \"Top Center\": 8,\n",
    "    \"Top Right\": 9,\n",
    "}\n",
    "ASS_ALIGNMENT_DEFAULT_LABEL = \"Bottom Center\"\n",
    "ASS_ALIGNMENT_DEFAULT = ASS_ALIGNMENT_CHOICES[ASS_ALIGNMENT_DEFAULT_LABEL]\n",
    "\n",
    "def clamp(value: float, lower: float, upper: float) -> float:\n",
    "    return max(lower, min(upper, value))\n",
    "\n",
    "def ass_color_from_hex(hex_color: str, opacity_pct: float) -> str:\n",
    "    value = (hex_color or \"#FFFFFF\").strip()\n",
    "    if not value.startswith(\"#\"):\n",
    "        value = f\"#{value}\"\n",
    "    raw = value.lstrip(\"#\")\n",
    "    if len(raw) != 6:\n",
    "        raw = \"FFFFFF\"\n",
    "    try:\n",
    "        r = int(raw[0:2], 16)\n",
    "        g = int(raw[2:4], 16)\n",
    "        b = int(raw[4:6], 16)\n",
    "    except ValueError:\n",
    "        r = g = b = 255\n",
    "    opacity = clamp(opacity_pct, 0.0, 100.0)\n",
    "    alpha = int(round(255 * (100.0 - opacity) / 100.0))\n",
    "    return f\"&H{alpha:02X}{b:02X}{g:02X}{r:02X}\"\n",
    "\n",
    "def alignment_label_to_code(label: str) -> int:\n",
    "    return ASS_ALIGNMENT_CHOICES.get(label, ASS_ALIGNMENT_DEFAULT)\n",
    "\n",
    "def alignment_code_to_label(code: int) -> str:\n",
    "    for name, value in ASS_ALIGNMENT_CHOICES.items():\n",
    "        if value == code:\n",
    "            return name\n",
    "    return ASS_ALIGNMENT_DEFAULT_LABEL\n",
    "\n",
    "def font_family_from_path(font_file: Optional[Path]) -> Optional[str]:\n",
    "    if not font_file or not font_file.exists():\n",
    "        return None\n",
    "    if shutil.which(\"fc-scan\"):\n",
    "        probe = run([\"fc-scan\", \"--format=%{family}\\n\", str(font_file)], capture=True)\n",
    "        output = (probe.stdout or \"\").strip().splitlines()\n",
    "        if output:\n",
    "            return output[0]\n",
    "    return font_file.stem or None\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class CaptionProfile:\n",
    "    font_family: str = \"Inter\"\n",
    "    font_size: int = 64\n",
    "    text_color: str = \"#FFFFFF\"\n",
    "    text_opacity: float = 100.0\n",
    "    outline_color: str = \"#000000\"\n",
    "    outline_opacity: float = 100.0\n",
    "    background_color: str = \"#000000\"\n",
    "    background_opacity: float = 40.0\n",
    "    outline_width: float = 3.0\n",
    "    shadow: float = 0.0\n",
    "    alignment: int = ASS_ALIGNMENT_DEFAULT\n",
    "    margin_h: int = 80\n",
    "    margin_v: int = 80\n",
    "    bold: bool = False\n",
    "\n",
    "    def to_style(self) -> CaptionStyle:\n",
    "        return CaptionStyle(\n",
    "            font=self.font_family,\n",
    "            font_size=int(clamp(self.font_size, 16, 128)),\n",
    "            primary_color=ass_color_from_hex(self.text_color, self.text_opacity),\n",
    "            secondary_color=ass_color_from_hex(self.text_color, self.text_opacity),\n",
    "            outline_color=ass_color_from_hex(self.outline_color, self.outline_opacity),\n",
    "            background_color=ass_color_from_hex(self.background_color, self.background_opacity),\n",
    "            outline_width=round(clamp(self.outline_width, 0.0, 12.0), 2),\n",
    "            shadow=round(clamp(self.shadow, 0.0, 20.0), 2),\n",
    "            alignment=self.alignment if 1 <= self.alignment <= 9 else ASS_ALIGNMENT_DEFAULT,\n",
    "            margin_h=int(clamp(self.margin_h, 0, 400)),\n",
    "            margin_v=int(clamp(self.margin_v, 0, 400)),\n",
    "            bold=self.bold,\n",
    "        )\n",
    "\n",
    "def srt_timestamp(seconds: float) -> str:\n",
    "    td = dt.timedelta(seconds=max(seconds, 0.0))\n",
    "    total = int(td.total_seconds())\n",
    "    hours = total // 3600\n",
    "    minutes = (total % 3600) // 60\n",
    "    secs = total % 60\n",
    "    millis = int((td.total_seconds() - total) * 1000)\n",
    "    return f\"{hours:02}:{minutes:02}:{secs:02},{millis:03}\"\n",
    "\n",
    "ASS_TEXT_TRANSLATION = str.maketrans({\n",
    "    92: \"\\\\\",\n",
    "    123: \"\\{\",\n",
    "    125: \"\\}\",\n",
    "    10: \"\\\\N\",\n",
    "})\n",
    "\n",
    "def escape_ass_text(text: str) -> str:\n",
    "    return text.translate(ASS_TEXT_TRANSLATION)\n",
    "\n",
    "def export_srt(segments: Iterable[SegmentTiming], path: Path) -> Path:\n",
    "    newline = os.linesep\n",
    "    lines: List[str] = []\n",
    "    for idx, seg in enumerate(segments, start=1):\n",
    "        lines.append(str(idx))\n",
    "        lines.append(f\"{srt_timestamp(seg.start)} --> {srt_timestamp(seg.end)}\")\n",
    "        lines.append(seg.text)\n",
    "        lines.append(\"\")\n",
    "    payload = newline.join(lines).strip() + newline\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    path.write_text(payload, encoding='utf-8')\n",
    "    return path\n",
    "\n",
    "def export_ass(segments: Iterable[SegmentTiming], path: Path, style: CaptionStyle) -> Path:\n",
    "    newline = os.linesep\n",
    "    header = [\n",
    "        \"[Script Info]\",\n",
    "        \"ScriptType: v4.00+\",\n",
    "        \"WrapStyle: 2\",\n",
    "        \"ScaledBorderAndShadow: yes\",\n",
    "        \"YCbCr Matrix: TV.709\",\n",
    "        \"\",\n",
    "        \"[V4+ Styles]\",\n",
    "        \"Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, \"\n",
    "        \"Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, \"\n",
    "        \"Alignment, MarginL, MarginR, MarginV, Encoding\",\n",
    "        style.ass_style(),\n",
    "        \"\",\n",
    "        \"[Events]\",\n",
    "        \"Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text\",\n",
    "    ]\n",
    "    body: List[str] = []\n",
    "    for seg in segments:\n",
    "        clean_text = escape_ass_text(seg.text)\n",
    "        body.append(\n",
    "            f\"Dialogue: 0,{srt_timestamp(seg.start).replace(',', '.')},{srt_timestamp(seg.end).replace(',', '.')},\"\n",
    "            f\"VRDefault,,0,0,0,,{clean_text}\"\n",
    "        )\n",
    "    payload = newline.join(header + body) + newline\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    path.write_text(payload, encoding='utf-8')\n",
    "    return path\n",
    "\n",
    "print(\"Caption authoring utilities ready ✅\")\n",
    "# ✅\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "# @title 8) Video Composition — FFmpeg Assembly\n",
    "from __future__ import annotations\n",
    "\n",
    "import shutil\n",
    "import tempfile\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class RenderConfig:\n",
    "    audio: Path\n",
    "    background: Optional[Path]\n",
    "    captions_ass: Optional[Path]\n",
    "    output: Path\n",
    "    fps: int = 30\n",
    "    resolution: Tuple[int, int] = (1080, 1920)\n",
    "    use_nvenc: bool = False\n",
    "    intro: Optional[Path] = None\n",
    "    outro: Optional[Path] = None\n",
    "    cta_loop: Optional[Path] = None\n",
    "\n",
    "\n",
    "def validate_config(cfg: RenderConfig) -> None:\n",
    "    if not cfg.audio.exists():\n",
    "        raise FileNotFoundError(cfg.audio)\n",
    "    if cfg.background and not cfg.background.exists():\n",
    "        raise FileNotFoundError(cfg.background)\n",
    "    if cfg.captions_ass and not cfg.captions_ass.exists():\n",
    "        raise FileNotFoundError(cfg.captions_ass)\n",
    "    cfg.output.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def background_input(cfg: RenderConfig) -> Tuple[str, ...]:\n",
    "    if cfg.background and cfg.background.exists():\n",
    "        if cfg.background.suffix.lower() in IMAGE_EXTS:\n",
    "            return (\"-loop\", \"1\", \"-framerate\", str(cfg.fps), \"-i\", str(cfg.background))\n",
    "        return (\"-i\", str(cfg.background))\n",
    "    width, height = cfg.resolution\n",
    "    return (\"-f\", \"lavfi\", \"-i\", f\"color=size={width}x{height}:rate={cfg.fps}:color=black\")\n",
    "\n",
    "\n",
    "def encoder_args(cfg: RenderConfig) -> Tuple[str, ...]:\n",
    "    if cfg.use_nvenc and shutil.which(\"nvidia-smi\"):\n",
    "        return (\"-c:v\", \"h264_nvenc\", \"-preset\", \"p4\", \"-b:v\", \"12M\", \"-maxrate\", \"16M\", \"-bufsize\", \"24M\")\n",
    "    return (\"-c:v\", \"libx264\", \"-preset\", \"slow\", \"-crf\", \"18\", \"-x264-params\", \"keyint=96:min-keyint=48\")\n",
    "\n",
    "\n",
    "def subtitles_expr(path: Path) -> str:\n",
    "    if not path:\n",
    "        return \"\"\n",
    "    escaped = path.as_posix().replace(\"'\", r\"'\")\n",
    "    return f\",subtitles='{escaped}'\"\n",
    "\n",
    "\n",
    "def render_video(cfg: RenderConfig) -> Path:\n",
    "    validate_config(cfg)\n",
    "    temp_dir = Path(tempfile.mkdtemp(prefix=\"vr-render-\", dir=PATHS.cache))\n",
    "    try:\n",
    "        video_label = \"[vout]\"\n",
    "        sub_expr = subtitles_expr(cfg.captions_ass) if cfg.captions_ass else \"\"\n",
    "        scale_filter = (\n",
    "            f\"[0:v]scale={cfg.resolution[0]}:{cfg.resolution[1]}:force_original_aspect_ratio=increase\"\n",
    "            f\",crop={cfg.resolution[0]}:{cfg.resolution[1]}{sub_expr}{video_label}\"\n",
    "        )\n",
    "        filters = [scale_filter, \"[1:a]anull[aout]\"]\n",
    "        cmd = [\n",
    "            \"ffmpeg\",\n",
    "            \"-hide_banner\",\n",
    "            \"-loglevel\",\n",
    "            \"error\",\n",
    "            \"-y\",\n",
    "            *background_input(cfg),\n",
    "            \"-i\",\n",
    "            str(cfg.audio),\n",
    "            \"-filter_complex\",\n",
    "            \";\".join(filters),\n",
    "            \"-map\",\n",
    "            video_label,\n",
    "            \"-map\",\n",
    "            \"[aout]\",\n",
    "            *encoder_args(cfg),\n",
    "            \"-r\",\n",
    "            str(cfg.fps),\n",
    "            \"-pix_fmt\",\n",
    "            \"yuv420p\",\n",
    "            \"-movflags\",\n",
    "            \"+faststart\",\n",
    "            \"-c:a\",\n",
    "            \"aac\",\n",
    "            \"-b:a\",\n",
    "            \"192k\",\n",
    "            str(cfg.output),\n",
    "        ]\n",
    "        result = run(cmd, capture=True)\n",
    "        if result.returncode != 0:\n",
    "            raise RuntimeError(f\"FFmpeg render failed: {result.stderr}\")\n",
    "        return cfg.output\n",
    "    finally:\n",
    "        shutil.rmtree(temp_dir, ignore_errors=True)\n",
    "\n",
    "print(\"Video composition engine primed ✅\")\n",
    "# ✅\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# @title 9) End-to-End Renderer — Orchestration Logic\n",
    "from __future__ import annotations\n",
    "\n",
    "import datetime as dt\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class RenderRequest:\n",
    "    audio: Path\n",
    "    background: Optional[Path]\n",
    "    caption: CaptionProfile\n",
    "    whisper_model: str = \"small\"\n",
    "    language: Optional[str] = None\n",
    "    fast_audio: bool = True\n",
    "    fps: int = 30\n",
    "    resolution: Tuple[int, int] = (1080, 1920)\n",
    "    use_nvenc: bool = False\n",
    "\n",
    "def workflow(request: RenderRequest) -> Tuple[Path, Path, Path]:\n",
    "    slug = safe_slug(request.audio.stem)\n",
    "    logger.info(\n",
    "        \"Starting render for %s | font=%s size=%s align=%s\",\n",
    "        slug,\n",
    "        request.caption.font_family,\n",
    "        request.caption.font_size,\n",
    "        alignment_code_to_label(request.caption.alignment),\n",
    "    )\n",
    "\n",
    "    normalized_audio = normalize_audio(request.audio, fast=request.fast_audio)\n",
    "    segments = transcribe_audio(\n",
    "        normalized_audio,\n",
    "        model_size=request.whisper_model,\n",
    "        language=request.language,\n",
    "    )\n",
    "\n",
    "    captions_dir = PATHS.cache / f\"captions-{slug}\"\n",
    "    captions_dir.mkdir(parents=True, exist_ok=True)\n",
    "    style = request.caption.to_style()\n",
    "    ass_path = export_ass(segments, captions_dir / f\"{slug}.ass\", style)\n",
    "    srt_path = export_srt(segments, captions_dir / f\"{slug}.srt\")\n",
    "\n",
    "    output = PATHS.renders / f\"{dt.datetime.utcnow():%Y%m%d-%H%M%S}-{slug}.mp4\"\n",
    "    cfg = RenderConfig(\n",
    "        audio=normalized_audio,\n",
    "        background=request.background,\n",
    "        captions_ass=ass_path,\n",
    "        output=output,\n",
    "        fps=request.fps,\n",
    "        resolution=request.resolution,\n",
    "        use_nvenc=request.use_nvenc,\n",
    "    )\n",
    "    render_video(cfg)\n",
    "    logger.info(\"Render complete: %s\", output)\n",
    "    return output, ass_path, srt_path\n",
    "\n",
    "print(\"Workflow coordinator armed ✅\")\n",
    "# ✅\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# @title 10) Interactive Studio — Gradio UI Definition\n",
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "THEME = gr.themes.Soft(primary_hue=\"blue\", secondary_hue=\"cyan\", neutral_hue=\"slate\")\n",
    "\n",
    "def refresh_catalog() -> Tuple[gr.Dropdown, gr.Dropdown, gr.Dropdown]:\n",
    "    global ASSETS\n",
    "    ASSETS = discover_assets()\n",
    "    audio_choices, bg_choices, _, font_choices = ASSETS.as_choices()\n",
    "    return (\n",
    "        gr.Dropdown.update(choices=audio_choices, value=audio_choices[0] if audio_choices else None),\n",
    "        gr.Dropdown.update(choices=bg_choices, value=bg_choices[0] if bg_choices else None),\n",
    "        gr.Dropdown.update(choices=font_choices, value=font_choices[0] if font_choices else None),\n",
    "    )\n",
    "\n",
    "def persist_upload(file: Optional[gr.FileData], subdir: str, *, register: bool = False) -> Optional[Path]:\n",
    "    if not file:\n",
    "        return None\n",
    "    target_dir = PATHS.assets / subdir\n",
    "    target_dir.mkdir(parents=True, exist_ok=True)\n",
    "    source = Path(file.path)\n",
    "    target = target_dir / safe_slug(source.stem + source.suffix)\n",
    "    target.write_bytes(Path(file.path).read_bytes())\n",
    "    if register:\n",
    "        register_font(target)\n",
    "    return target\n",
    "\n",
    "def render_entry(\n",
    "    audio_choice: str,\n",
    "    audio_upload: Optional[gr.FileData],\n",
    "    background_choice: str,\n",
    "    background_upload: Optional[gr.FileData],\n",
    "    font_choice: str,\n",
    "    font_upload: Optional[gr.FileData],\n",
    "    font_family_override: str,\n",
    "    text_color: str,\n",
    "    text_opacity: float,\n",
    "    outline_color: str,\n",
    "    outline_opacity: float,\n",
    "    background_color: str,\n",
    "    background_opacity: float,\n",
    "    outline_width: float,\n",
    "    shadow: float,\n",
    "    font_size: float,\n",
    "    margin_h: float,\n",
    "    margin_v: float,\n",
    "    alignment_label: str,\n",
    "    bold: bool,\n",
    "    whisper_model: str,\n",
    "    language: str,\n",
    "    fast_audio: bool,\n",
    "    fps: float,\n",
    "    use_nvenc: bool,\n",
    ") -> Tuple[str, str, int]:\n",
    "    progress = gr.Progress(track_tqdm=False)\n",
    "    progress(0, desc=\"Preparing\")\n",
    "\n",
    "    audio_path = Path(audio_choice) if audio_choice else None\n",
    "    if audio_upload:\n",
    "        uploaded = persist_upload(audio_upload, \"uploads/audio\")\n",
    "        audio_path = uploaded or audio_path\n",
    "    if not audio_path:\n",
    "        raise gr.Error(\"Select or upload an audio track\")\n",
    "\n",
    "    background_path = Path(background_choice) if background_choice else None\n",
    "    if background_upload:\n",
    "        uploaded_bg = persist_upload(background_upload, \"uploads/background\")\n",
    "        background_path = uploaded_bg or background_path\n",
    "\n",
    "    font_path = Path(font_choice) if font_choice else None\n",
    "    if font_upload:\n",
    "        uploaded_font = persist_upload(font_upload, \"uploads/fonts\", register=True)\n",
    "        font_path = uploaded_font or font_path\n",
    "\n",
    "    manual_family = (font_family_override or \"\").strip()\n",
    "    detected_family = font_family_from_path(font_path)\n",
    "    caption_font = choose_font_family(\n",
    "        [name for name in (manual_family, detected_family, \"Inter\", \"DejaVu Sans\") if name],\n",
    "        default=\"Inter\",\n",
    "    )\n",
    "\n",
    "    caption = CaptionProfile(\n",
    "        font_family=caption_font,\n",
    "        font_size=int(font_size),\n",
    "        text_color=text_color or \"#FFFFFF\",\n",
    "        text_opacity=float(text_opacity),\n",
    "        outline_color=outline_color or \"#000000\",\n",
    "        outline_opacity=float(outline_opacity),\n",
    "        background_color=background_color or \"#000000\",\n",
    "        background_opacity=float(background_opacity),\n",
    "        outline_width=float(outline_width),\n",
    "        shadow=float(shadow),\n",
    "        alignment=alignment_label_to_code(alignment_label),\n",
    "        margin_h=int(margin_h),\n",
    "        margin_v=int(margin_v),\n",
    "        bold=bold,\n",
    "    )\n",
    "\n",
    "    request = RenderRequest(\n",
    "        audio=audio_path,\n",
    "        background=background_path,\n",
    "        caption=caption,\n",
    "        whisper_model=whisper_model,\n",
    "        language=language or None,\n",
    "        fast_audio=fast_audio,\n",
    "        fps=int(fps),\n",
    "        use_nvenc=use_nvenc,\n",
    "    )\n",
    "\n",
    "    progress(30, desc=\"Transcribing & styling\")\n",
    "    video_path, ass_path, srt_path = workflow(request)\n",
    "    progress(100, desc=\"Done\")\n",
    "\n",
    "    status = (\n",
    "        f\"<div><h3>Render complete</h3><ul>\"\n",
    "        f\"<li>Video: {video_path}</li>\"\n",
    "        f\"<li>ASS: {ass_path}</li>\"\n",
    "        f\"<li>SRT: {srt_path}</li>\"\n",
    "        f\"<li>Captions: {caption.font_family} · {alignment_label} · size {caption.font_size}</li>\"\n",
    "        \"</ul></div>\"\n",
    "    )\n",
    "    return str(video_path), status, 100\n",
    "\n",
    "def create_ui() -> gr.Blocks:\n",
    "    audio_choices, bg_choices, _, font_choices = ASSETS.as_choices()\n",
    "    alignment_labels = list(ASS_ALIGNMENT_CHOICES.keys())\n",
    "    default_alignment = alignment_code_to_label(ASS_ALIGNMENT_DEFAULT)\n",
    "    with gr.Blocks(theme=THEME, title=\"VideoRobot Studio Pro — Refactored\") as demo:\n",
    "        gr.Markdown(\"## 🎬 VideoRobot Studio Pro — Production Edition\")\n",
    "        with gr.Row():\n",
    "            with gr.Column(scale=1):\n",
    "                audio = gr.Dropdown(audio_choices, label=\"Audio\", value=audio_choices[0] if audio_choices else None)\n",
    "                audio_up = gr.File(label=\"Upload audio\", file_count=\"single\", file_types=[\"audio\"])\n",
    "                bg = gr.Dropdown(bg_choices, label=\"Background\", value=bg_choices[0] if bg_choices else None)\n",
    "                bg_up = gr.File(label=\"Upload background\", file_count=\"single\", file_types=[\"image\", \"video\"])\n",
    "                refresh = gr.Button(\"🔄 Refresh assets\", variant=\"secondary\")\n",
    "            with gr.Column(scale=1):\n",
    "                model = gr.Radio([\"large-v3\", \"medium\", \"small\"], value=\"small\", label=\"Whisper size\")\n",
    "                language = gr.Textbox(value=\"\", label=\"Language hint (optional)\")\n",
    "                fast_audio = gr.Checkbox(True, label=\"Fast audio path (skip loudnorm)\")\n",
    "                fps = gr.Slider(24, 60, 30, step=6, label=\"FPS\")\n",
    "                use_nvenc = gr.Checkbox(False, label=\"Use NVENC (if available)\")\n",
    "            with gr.Column(scale=1):\n",
    "                with gr.Accordion(\"Caption Designer\", open=True):\n",
    "                    font = gr.Dropdown(font_choices, label=\"Font asset\", value=font_choices[0] if font_choices else None)\n",
    "                    font_up = gr.File(label=\"Upload font\", file_count=\"single\", file_types=[\".ttf\", \".otf\"])\n",
    "                    font_family = gr.Textbox(value=\"\", label=\"Font family override\", placeholder=\"e.g. Inter, Helvetica Neue\")\n",
    "                    text_color = gr.ColorPicker(value=\"#FFFFFF\", label=\"Text color\")\n",
    "                    text_opacity = gr.Slider(0, 100, 100, step=5, label=\"Text opacity (%)\")\n",
    "                    outline_color = gr.ColorPicker(value=\"#000000\", label=\"Outline color\")\n",
    "                    outline_opacity = gr.Slider(0, 100, 100, step=5, label=\"Outline opacity (%)\")\n",
    "                    outline_width = gr.Slider(0, 10, 3, step=0.1, label=\"Outline width\")\n",
    "                    shadow = gr.Slider(0, 10, 0.7, step=0.1, label=\"Shadow\")\n",
    "                    background_color = gr.ColorPicker(value=\"#000000\", label=\"Background color\")\n",
    "                    background_opacity = gr.Slider(0, 100, 50, step=5, label=\"Background opacity (%)\")\n",
    "                    font_size = gr.Slider(32, 96, 64, step=2, label=\"Font size\")\n",
    "                    margin_h = gr.Slider(0, 200, 80, step=5, label=\"Horizontal margin (px)\")\n",
    "                    margin_v = gr.Slider(0, 200, 80, step=5, label=\"Vertical margin (px)\")\n",
    "                    alignment = gr.Dropdown(alignment_labels, value=default_alignment, label=\"Caption anchor\")\n",
    "                    bold = gr.Checkbox(False, label=\"Bold captions\")\n",
    "        with gr.Row():\n",
    "            run_btn = gr.Button(\"Render\", variant=\"primary\")\n",
    "        with gr.Row():\n",
    "            video = gr.Video(label=\"Preview\", height=420, autoplay=True, show_download_button=True)\n",
    "            status = gr.HTML(\"Awaiting render…\")\n",
    "            progress = gr.Slider(0, 100, 0, interactive=False, label=\"Progress %\")\n",
    "\n",
    "        run_btn.click(\n",
    "            render_entry,\n",
    "            inputs=[\n",
    "                audio,\n",
    "                audio_up,\n",
    "                bg,\n",
    "                bg_up,\n",
    "                font,\n",
    "                font_up,\n",
    "                font_family,\n",
    "                text_color,\n",
    "                text_opacity,\n",
    "                outline_color,\n",
    "                outline_opacity,\n",
    "                background_color,\n",
    "                background_opacity,\n",
    "                outline_width,\n",
    "                shadow,\n",
    "                font_size,\n",
    "                margin_h,\n",
    "                margin_v,\n",
    "                alignment,\n",
    "                bold,\n",
    "                model,\n",
    "                language,\n",
    "                fast_audio,\n",
    "                fps,\n",
    "                use_nvenc,\n",
    "            ],\n",
    "            outputs=[video, status, progress],\n",
    "        )\n",
    "\n",
    "        refresh.click(refresh_catalog, outputs=[audio, bg, font])\n",
    "    return demo\n",
    "\n",
    "print(\"UI factory configured ✅\")\n",
    "# ✅\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "\n",
    "# @title 11) Launch Studio — Gradio App\n",
    "from __future__ import annotations\n",
    "\n",
    "try:\n",
    "    ui = create_ui()\n",
    "    ui.queue(api_open=False).launch(inline=True, show_error=True, prevent_thread_lock=True)\n",
    "    print(\"Studio ready ✅\")\n",
    "except Exception as exc:\n",
    "    raise RuntimeError(f\"Failed to launch UI: {exc}\")\n",
    "# ✅\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}